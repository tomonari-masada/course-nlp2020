{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_document_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7jqZv94avJ8XZBhlYxPdh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/07_document_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_0ZZ8bo1mgH"
      },
      "source": [
        "# 07 単語埋め込みを使った文書分類\n",
        "* 今回も、IMDbデータセットの感情分析を文書分類問題として解く。\n",
        "* ただし今回は、fastTextのような学習済みの単語埋め込みは使わない。\n",
        "* 単語埋め込み自体の学習も、ネットワークの学習と同時におこなう。\n",
        "* IMDbデータの準備も、`torch.torchtext`を使っておこなう。\n",
        " * つまりすべてをPyTorchのなかでおこなう。\n",
        "* 参考資料\n",
        " * https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
        " * https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb\n",
        " * https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyjU004LNbMt"
      },
      "source": [
        "## データをどう扱うか\n",
        "* ネットワークへの入力は、単語埋め込みを、単語の出現順どおりに並べた列にする。\n",
        " * ミニバッチは[ミニバッチのなかでの最大文書長, ミニバッチのサイズ, 単語埋め込み次元数]という形の3階のテンソルになる。\n",
        "* そして、前向き計算のなかではじめて、単語埋め込みの平均をとることにする。\n",
        " * `.mean(0)`と、軸0で平均をとることになる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_puYg6Zi8x3"
      },
      "source": [
        "## 07-00 Google Colabのランタイムのタイプを変更する\n",
        "* Google ColabのランタイムのタイプをGPUに変更しておこう。\n",
        " * 上のメニューの「ランタイム」→「ランタイムのタイプを変更」→「ハードウェア　アクセラレータ」から「GPU」を選択"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLEeO0fw23Xp"
      },
      "source": [
        "## 07-01 torchtextを使ってIMDbデータを読み込む\n",
        "* ここでIMDbデータセットの読み込みにつかう`torchtext.datasets`については、下記を参照。\n",
        " * https://torchtext.readthedocs.io/en/latest/datasets.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go7epLZe3JmF"
      },
      "source": [
        "### 実験の再現性確保のための設定など\n",
        "* https://pytorch.org/docs/stable/notes/randomness.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nSqNzof1lTJ"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.data import Field, LabelField, BucketIterator\n",
        "\n",
        "SEED = 123\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.set_deterministic(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y1_GyXg22f6"
      },
      "source": [
        "### torchtextのフィールド\n",
        "* TEXTフィールドと、LABELフィールドという２種類のFieldオブジェクトのインスタンスを作る。\n",
        " * Fieldクラスの詳細については[ここ](https://github.com/pytorch/text/blob/master/torchtext/data/field.py)を参照。\n",
        "* TEXTフィールドは、テキストの前処理の仕方を決めておくのに使う。\n",
        " * tokenizerは、デフォルトでは単にstring型のsplitメソッドを適用するだけになる。これは高速だが、tokenizationとしては雑。\n",
        "* LABELフィールドは、ラベルの前処理に使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjq8oooE2uQY"
      },
      "source": [
        "TEXT = Field(tokenize=\"spacy\")\n",
        "LABEL = LabelField()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtEq23GS3Vxl"
      },
      "source": [
        "### IMDbデータセットをダウンロードした後、前処理しつつ読み込む\n",
        "* ダウンロードはすぐ終わるが、解凍に少し時間がかかる。\n",
        "* また、TEXTフィールドでspaCyのtokenizationを使うように設定したので、少し時間がかかる。\n",
        " * string型のsplitメソッドでtokenizeすると、時間はあまりかからない。（そのかわり、やや雑なtokenizationになる。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzgVXf3G3YPI"
      },
      "source": [
        "train_valid_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0sltPjT3j36"
      },
      "source": [
        "### 最初の文書を見てみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrXwYMVH3orf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1414ef0c-44f6-40ab-add0-97386e6326d1"
      },
      "source": [
        "print(train_valid_data[0].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', 'couple(Janet', 'and', 'Richard', ')', 'go', 'camping', 'out', 'in', 'the', 'woods', 'near', 'a', 'giant', 'swamp', '.', 'After', 'camping', 'and', 'enjoying', 'nature', ',', 'the', 'couple', 'takes', 'shelter', 'in', 'what', 'they', 'think', 'is', 'an', 'abandoned', 'farm', 'house', '.', 'Soon', ',', 'a', 'pair', 'of', 'escaped', 'convicts', 'show', 'up', 'and', ',', 'after', 'much', 'delaying', 'of', 'the', 'inevitable', ',', 'they', 'proceed', 'to', 'rape', 'Janet', 'and', 'lock', 'Richard', 'in', 'a', 'birdcage.<br', '/><br', '/>This', 'LAST', 'HOUSE', 'ON', 'THE', 'LEFT', '-', 'like', 'film', 'has', 'to', 'be', 'one', 'of', 'the', 'most', 'underrated', 'horror', 'films', 'ever', 'made', '.', 'It', \"'s\", 'one', 'of', 'the', 'more', 'sick', 'and', 'twisted', 'early', '70s', 'shockers', '.', 'Moreover', ',', 'I', 'found', 'this', 'to', 'be', 'quite', 'enchanting', 'and', 'beautiful', 'in', 'it', \"'s\", 'perverse', 'tone', '.', 'I', 'love', 'CAGED', 'TERROR', '.', 'The', 'music', 'definitely', 'helps', 'lend', 'a', 'sense', 'of', 'personality', 'to', 'the', 'film', 'as', 'well', 'as', 'a', 'lot', 'of', 'beauty', '.', 'I', 'found', 'the', 'film', 'to', 'be', 'quite', 'creepy.<br', '/><br', '/>The', 'flaws', 'mainly', 'have', 'to', 'do', 'with', 'the', 'pacing', 'of', 'the', 'film', ',', 'which', 'is', 'to', 'say', 'that', 'the', 'film', 'is', 'rather', 'slow', 'and', 'meandering', '.', 'While', 'I', 'did', \"n't\", 'mind', 'the', 'pacing', 'due', 'to', 'the', 'beauty', 'and', 'suspense', 'of', 'the', 'film', 'in', 'question', ',', 'I', 'do', 'think', 'that', 'it', 'will', 'both', 'most', 'people', '.', 'The', 'acting', 'is', \"n't\", 'too', 'good', 'nor', 'is', 'the', 'dialogue', ',', 'at', 'least', 'in', 'the', 'early', 'scenes', '.', 'This', 'film', 'takes', 'a', 'little', 'more', 'patience', 'than', 'usual', ',', 'and', 'it', \"'s\", 'really', 'not', 'for', 'everyone.<br', '/><br', '/>In', 'short', ',', 'this', 'was', 'a', 'good', 'film', '.', 'Not', 'the', 'greatest', 'horror', 'film', 'I', \"'ve\", 'ever', 'seen', ',', 'but', 'it', 'is', 'certainly', 'a', 'lot', 'of', 'fun', '.', 'It', \"'s\", 'not', 'exactly', 'the', 'easiest', 'film', 'to', 'find', '.', 'It', \"'s\", 'possible', 'to', 'find', 'it', 'in', 'the', 'USED', 'section', 'of', 'a', 'lot', 'of', 'stores', 'if', 'you', 'look', 'hard', 'enough', '.', 'It', \"'s\", 'not', 'for', 'everyone', ',', 'but', 'if', 'you', \"'re\", 'a', 'fan', 'of', 'trash', 'cinema', 'then', 'it', \"'s\", 'definitely', 'worth', 'checking', 'out', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRMuAOum3rB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea56f2a-6f02-46b9-d151-f87fbd8dd9ab"
      },
      "source": [
        "print(train_valid_data[0].label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgZgQbyD3u9D"
      },
      "source": [
        "### テストセット以外の部分を訓練データと検証データに分ける"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2FtnEKZ32hM"
      },
      "source": [
        "train_data, valid_data = train_valid_data.split(split_ratio=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fzsi9ZC36eR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15dee62-f70c-4304-f6a7-ba24b3660186"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsLNP7pGaNtp",
        "outputId": "6da55357-4ef7-4e10-a5d3-9d8ece0b7de4"
      },
      "source": [
        "print(train_data[0].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'have', 'complained', 'to', 'ABC', 'about', 'the', 'cancellation', 'of', 'six', 'degrees', '.', 'If', 'enough', 'people', 'do', 'the', 'same', 'then', 'it', 'could', 'be', 'enough', 'to', 'bring', 'this', 'fabulous', 'show', 'back', 'to', 'life', '!', '!', 'Just', 'go', 'onto', 'the', 'official', 'site', 'and', 'the', 'rest', 'is', 'simple', 'enough', '.', 'I', 'do', 'not', 'understand', 'why', 'this', 'show', 'has', 'been', 'cancelled', '.', 'What', 'a', 'fantastic', 'show', ',', 'cast', 'and', 'characters', '.', 'The', 'whole', 'concept', 'is', 'gripping', 'viewing', '!', 'I', 'am', 'astounded', 'that', 'my', 'favourite', 'show', 'is', 'over', 'after', 'just', 'one', 'series', '.', 'Why', 'is', 'this', '?', 'Six', 'degrees', 'is', 'phenomenal', ',', 'it', \"'s\", 'better', 'than', 'so', 'many', 'other', 'TV', 'programmes', 'out', 'there', '!', 'Until', 'I', 'heard', 'they', 'were', 'stopping', 'it', 'from', 'a', 'friend', 'it', 'had', \"n't\", 'even', 'occurred', 'to', 'me', 'that', 'this', 'might', 'happen', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oXz2lvB37Vm"
      },
      "source": [
        "### データセットの語彙とラベルを作る\n",
        "* TEXTラベルのほうでは、最大語彙サイズを指定する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBQeD7yC37x4"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000 # この値は適当。\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iv6RSh3HmLf"
      },
      "source": [
        "なぜ語彙サイズが25,000ではなく25,002なのかについては、少し下の説明を参照。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWuYQthC4Ml8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "435e6073-2b28-4409-f160-5aabde8d438e"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW4eR-K44Rba"
      },
      "source": [
        "### 出現頻度順で上位２０単語を見てみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jan98ffr4PXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "addea501-036c-45ab-f7c3-51ec1d7f1490"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 231080), (',', 219679), ('.', 189780), ('and', 125114), ('a', 124787), ('of', 114842), ('to', 106981), ('is', 87533), ('in', 70047), ('I', 62069), ('it', 61265), ('that', 56156), ('\"', 50707), (\"'s\", 49452), ('this', 48451), ('-', 42013), ('/><br', 40450), ('was', 39644), ('as', 34848), ('with', 34297)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKQojOuv4Z38"
      },
      "source": [
        "### 単語ID順に最初の１０単語を見てみる\n",
        "* IDのうち、0と1は、未知語とパディング用の単語という特殊な単語に割り振られている。\n",
        " * 未知語は`<unk>`という特殊な単語に置き換えられる。これのIDが0。\n",
        " * パディングとは、長さが不揃いの複数の文書を同じミニバッチにまとめるとき、すべての文書の長さを無理やりそろえるため、文書末尾に特殊な単語（元々の語彙にない、人工的に用意した単語）を追加すること。\n",
        " * パディング用の単語が`<pad>`になっているのは、上のほうで使ったFieldクラスのインスタンスを作るときのデフォルトの値がこの`<pad>`になっているため。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlhXRT3g4Xad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf8895d-09c9-4e12-ca5c-7a5270042988"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vJfHTdR4qd4"
      },
      "source": [
        "### ラベルのほうのIDを確認する\n",
        "* こちらはnegとposに対応する２つのIDしかない。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI7Pz_6R4bYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd10f42-a6d7-4ddf-e11b-17a606051ec7"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f277c7d11e0>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14_znTjp4w5s"
      },
      "source": [
        "### ミニバッチを取り出すためのiteratorを作る\n",
        "* ミニバッチのサイズを指定する。\n",
        " * ミニバッチのサイズは、性能を出すためにチューニングすべきハイパーパラメータのひとつ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUED86Jb4tUy"
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator = data.BucketIterator(train_data, batch_size=BATCH_SIZE, device=device,\n",
        "                                     sort_within_batch=True, shuffle=True, sort_key=lambda x: len(x.text))\n",
        "valid_iterator = data.BucketIterator(valid_data, batch_size=BATCH_SIZE, device=device)\n",
        "test_iterator = data.BucketIterator(test_data, batch_size=BATCH_SIZE, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a45QA7ncg_Qv"
      },
      "source": [
        "### ミニバッチの中身を確認する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAW9Ec5q6BQO"
      },
      "source": [
        "* 訓練データのiteratorを回してミニバッチをすべて取得してみる\n",
        " * ミニバッチのshapeを表示してみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpn4tfWl42kY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e3a502-97fa-4f56-84a4-4596980e62ca"
      },
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "  print(i, batch.text.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([133, 100])\n",
            "1 torch.Size([458, 100])\n",
            "2 torch.Size([247, 100])\n",
            "3 torch.Size([212, 100])\n",
            "4 torch.Size([105, 100])\n",
            "5 torch.Size([380, 100])\n",
            "6 torch.Size([94, 100])\n",
            "7 torch.Size([185, 100])\n",
            "8 torch.Size([285, 100])\n",
            "9 torch.Size([112, 100])\n",
            "10 torch.Size([50, 100])\n",
            "11 torch.Size([538, 100])\n",
            "12 torch.Size([188, 100])\n",
            "13 torch.Size([161, 100])\n",
            "14 torch.Size([226, 100])\n",
            "15 torch.Size([135, 100])\n",
            "16 torch.Size([391, 100])\n",
            "17 torch.Size([835, 100])\n",
            "18 torch.Size([180, 100])\n",
            "19 torch.Size([169, 100])\n",
            "20 torch.Size([242, 100])\n",
            "21 torch.Size([929, 100])\n",
            "22 torch.Size([1064, 100])\n",
            "23 torch.Size([69, 100])\n",
            "24 torch.Size([298, 100])\n",
            "25 torch.Size([268, 100])\n",
            "26 torch.Size([329, 100])\n",
            "27 torch.Size([215, 100])\n",
            "28 torch.Size([622, 100])\n",
            "29 torch.Size([128, 100])\n",
            "30 torch.Size([274, 100])\n",
            "31 torch.Size([223, 100])\n",
            "32 torch.Size([154, 100])\n",
            "33 torch.Size([475, 100])\n",
            "34 torch.Size([63, 100])\n",
            "35 torch.Size([173, 100])\n",
            "36 torch.Size([404, 100])\n",
            "37 torch.Size([440, 100])\n",
            "38 torch.Size([121, 100])\n",
            "39 torch.Size([707, 100])\n",
            "40 torch.Size([416, 100])\n",
            "41 torch.Size([199, 100])\n",
            "42 torch.Size([164, 100])\n",
            "43 torch.Size([157, 100])\n",
            "44 torch.Size([348, 100])\n",
            "45 torch.Size([587, 100])\n",
            "46 torch.Size([428, 100])\n",
            "47 torch.Size([263, 100])\n",
            "48 torch.Size([145, 100])\n",
            "49 torch.Size([57, 100])\n",
            "50 torch.Size([100, 100])\n",
            "51 torch.Size([142, 100])\n",
            "52 torch.Size([291, 100])\n",
            "53 torch.Size([148, 100])\n",
            "54 torch.Size([257, 100])\n",
            "55 torch.Size([159, 100])\n",
            "56 torch.Size([253, 100])\n",
            "57 torch.Size([369, 100])\n",
            "58 torch.Size([178, 100])\n",
            "59 torch.Size([117, 100])\n",
            "60 torch.Size([495, 100])\n",
            "61 torch.Size([162, 100])\n",
            "62 torch.Size([183, 100])\n",
            "63 torch.Size([205, 100])\n",
            "64 torch.Size([761, 100])\n",
            "65 torch.Size([209, 100])\n",
            "66 torch.Size([176, 100])\n",
            "67 torch.Size([152, 100])\n",
            "68 torch.Size([234, 100])\n",
            "69 torch.Size([279, 100])\n",
            "70 torch.Size([663, 100])\n",
            "71 torch.Size([140, 100])\n",
            "72 torch.Size([230, 100])\n",
            "73 torch.Size([155, 100])\n",
            "74 torch.Size([238, 100])\n",
            "75 torch.Size([202, 100])\n",
            "76 torch.Size([359, 100])\n",
            "77 torch.Size([339, 100])\n",
            "78 torch.Size([150, 100])\n",
            "79 torch.Size([314, 100])\n",
            "80 torch.Size([166, 100])\n",
            "81 torch.Size([76, 100])\n",
            "82 torch.Size([196, 100])\n",
            "83 torch.Size([81, 100])\n",
            "84 torch.Size([219, 100])\n",
            "85 torch.Size([88, 100])\n",
            "86 torch.Size([147, 100])\n",
            "87 torch.Size([131, 100])\n",
            "88 torch.Size([2789, 100])\n",
            "89 torch.Size([562, 100])\n",
            "90 torch.Size([144, 100])\n",
            "91 torch.Size([137, 100])\n",
            "92 torch.Size([139, 100])\n",
            "93 torch.Size([171, 100])\n",
            "94 torch.Size([193, 100])\n",
            "95 torch.Size([124, 100])\n",
            "96 torch.Size([322, 100])\n",
            "97 torch.Size([306, 100])\n",
            "98 torch.Size([515, 100])\n",
            "99 torch.Size([191, 100])\n",
            "100 torch.Size([242, 100])\n",
            "101 torch.Size([200, 100])\n",
            "102 torch.Size([224, 100])\n",
            "103 torch.Size([233, 100])\n",
            "104 torch.Size([105, 100])\n",
            "105 torch.Size([133, 100])\n",
            "106 torch.Size([153, 100])\n",
            "107 torch.Size([220, 100])\n",
            "108 torch.Size([553, 100])\n",
            "109 torch.Size([112, 100])\n",
            "110 torch.Size([190, 100])\n",
            "111 torch.Size([228, 100])\n",
            "112 torch.Size([385, 100])\n",
            "113 torch.Size([188, 100])\n",
            "114 torch.Size([272, 100])\n",
            "115 torch.Size([157, 100])\n",
            "116 torch.Size([324, 100])\n",
            "117 torch.Size([141, 100])\n",
            "118 torch.Size([155, 100])\n",
            "119 torch.Size([256, 100])\n",
            "120 torch.Size([1018, 100])\n",
            "121 torch.Size([196, 100])\n",
            "122 torch.Size([527, 100])\n",
            "123 torch.Size([650, 100])\n",
            "124 torch.Size([251, 100])\n",
            "125 torch.Size([171, 100])\n",
            "126 torch.Size([308, 100])\n",
            "127 torch.Size([2142, 100])\n",
            "128 torch.Size([582, 100])\n",
            "129 torch.Size([145, 100])\n",
            "130 torch.Size([340, 100])\n",
            "131 torch.Size([150, 100])\n",
            "132 torch.Size([408, 100])\n",
            "133 torch.Size([214, 100])\n",
            "134 torch.Size([468, 100])\n",
            "135 torch.Size([94, 100])\n",
            "136 torch.Size([167, 100])\n",
            "137 torch.Size([63, 100])\n",
            "138 torch.Size([185, 100])\n",
            "139 torch.Size([207, 100])\n",
            "140 torch.Size([802, 100])\n",
            "141 torch.Size([198, 100])\n",
            "142 torch.Size([302, 100])\n",
            "143 torch.Size([217, 100])\n",
            "144 torch.Size([69, 100])\n",
            "145 torch.Size([486, 100])\n",
            "146 torch.Size([435, 100])\n",
            "147 torch.Size([375, 100])\n",
            "148 torch.Size([366, 100])\n",
            "149 torch.Size([125, 100])\n",
            "150 torch.Size([238, 100])\n",
            "151 torch.Size([128, 100])\n",
            "152 torch.Size([266, 100])\n",
            "153 torch.Size([289, 100])\n",
            "154 torch.Size([296, 100])\n",
            "155 torch.Size([121, 100])\n",
            "156 torch.Size([75, 100])\n",
            "157 torch.Size([88, 100])\n",
            "158 torch.Size([347, 100])\n",
            "159 torch.Size([143, 100])\n",
            "160 torch.Size([169, 100])\n",
            "161 torch.Size([193, 100])\n",
            "162 torch.Size([173, 100])\n",
            "163 torch.Size([612, 100])\n",
            "164 torch.Size([420, 100])\n",
            "165 torch.Size([742, 100])\n",
            "166 torch.Size([148, 100])\n",
            "167 torch.Size([137, 100])\n",
            "168 torch.Size([81, 100])\n",
            "169 torch.Size([146, 100])\n",
            "170 torch.Size([100, 100])\n",
            "171 torch.Size([49, 100])\n",
            "172 torch.Size([118, 100])\n",
            "173 torch.Size([176, 100])\n",
            "174 torch.Size([204, 100])\n",
            "175 torch.Size([278, 100])\n",
            "176 torch.Size([135, 100])\n",
            "177 torch.Size([330, 100])\n",
            "178 torch.Size([165, 100])\n",
            "179 torch.Size([183, 100])\n",
            "180 torch.Size([397, 100])\n",
            "181 torch.Size([161, 100])\n",
            "182 torch.Size([163, 100])\n",
            "183 torch.Size([356, 100])\n",
            "184 torch.Size([178, 100])\n",
            "185 torch.Size([159, 100])\n",
            "186 torch.Size([131, 100])\n",
            "187 torch.Size([892, 100])\n",
            "188 torch.Size([316, 100])\n",
            "189 torch.Size([210, 100])\n",
            "190 torch.Size([180, 100])\n",
            "191 torch.Size([283, 100])\n",
            "192 torch.Size([246, 100])\n",
            "193 torch.Size([56, 100])\n",
            "194 torch.Size([151, 100])\n",
            "195 torch.Size([506, 100])\n",
            "196 torch.Size([689, 100])\n",
            "197 torch.Size([261, 100])\n",
            "198 torch.Size([452, 100])\n",
            "199 torch.Size([139, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWW1np1P6OQg"
      },
      "source": [
        "* ミニバッチの形は、[ミニバッチ内での最大文書長, ミニバッチのサイズ]になっていることに注意！\n",
        " * ミニバッチのサイズが最初に来ているのではない！\n",
        " * [ミニバッチのサイズ, ミニバッチ内での最大文書長]という形にしたいなら、テキストのfieldを作るとき以下のようにする。\n",
        "\n",
        "__`TEXT = data.Field(tokenize=\"spacy\", batch_first=True)`__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHytOsiSUdeS"
      },
      "source": [
        "* 上記のループを抜けたあとには、変数batchには最後のミニバッチが代入されている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d78vJW616H7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198614d1-c77e-44ff-bbaf-236adbbf99be"
      },
      "source": [
        "batch.text.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([139, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHMHkR73VuCD"
      },
      "source": [
        "* このミニバッチに含まれる文書のうち、最初の文書の単語ID列を表示させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tZLm0hQVjZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a66f8e-40e3-4540-a31d-6006e6d97a11"
      },
      "source": [
        "print(batch.text[:, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   11,    97,   133,   995,     2,   406,    11,   236,    16,    22,\n",
            "            4,   357,    79,    29,     6, 10165,    29,     0,    10,     2,\n",
            "         2902,  8669,     5,    16,    19,     2, 19088,    22,     7,     2,\n",
            "         2498,     4,   357,  2384,   542,    64,   139,     2,   375,  5891,\n",
            "            4,   239,    86,    33,    80,   378,     8,   140,    12,    41,\n",
            "            2,  2080,    17,   406,   820,     4,     0,    23,     6, 18057,\n",
            "          425,  3810,    66,     9,    42,    11,    74,    34,     8,   153,\n",
            "           26,    45,    34,    16,   407,  3129,    13,    83,   988,   228,\n",
            "         3404,   872,   444,     4,    11,   171,    33,   433,     8,  6890,\n",
            "            2,   988,    21,  1546,   759,    48,    11,    97,    55,  1753,\n",
            "            8, 16358,   382,    11,    93,    83,   872,   444,     7, 19338,\n",
            "            4,    11,    91,    33,   180,   755,     0,  3643,    10,     2,\n",
            "          942,    26,    11,   426,    99,    10,     2,    22,     4,    25,\n",
            "            0,    19,   442,     5,     2,   714,    80,   484,     4],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcXV1WLCdax1"
      },
      "source": [
        "* このミニバッチに含まれる文書のうち、最初の文書の単語ID列を単語列に戻したものを表示させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjaS-Mjadf63",
        "outputId": "1b2c347f-ce05-4c85-c6c6-df386579c277"
      },
      "source": [
        "print(' '.join([TEXT.vocab.itos[i] for i in batch.text[:, 0]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I will never forget the night I saw this movie . We were on a submarine on <unk> in the North Atlantic and this was the scheduled movie of the evening . We ALL gave up after the second reel . They did not even try to show it at the mid - night showing . <unk> for a rerun instead ...... This is all I really have to say but they have this stupid rule that my comment must contain ten lines . I 'm not supposed to pad the comment with random words so I will just continue to ramble until I get my ten lines of BS . I could not find George <unk> listed in the credits but I remember him in the movie . The <unk> was terrible and the songs even worse .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uoslpyTgz8w"
      },
      "source": [
        "* このミニバッチに含まれる文書のうち、最後の文書の単語ID列を表示させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcdyIhK0TUac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "793e9452-ae8e-4f53-f079-b81dcd6e923c"
      },
      "source": [
        "print(batch.text[:, BATCH_SIZE-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([12995,     3,  7102,  4776,   221,    22,  3786,     4,    11,    73,\n",
            "          355,  1887,    23,    16,    22,     3,     5,     2,   548,     7,\n",
            "         5743,  2604,  1057,     0,     9,    38,    13,   156,    57,    28,\n",
            "         8947,     3,    26,    62,  1901,    57,   156,    78,     6,   784,\n",
            "           20,  3394,     5,  3024,    20,    16,    38,    19,     4,    66,\n",
            "           63,    34,    92, 10355,     3,    20,    12,   230,     9,    10,\n",
            "          168,  2641,     7,   112,     3,    70,     2,   221,     0,     3,\n",
            "         1112,     3,    12,    86,    33,     4,    25,   221,    84,  1718,\n",
            "            2,  5902,     0,     5,   134,     2,   374,   907,     7,  5743,\n",
            "          221,     3,    26,    12,    15,    33,    62,  1233,     3, 23158,\n",
            "         2226,     3,     5,    10,   213,   448,   360,  3434,    27,   570,\n",
            "           16,     9,   732,     8,   863,    17,   839,    23,  8550,   825,\n",
            "            3,    12,    84,   140,  4396,    10,   132,  1410,     7, 21570,\n",
            "           30,     4,    11,    19,    62,   730,     4,     1,     1],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtDXRKPMT9KW"
      },
      "source": [
        "最後の文書の末尾は「1」で埋められていることが分かる。\n",
        "\n",
        "この1は、パディング用単語のIDだったことを想起されたい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDzk2ghCUD8N"
      },
      "source": [
        "ミニバッチに含まれる文書の長さを調べると、文書が文書長の降順に並べられていることが分かる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PutP_EU4Tca-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b713a444-69e4-42ef-99fd-7f82aea0aed2"
      },
      "source": [
        "(batch.text != 1).sum(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
              "        139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
              "        139, 139, 139, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
              "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
              "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
              "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
              "        138, 138, 138, 138, 138, 138, 137, 137, 137, 137, 137, 137, 137, 137,\n",
              "        137, 137], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PDZlF0O6doP"
      },
      "source": [
        "## 07-02 MLPによる文書分類の準備\n",
        "* 今回は、ごく簡単なMLPで文書分類をする。\n",
        "* 文書中の全単語トークンの埋め込みベクトルの平均を、MLPの入力とする。\n",
        " * 当然、語順の情報は使われない。\n",
        " * つまり、bag-of-wordsモデルになっている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjpel2i46gbD"
      },
      "source": [
        "### 定数の設定\n",
        "* 単語埋め込みベクトルの次元数は128にする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQPXVLC66NUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2542b05-42bf-4c44-8beb-5722eddf68f4"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "NUM_CLASS = len(LABEL.vocab)\n",
        "EMBED_DIM = 128\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "print(f'語彙サイズ {INPUT_DIM}, クラス数 {NUM_CLASS}, 単語埋め込み次元 {EMBED_DIM}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "語彙サイズ 25002, クラス数 2, 単語埋め込み次元 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsuHjuNp6tvt"
      },
      "source": [
        "### モデルを定義する前にPyTorchの単語埋め込みがどんなものかを見てみる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3J7TzxFVMsR"
      },
      "source": [
        "以下のように、語彙サイズと埋め込みの次元数を指定しつつ、torch.nn.Embeddingのインスタンスを作ればよい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP7jJVYT6tBg"
      },
      "source": [
        "embed = nn.Embedding(INPUT_DIM, EMBED_DIM, padding_idx=PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUl6lR8JVWTu"
      },
      "source": [
        "パディング用の単語の埋め込みはゼロベクトルになる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3ZCr9Ll61m8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b578602-fd9f-4c45-b577-e12c43ccaab6"
      },
      "source": [
        "print(embed(torch.tensor([21,1])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.4663,  0.3888,  0.5244, -0.6720,  1.2702,  0.1475, -0.6756,  1.0647,\n",
            "          0.4122,  0.4360,  0.4711,  1.7838, -0.2890, -0.1943, -0.4321,  0.1552,\n",
            "         -0.2901,  0.6956,  0.3870,  1.3461,  3.0132,  0.9346, -2.4039, -0.0521,\n",
            "         -0.7123, -0.9902,  1.6379,  0.2446, -0.4733,  1.0840, -0.1715, -1.9957,\n",
            "         -0.7140,  0.2289, -0.5881,  2.2581, -0.5802,  1.4646,  0.0392, -0.7295,\n",
            "          0.4982, -1.1848,  0.4286, -0.0767,  1.2760, -1.3223,  0.0627,  0.3617,\n",
            "         -0.7071,  0.0949, -0.5615, -0.6247,  1.0816,  0.7235, -0.9131,  0.6759,\n",
            "          0.0999, -0.9366,  1.9773,  1.2333,  0.1287, -1.0535, -1.6376,  0.7970,\n",
            "          0.1361, -0.0714, -0.2324, -0.8216,  1.4716, -0.0678,  0.4309, -0.1257,\n",
            "          0.2348, -1.3550,  0.3339,  2.1095,  1.8534, -0.8028,  0.6104,  0.8844,\n",
            "         -0.4362,  0.4587,  0.4177,  1.4428,  0.0063, -0.2002,  0.4557,  0.4221,\n",
            "         -1.5692, -0.5961, -0.7103, -0.9230,  0.1227, -0.0557, -0.0169,  0.9816,\n",
            "          0.1775,  0.8781, -2.7163, -0.1170, -0.4895, -0.4243,  0.5754, -0.2282,\n",
            "          0.2867,  0.4296, -1.3569, -0.4296,  0.5040, -1.0372,  1.0028, -1.2460,\n",
            "         -0.1285, -1.9543, -1.0806,  2.8702,  0.3659, -1.1613,  0.4680,  0.1308,\n",
            "          1.0111, -1.1194, -1.4237, -1.2461, -0.2059, -1.8122, -2.5448, -0.5135],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
            "       grad_fn=<EmbeddingBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyngitc78hv"
      },
      "source": [
        "### モデルの定義\n",
        "* MLP（多層パーセプトロン）だが、入り口に単語埋め込み層が挿入されている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9asdLYng7DOu"
      },
      "source": [
        "class EmbedTextSentiment(nn.Module):\n",
        "  def __init__(self, embed_dim, num_class, vocab_size, padding_idx):\n",
        "    super(EmbedTextSentiment, self).__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
        "    self.fc1 = nn.Linear(embed_dim, 500)\n",
        "    self.fc2 = nn.Linear(500, 100)\n",
        "    self.fc3 = nn.Linear(100, num_class)\n",
        "\n",
        "  def forward(self, text):\n",
        "    x = self.embed(text)\n",
        "    x = x.mean(0) # 文書に含まれる全単語トークンの単語ベクトルの平均\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foU72cB48IO9"
      },
      "source": [
        "### モデルを作る\n",
        "* モデル（のインスタンス）をGPUに移動させている点に注意。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0BHCGAZ8F18"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wylQOq8N8cqI"
      },
      "source": [
        "### 損失関数とoptimizerとschedulerを作る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw34INS78cIW"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilWLfu8Z8MzW"
      },
      "source": [
        "### 訓練用の関数\n",
        "* 最初の`model.train()`に注意。こうやって、モデルを訓練モードに設定する。\n",
        " * 例えば、dropoutを含むモデルなど、訓練時と評価時で、ふるまい方を変える必要があるときがあるため、こういうことをする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR2R4Lqh8J7n"
      },
      "source": [
        "def train(data_iterator, model, optimizer, scheduler, criterion):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  for batch in data_iterator:\n",
        "    optimizer.zero_grad()\n",
        "    text, cls = batch.text, batch.label\n",
        "    output = model(text)\n",
        "    loss = criterion(output, cls)\n",
        "    train_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_acc += (output.argmax(1) == cls).float().mean().item()\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  num_batch = len(data_iterator)\n",
        "  return train_loss / num_batch, train_acc / num_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftuX8e1W8iRh"
      },
      "source": [
        "### 評価用の関数\n",
        "* 最初の`model.eval()`に注意。こうやって、モデルを評価モードに設定する。\n",
        " * 例えば、dropoutを含むモデルなど、訓練時と評価時で、ふるまい方を変える必要があるときがあるため、こういうことをする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGUnsJlq8Ue3"
      },
      "source": [
        "def test(data_iterator, model, criterion):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  for batch in data_iterator:\n",
        "    text, cls = batch.text, batch.label\n",
        "    with torch.no_grad():\n",
        "      output = model(text)\n",
        "      loss = criterion(output, cls)\n",
        "      loss += loss.item()\n",
        "      acc += (output.argmax(1) == cls).float().mean().item()\n",
        "\n",
        "  num_batch = len(data_iterator)\n",
        "  return loss / num_batch, acc / num_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8o_jDAg8osP"
      },
      "source": [
        "## 07-03 分類器の訓練と検証セットでの評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJJFv4k-8mH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a620f913-4e66-42f7-fdc6-0da612c4fc26"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | time in 0 minutes, 2 seconds | lr=0.009500\n",
            "\tLoss: 0.38365(train)\t|\tAcc: 82.22%(train)\n",
            "\tLoss: 0.01790(valid)\t|\tAcc: 88.22%(valid)\n",
            "Epoch 2 | time in 0 minutes, 2 seconds | lr=0.009025\n",
            "\tLoss: 0.16225(train)\t|\tAcc: 93.99%(train)\n",
            "\tLoss: 0.01481(valid)\t|\tAcc: 88.52%(valid)\n",
            "Epoch 3 | time in 0 minutes, 2 seconds | lr=0.008574\n",
            "\tLoss: 0.07868(train)\t|\tAcc: 97.22%(train)\n",
            "\tLoss: 0.01262(valid)\t|\tAcc: 86.78%(valid)\n",
            "Epoch 4 | time in 0 minutes, 2 seconds | lr=0.008145\n",
            "\tLoss: 0.03622(train)\t|\tAcc: 98.72%(train)\n",
            "\tLoss: 0.01336(valid)\t|\tAcc: 87.76%(valid)\n",
            "Epoch 5 | time in 0 minutes, 2 seconds | lr=0.007738\n",
            "\tLoss: 0.02071(train)\t|\tAcc: 99.30%(train)\n",
            "\tLoss: 0.00742(valid)\t|\tAcc: 87.70%(valid)\n",
            "Epoch 6 | time in 0 minutes, 2 seconds | lr=0.007351\n",
            "\tLoss: 0.01853(train)\t|\tAcc: 99.40%(train)\n",
            "\tLoss: 0.01542(valid)\t|\tAcc: 87.30%(valid)\n",
            "Epoch 7 | time in 0 minutes, 2 seconds | lr=0.006983\n",
            "\tLoss: 0.01147(train)\t|\tAcc: 99.58%(train)\n",
            "\tLoss: 0.01617(valid)\t|\tAcc: 87.88%(valid)\n",
            "Epoch 8 | time in 0 minutes, 2 seconds | lr=0.006634\n",
            "\tLoss: 0.00950(train)\t|\tAcc: 99.63%(train)\n",
            "\tLoss: 0.01347(valid)\t|\tAcc: 86.34%(valid)\n",
            "Epoch 9 | time in 0 minutes, 2 seconds | lr=0.006302\n",
            "\tLoss: 0.00979(train)\t|\tAcc: 99.65%(train)\n",
            "\tLoss: 0.01758(valid)\t|\tAcc: 87.84%(valid)\n",
            "Epoch 10 | time in 0 minutes, 2 seconds | lr=0.005987\n",
            "\tLoss: 0.00610(train)\t|\tAcc: 99.87%(train)\n",
            "\tLoss: 0.01464(valid)\t|\tAcc: 87.70%(valid)\n",
            "Epoch 11 | time in 0 minutes, 2 seconds | lr=0.005688\n",
            "\tLoss: 0.00365(train)\t|\tAcc: 99.89%(train)\n",
            "\tLoss: 0.01425(valid)\t|\tAcc: 87.58%(valid)\n",
            "Epoch 12 | time in 0 minutes, 2 seconds | lr=0.005404\n",
            "\tLoss: 0.00242(train)\t|\tAcc: 99.92%(train)\n",
            "\tLoss: 0.01832(valid)\t|\tAcc: 87.50%(valid)\n",
            "Epoch 13 | time in 0 minutes, 2 seconds | lr=0.005133\n",
            "\tLoss: 0.00430(train)\t|\tAcc: 99.83%(train)\n",
            "\tLoss: 0.00985(valid)\t|\tAcc: 88.20%(valid)\n",
            "Epoch 14 | time in 0 minutes, 2 seconds | lr=0.004877\n",
            "\tLoss: 0.00400(train)\t|\tAcc: 99.89%(train)\n",
            "\tLoss: 0.01406(valid)\t|\tAcc: 87.62%(valid)\n",
            "Epoch 15 | time in 0 minutes, 2 seconds | lr=0.004633\n",
            "\tLoss: 0.00138(train)\t|\tAcc: 99.97%(train)\n",
            "\tLoss: 0.00984(valid)\t|\tAcc: 87.16%(valid)\n",
            "Epoch 16 | time in 0 minutes, 2 seconds | lr=0.004401\n",
            "\tLoss: 0.00021(train)\t|\tAcc: 99.99%(train)\n",
            "\tLoss: 0.00887(valid)\t|\tAcc: 87.50%(valid)\n",
            "Epoch 17 | time in 0 minutes, 2 seconds | lr=0.004181\n",
            "\tLoss: 0.00002(train)\t|\tAcc: 100.00%(train)\n",
            "\tLoss: 0.03332(valid)\t|\tAcc: 87.76%(valid)\n",
            "Epoch 18 | time in 0 minutes, 2 seconds | lr=0.003972\n",
            "\tLoss: 0.00001(train)\t|\tAcc: 100.00%(train)\n",
            "\tLoss: 0.00775(valid)\t|\tAcc: 87.72%(valid)\n",
            "Epoch 19 | time in 0 minutes, 2 seconds | lr=0.003774\n",
            "\tLoss: 0.00001(train)\t|\tAcc: 100.00%(train)\n",
            "\tLoss: 0.01694(valid)\t|\tAcc: 87.70%(valid)\n",
            "Epoch 20 | time in 0 minutes, 2 seconds | lr=0.003585\n",
            "\tLoss: 0.00000(train)\t|\tAcc: 100.00%(train)\n",
            "\tLoss: 0.01113(valid)\t|\tAcc: 87.64%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPux8PReWTXG"
      },
      "source": [
        "## 07-04 再検討\n",
        "* 訓練データ上での分類精度がほぼ100%になってしまっている。\n",
        "* 検証データでの分類精度と大きな差があり、明らかにオーバーフィッティング。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23jMgtmoWkty"
      },
      "source": [
        "### ドロップアウトを使う\n",
        "* モデルのインスタンスを作るときにdropoutの確率を引数pで指定できるようにする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khps3ZuBWntq"
      },
      "source": [
        "class EmbedTextSentiment(nn.Module):\n",
        "  def __init__(self, embed_dim, num_class, vocab_size, padding_idx, p=0.0):\n",
        "    super(EmbedTextSentiment, self).__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
        "    self.dropout = nn.Dropout(p=p)\n",
        "    self.fc1 = nn.Linear(embed_dim, 500)\n",
        "    self.fc2 = nn.Linear(500, 100)\n",
        "    self.fc3 = nn.Linear(100, num_class)\n",
        "\n",
        "  def forward(self, text):\n",
        "    x = self.dropout(self.embed(text)) #埋め込み層の直後にdropout\n",
        "    x = x.mean(0)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVXbkt6qXxNt"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXkBDXc6X1mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8607de16-acbc-4eac-a788-d1d8860cc672"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | time in 0 minutes, 2 seconds | lr=0.009500\n",
            "\tLoss: 0.43358(train)\t|\tAcc: 78.99%(train)\n",
            "\tLoss: 0.01906(valid)\t|\tAcc: 87.42%(valid)\n",
            "Epoch 2 | time in 0 minutes, 2 seconds | lr=0.009025\n",
            "\tLoss: 0.22468(train)\t|\tAcc: 91.23%(train)\n",
            "\tLoss: 0.01557(valid)\t|\tAcc: 88.08%(valid)\n",
            "Epoch 3 | time in 0 minutes, 2 seconds | lr=0.008574\n",
            "\tLoss: 0.15242(train)\t|\tAcc: 94.25%(train)\n",
            "\tLoss: 0.01521(valid)\t|\tAcc: 88.64%(valid)\n",
            "Epoch 4 | time in 0 minutes, 2 seconds | lr=0.008145\n",
            "\tLoss: 0.10738(train)\t|\tAcc: 96.01%(train)\n",
            "\tLoss: 0.01225(valid)\t|\tAcc: 88.48%(valid)\n",
            "Epoch 5 | time in 0 minutes, 2 seconds | lr=0.007738\n",
            "\tLoss: 0.07579(train)\t|\tAcc: 97.20%(train)\n",
            "\tLoss: 0.01259(valid)\t|\tAcc: 88.74%(valid)\n",
            "Epoch 6 | time in 0 minutes, 2 seconds | lr=0.007351\n",
            "\tLoss: 0.05858(train)\t|\tAcc: 97.82%(train)\n",
            "\tLoss: 0.01455(valid)\t|\tAcc: 87.94%(valid)\n",
            "Epoch 7 | time in 0 minutes, 2 seconds | lr=0.006983\n",
            "\tLoss: 0.04387(train)\t|\tAcc: 98.33%(train)\n",
            "\tLoss: 0.01025(valid)\t|\tAcc: 88.82%(valid)\n",
            "Epoch 8 | time in 0 minutes, 2 seconds | lr=0.006634\n",
            "\tLoss: 0.03483(train)\t|\tAcc: 98.77%(train)\n",
            "\tLoss: 0.00720(valid)\t|\tAcc: 88.40%(valid)\n",
            "Epoch 9 | time in 0 minutes, 2 seconds | lr=0.006302\n",
            "\tLoss: 0.03162(train)\t|\tAcc: 98.83%(train)\n",
            "\tLoss: 0.00868(valid)\t|\tAcc: 88.06%(valid)\n",
            "Epoch 10 | time in 0 minutes, 2 seconds | lr=0.005987\n",
            "\tLoss: 0.02709(train)\t|\tAcc: 99.00%(train)\n",
            "\tLoss: 0.01184(valid)\t|\tAcc: 88.38%(valid)\n",
            "Epoch 11 | time in 0 minutes, 2 seconds | lr=0.005688\n",
            "\tLoss: 0.01956(train)\t|\tAcc: 99.38%(train)\n",
            "\tLoss: 0.01337(valid)\t|\tAcc: 88.52%(valid)\n",
            "Epoch 12 | time in 0 minutes, 2 seconds | lr=0.005404\n",
            "\tLoss: 0.01625(train)\t|\tAcc: 99.35%(train)\n",
            "\tLoss: 0.00960(valid)\t|\tAcc: 88.06%(valid)\n",
            "Epoch 13 | time in 0 minutes, 2 seconds | lr=0.005133\n",
            "\tLoss: 0.01638(train)\t|\tAcc: 99.45%(train)\n",
            "\tLoss: 0.01501(valid)\t|\tAcc: 88.24%(valid)\n",
            "Epoch 14 | time in 0 minutes, 2 seconds | lr=0.004877\n",
            "\tLoss: 0.01191(train)\t|\tAcc: 99.56%(train)\n",
            "\tLoss: 0.02272(valid)\t|\tAcc: 88.44%(valid)\n",
            "Epoch 15 | time in 0 minutes, 2 seconds | lr=0.004633\n",
            "\tLoss: 0.01009(train)\t|\tAcc: 99.62%(train)\n",
            "\tLoss: 0.01168(valid)\t|\tAcc: 88.26%(valid)\n",
            "Epoch 16 | time in 0 minutes, 2 seconds | lr=0.004401\n",
            "\tLoss: 0.01044(train)\t|\tAcc: 99.63%(train)\n",
            "\tLoss: 0.01400(valid)\t|\tAcc: 87.82%(valid)\n",
            "Epoch 17 | time in 0 minutes, 2 seconds | lr=0.004181\n",
            "\tLoss: 0.00796(train)\t|\tAcc: 99.73%(train)\n",
            "\tLoss: 0.00938(valid)\t|\tAcc: 88.20%(valid)\n",
            "Epoch 18 | time in 0 minutes, 2 seconds | lr=0.003972\n",
            "\tLoss: 0.00752(train)\t|\tAcc: 99.71%(train)\n",
            "\tLoss: 0.01687(valid)\t|\tAcc: 87.96%(valid)\n",
            "Epoch 19 | time in 0 minutes, 2 seconds | lr=0.003774\n",
            "\tLoss: 0.00797(train)\t|\tAcc: 99.73%(train)\n",
            "\tLoss: 0.02296(valid)\t|\tAcc: 88.24%(valid)\n",
            "Epoch 20 | time in 0 minutes, 2 seconds | lr=0.003585\n",
            "\tLoss: 0.00691(train)\t|\tAcc: 99.76%(train)\n",
            "\tLoss: 0.01459(valid)\t|\tAcc: 87.64%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu3Y-wjwb0po"
      },
      "source": [
        "### L２正則化を使う\n",
        "* optimizerのweight_decayパラメータを0より大きな値にする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmxEuSFJazCJ"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0Zr2S7ga3J4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be49fc1c-2c89-45f2-8f36-7047c470e259"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | time in 0 minutes, 2 seconds | lr=0.009500\n",
            "\tLoss: 0.58818(train)\t|\tAcc: 68.09%(train)\n",
            "\tLoss: 0.02606(valid)\t|\tAcc: 54.48%(valid)\n",
            "Epoch 2 | time in 0 minutes, 2 seconds | lr=0.009025\n",
            "\tLoss: 0.45343(train)\t|\tAcc: 79.09%(train)\n",
            "\tLoss: 0.02441(valid)\t|\tAcc: 81.82%(valid)\n",
            "Epoch 3 | time in 0 minutes, 2 seconds | lr=0.008574\n",
            "\tLoss: 0.40164(train)\t|\tAcc: 82.25%(train)\n",
            "\tLoss: 0.02321(valid)\t|\tAcc: 74.08%(valid)\n",
            "Epoch 4 | time in 0 minutes, 2 seconds | lr=0.008145\n",
            "\tLoss: 0.37071(train)\t|\tAcc: 83.83%(train)\n",
            "\tLoss: 0.02561(valid)\t|\tAcc: 60.28%(valid)\n",
            "Epoch 5 | time in 0 minutes, 2 seconds | lr=0.007738\n",
            "\tLoss: 0.34453(train)\t|\tAcc: 85.48%(train)\n",
            "\tLoss: 0.02345(valid)\t|\tAcc: 77.32%(valid)\n",
            "Epoch 6 | time in 0 minutes, 2 seconds | lr=0.007351\n",
            "\tLoss: 0.33281(train)\t|\tAcc: 85.71%(train)\n",
            "\tLoss: 0.02430(valid)\t|\tAcc: 69.64%(valid)\n",
            "Epoch 7 | time in 0 minutes, 2 seconds | lr=0.006983\n",
            "\tLoss: 0.33043(train)\t|\tAcc: 86.00%(train)\n",
            "\tLoss: 0.02125(valid)\t|\tAcc: 86.98%(valid)\n",
            "Epoch 8 | time in 0 minutes, 2 seconds | lr=0.006634\n",
            "\tLoss: 0.31681(train)\t|\tAcc: 86.75%(train)\n",
            "\tLoss: 0.02256(valid)\t|\tAcc: 77.36%(valid)\n",
            "Epoch 9 | time in 0 minutes, 2 seconds | lr=0.006302\n",
            "\tLoss: 0.30216(train)\t|\tAcc: 87.61%(train)\n",
            "\tLoss: 0.02215(valid)\t|\tAcc: 77.08%(valid)\n",
            "Epoch 10 | time in 0 minutes, 2 seconds | lr=0.005987\n",
            "\tLoss: 0.29999(train)\t|\tAcc: 87.57%(train)\n",
            "\tLoss: 0.01835(valid)\t|\tAcc: 87.94%(valid)\n",
            "Epoch 11 | time in 0 minutes, 2 seconds | lr=0.005688\n",
            "\tLoss: 0.29860(train)\t|\tAcc: 87.67%(train)\n",
            "\tLoss: 0.01940(valid)\t|\tAcc: 86.84%(valid)\n",
            "Epoch 12 | time in 0 minutes, 2 seconds | lr=0.005404\n",
            "\tLoss: 0.28120(train)\t|\tAcc: 88.69%(train)\n",
            "\tLoss: 0.02187(valid)\t|\tAcc: 67.84%(valid)\n",
            "Epoch 13 | time in 0 minutes, 2 seconds | lr=0.005133\n",
            "\tLoss: 0.27949(train)\t|\tAcc: 88.59%(train)\n",
            "\tLoss: 0.01988(valid)\t|\tAcc: 87.62%(valid)\n",
            "Epoch 14 | time in 0 minutes, 2 seconds | lr=0.004877\n",
            "\tLoss: 0.26965(train)\t|\tAcc: 88.93%(train)\n",
            "\tLoss: 0.01773(valid)\t|\tAcc: 87.96%(valid)\n",
            "Epoch 15 | time in 0 minutes, 2 seconds | lr=0.004633\n",
            "\tLoss: 0.27458(train)\t|\tAcc: 88.78%(train)\n",
            "\tLoss: 0.01932(valid)\t|\tAcc: 87.18%(valid)\n",
            "Epoch 16 | time in 0 minutes, 2 seconds | lr=0.004401\n",
            "\tLoss: 0.26432(train)\t|\tAcc: 89.22%(train)\n",
            "\tLoss: 0.01899(valid)\t|\tAcc: 88.22%(valid)\n",
            "Epoch 17 | time in 0 minutes, 2 seconds | lr=0.004181\n",
            "\tLoss: 0.26196(train)\t|\tAcc: 89.46%(train)\n",
            "\tLoss: 0.02263(valid)\t|\tAcc: 72.56%(valid)\n",
            "Epoch 18 | time in 0 minutes, 2 seconds | lr=0.003972\n",
            "\tLoss: 0.24841(train)\t|\tAcc: 90.24%(train)\n",
            "\tLoss: 0.02149(valid)\t|\tAcc: 79.52%(valid)\n",
            "Epoch 19 | time in 0 minutes, 2 seconds | lr=0.003774\n",
            "\tLoss: 0.24811(train)\t|\tAcc: 90.03%(train)\n",
            "\tLoss: 0.01815(valid)\t|\tAcc: 85.66%(valid)\n",
            "Epoch 20 | time in 0 minutes, 2 seconds | lr=0.003585\n",
            "\tLoss: 0.23444(train)\t|\tAcc: 90.67%(train)\n",
            "\tLoss: 0.01895(valid)\t|\tAcc: 86.52%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIHA64UTdmBj"
      },
      "source": [
        "### early stopping\n",
        "* dev setでのaccuracyが4回連続で最高値を下回ったら訓練を終えることにする。\n",
        "* early stoppingの実現については、PyTorch Lightningを使う手もある。\n",
        " * https://pytorch-lightning.readthedocs.io/en/latest/early_stopping.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0zclQnVdlVZ"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3E_I5sRc3FF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0ca26d-f3be-49bf-d85a-a759b0648115"
      },
      "source": [
        "patience = 4\n",
        "early_stop_count = 0\n",
        "best_valid_acc = 0.0\n",
        "\n",
        "MIN_N_EPOCHS = 10 # 最低このエポック数は実行する\n",
        "N_EPOCHS = 50 # エポック数を増やしておく\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')\n",
        "\n",
        "  # early stopping\n",
        "  if epoch + 1 > MIN_N_EPOCHS:\n",
        "    if best_valid_acc <= valid_acc:\n",
        "      best_valid_acc = valid_acc\n",
        "      early_stop_count = 0\n",
        "    else:\n",
        "      early_stop_count += 1\n",
        "      if early_stop_count == patience:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | time in 0 minutes, 2 seconds | lr=0.009500\n",
            "\tLoss: 0.59871(train)\t|\tAcc: 66.79%(train)\n",
            "\tLoss: 0.02251(valid)\t|\tAcc: 56.18%(valid)\n",
            "Epoch 2 | time in 0 minutes, 2 seconds | lr=0.009025\n",
            "\tLoss: 0.43493(train)\t|\tAcc: 80.24%(train)\n",
            "\tLoss: 0.02186(valid)\t|\tAcc: 77.00%(valid)\n",
            "Epoch 3 | time in 0 minutes, 2 seconds | lr=0.008574\n",
            "\tLoss: 0.38540(train)\t|\tAcc: 83.23%(train)\n",
            "\tLoss: 0.02093(valid)\t|\tAcc: 83.76%(valid)\n",
            "Epoch 4 | time in 0 minutes, 2 seconds | lr=0.008145\n",
            "\tLoss: 0.35846(train)\t|\tAcc: 84.48%(train)\n",
            "\tLoss: 0.02126(valid)\t|\tAcc: 85.30%(valid)\n",
            "Epoch 5 | time in 0 minutes, 2 seconds | lr=0.007738\n",
            "\tLoss: 0.34493(train)\t|\tAcc: 85.37%(train)\n",
            "\tLoss: 0.02423(valid)\t|\tAcc: 75.62%(valid)\n",
            "Epoch 6 | time in 0 minutes, 2 seconds | lr=0.007351\n",
            "\tLoss: 0.33198(train)\t|\tAcc: 85.92%(train)\n",
            "\tLoss: 0.02041(valid)\t|\tAcc: 82.98%(valid)\n",
            "Epoch 7 | time in 0 minutes, 2 seconds | lr=0.006983\n",
            "\tLoss: 0.31971(train)\t|\tAcc: 86.85%(train)\n",
            "\tLoss: 0.02184(valid)\t|\tAcc: 86.56%(valid)\n",
            "Epoch 8 | time in 0 minutes, 2 seconds | lr=0.006634\n",
            "\tLoss: 0.31571(train)\t|\tAcc: 86.90%(train)\n",
            "\tLoss: 0.02071(valid)\t|\tAcc: 86.66%(valid)\n",
            "Epoch 9 | time in 0 minutes, 2 seconds | lr=0.006302\n",
            "\tLoss: 0.30255(train)\t|\tAcc: 87.62%(train)\n",
            "\tLoss: 0.02063(valid)\t|\tAcc: 77.64%(valid)\n",
            "Epoch 10 | time in 0 minutes, 2 seconds | lr=0.005987\n",
            "\tLoss: 0.29818(train)\t|\tAcc: 87.70%(train)\n",
            "\tLoss: 0.02094(valid)\t|\tAcc: 71.52%(valid)\n",
            "Epoch 11 | time in 0 minutes, 2 seconds | lr=0.005688\n",
            "\tLoss: 0.28962(train)\t|\tAcc: 88.05%(train)\n",
            "\tLoss: 0.02188(valid)\t|\tAcc: 87.46%(valid)\n",
            "Epoch 12 | time in 0 minutes, 2 seconds | lr=0.005404\n",
            "\tLoss: 0.28703(train)\t|\tAcc: 88.32%(train)\n",
            "\tLoss: 0.02332(valid)\t|\tAcc: 72.02%(valid)\n",
            "Epoch 13 | time in 0 minutes, 2 seconds | lr=0.005133\n",
            "\tLoss: 0.28297(train)\t|\tAcc: 88.54%(train)\n",
            "\tLoss: 0.02103(valid)\t|\tAcc: 85.72%(valid)\n",
            "Epoch 14 | time in 0 minutes, 2 seconds | lr=0.004877\n",
            "\tLoss: 0.27238(train)\t|\tAcc: 88.94%(train)\n",
            "\tLoss: 0.02083(valid)\t|\tAcc: 88.00%(valid)\n",
            "Epoch 15 | time in 0 minutes, 2 seconds | lr=0.004633\n",
            "\tLoss: 0.26952(train)\t|\tAcc: 88.88%(train)\n",
            "\tLoss: 0.02107(valid)\t|\tAcc: 77.38%(valid)\n",
            "Epoch 16 | time in 0 minutes, 2 seconds | lr=0.004401\n",
            "\tLoss: 0.26073(train)\t|\tAcc: 89.45%(train)\n",
            "\tLoss: 0.02070(valid)\t|\tAcc: 74.40%(valid)\n",
            "Epoch 17 | time in 0 minutes, 2 seconds | lr=0.004181\n",
            "\tLoss: 0.25400(train)\t|\tAcc: 89.83%(train)\n",
            "\tLoss: 0.01971(valid)\t|\tAcc: 78.76%(valid)\n",
            "Epoch 18 | time in 0 minutes, 2 seconds | lr=0.003972\n",
            "\tLoss: 0.24744(train)\t|\tAcc: 90.10%(train)\n",
            "\tLoss: 0.01977(valid)\t|\tAcc: 87.68%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRvkncN09MKk"
      },
      "source": [
        "## 07-05 テストセット上で評価\n",
        "* 見つけ出したベストな設定を使って、テストセット上での最終的な評価をおこなう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_gHj4x38y8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d632645-e822-47ba-8cfa-9278a5d09d69"
      },
      "source": [
        "print('Checking the results of test dataset...')\n",
        "test_loss, test_acc = test(test_iterator, model, criterion)\n",
        "print(f'\\tLoss: {test_loss:.5f}(test)\\t|\\tAcc: {test_acc * 100:.2f}%(test)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset...\n",
            "\tLoss: 0.00390(test)\t|\tAcc: 86.76%(test)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1M_VQ1xhcWq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}