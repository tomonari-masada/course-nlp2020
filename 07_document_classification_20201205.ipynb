{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_document_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPT2CAq+Xa4AIVXeEz1X2nN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/07_document_classification_20201205.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_0ZZ8bo1mgH"
      },
      "source": [
        "# 07 単語埋め込みを使った文書分類\n",
        "* 今回も、IMDbデータセットの感情分析を文書分類問題として解く。\n",
        "* ただし今回は、fastTextのような学習済みの単語埋め込みは使わない。\n",
        "* 単語埋め込み自体の学習も、ネットワークの学習と同時におこなう。\n",
        "* IMDbデータの準備も、`torch.torchtext`を使っておこなう。\n",
        " * つまりすべてをPyTorchのなかでおこなう。\n",
        "* 参考資料\n",
        " * https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
        " * https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb\n",
        " * https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyjU004LNbMt"
      },
      "source": [
        "## データをどう扱うか\n",
        "* ネットワークへの入力は、単語埋め込みを、単語の出現順どおりに並べた列にする。\n",
        " * ミニバッチは[ミニバッチのなかでの最大文書長, ミニバッチのサイズ, 単語埋め込み次元数]という形の3階のテンソルになる。\n",
        "* そして、前向き計算のなかではじめて、単語埋め込みの平均をとることにする。\n",
        " * `.mean(0)`と、軸0で平均をとることになる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_puYg6Zi8x3"
      },
      "source": [
        "## 07-00 Google Colabのランタイムのタイプを変更する\n",
        "* Google ColabのランタイムのタイプをGPUに変更しておこう。\n",
        " * 上のメニューの「ランタイム」→「ランタイムのタイプを変更」→「ハードウェア　アクセラレータ」から「GPU」を選択"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLEeO0fw23Xp"
      },
      "source": [
        "## 07-01 torchtextを使ってIMDbデータを読み込む\n",
        "* ここでIMDbデータセットの読み込みにつかう`torchtext.datasets`については、下記を参照。\n",
        " * https://torchtext.readthedocs.io/en/latest/datasets.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go7epLZe3JmF"
      },
      "source": [
        "### 実験の再現性確保のための設定など\n",
        "* https://pytorch.org/docs/stable/notes/randomness.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nSqNzof1lTJ"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.data import Field, LabelField, BucketIterator\n",
        "\n",
        "SEED = 123\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.set_deterministic(True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y1_GyXg22f6"
      },
      "source": [
        "### torchtextのフィールド\n",
        "* TEXTフィールドと、LABELフィールドという２種類のFieldオブジェクトのインスタンスを作る。\n",
        " * Fieldクラスの詳細については[ここ](https://github.com/pytorch/text/blob/master/torchtext/data/field.py)を参照。\n",
        "* TEXTフィールドは、テキストの前処理の仕方を決めておくのに使う。\n",
        " * tokenizerは、デフォルトでは単にstring型のsplitメソッドを適用するだけになる。これは高速だが、tokenizationとしては雑。\n",
        "* LABELフィールドは、ラベルの前処理に使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjq8oooE2uQY"
      },
      "source": [
        "TEXT = Field(tokenize=\"spacy\")\n",
        "LABEL = LabelField()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtEq23GS3Vxl"
      },
      "source": [
        "### IMDbデータセットをダウンロードした後、前処理しつつ読み込む\n",
        "* ダウンロードはすぐ終わるが、解凍に少し時間がかかる。\n",
        "* また、TEXTフィールドでspaCyのtokenizationを使うように設定したので、少し時間がかかる。\n",
        " * string型のsplitメソッドでtokenizeすると、時間はあまりかからない。（そのかわり、やや雑なtokenizationになる。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzgVXf3G3YPI",
        "outputId": "fcdf4bcd-4698-4284-902a-af4d2a2f8592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_valid_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 21.2MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0sltPjT3j36"
      },
      "source": [
        "### 最初の文書を見てみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrXwYMVH3orf",
        "outputId": "76e2254d-bee8-4634-8da4-0eb9ebf8fa01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_valid_data[0].text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['What', 'could', 'be', 'more', 'schlocky', 'than', 'the', 'idea', 'of', 'private', 'detectives', 'getting', 'involved', 'with', 'the', 'women', 'they', \"'re\", 'supposed', 'to', 'be', 'spying', 'on', '?', 'And', 'most', 'of', 'the', 'dialogue', 'as', 'written', 'is', 'perfectly', 'banal.<br', '/><br', '/>But', 'the', 'actors', 'turn', 'the', 'dialog', 'into', 'something', 'that', 'makes', 'sense', '.', 'You', 'can', 'see', 'real', 'people', 'behind', 'the', 'unreal', 'lines', '.', 'And', 'the', 'directing', 'is', 'wonderful', '.', 'Each', 'scene', 'does', 'just', 'what', 'it', 'has', 'to', 'and', 'ends', 'without', 'dragging', 'on', 'too', 'long.<br', '/><br', '/>I', 'showed', 'this', 'to', 'several', 'friends', 'in', 'the', 'mid-80s', 'because', 'I', 'was', 'perplexed', 'at', 'how', 'such', 'bad', 'material', 'could', 'be', 'made', 'into', 'such', 'a', 'good', 'movie', '.', 'The', 'friends', 'enjoyed', 'it', 'too', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRMuAOum3rB5",
        "outputId": "3a198d4a-7dc9-4d08-efdd-4864b69b0e5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_valid_data[0].label)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgZgQbyD3u9D"
      },
      "source": [
        "### テストセット以外の部分を訓練データと検証データに分ける"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2FtnEKZ32hM"
      },
      "source": [
        "train_data, valid_data = train_valid_data.split(split_ratio=0.8)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fzsi9ZC36eR",
        "outputId": "ef1762c3-5ba5-4e88-984d-25a101610e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsLNP7pGaNtp",
        "outputId": "7bf7d341-263b-4f96-ac01-efb955e62b20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_data[0].text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'was', 'pleasantly', 'surprised', 'by', 'the', 'film', '.', 'Let', \"'s\", 'face', 'it', ';', 'the', 'premise', 'does', \"n't\", 'sound', 'particularly', 'appealing', 'when', 'having', 'to', 'hand', 'over', 'money', 'for', 'a', 'the', 'night', \"'s\", 'flick', ',', 'but', 'it', 'had', 'an', 'easygoing', 'nature', 'that', 'wins', 'one', 'over', '.', 'There', 'were', 'no', 'moments', 'that', 'I', 'found', 'uproarious', ',', 'and', 'I', 'doubt', 'any', 'that', 'I', \"'ll\", 'remember', 'the', 'next', 'day', ',', 'but', 'this', 'does', \"n't\", 'fail', 'as', 'a', 'nice', 'diversion', '.', 'What', 'I', 'found', 'funny', 'was', 'watching', 'it', 'here', 'in', 'Peking', 'with', 'my', 'Chinese', 'girlfriend', 'who', 'never', 'understands', 'anything', 'I', 'like', '.', 'I', 'told', 'her', 'there', 'was', 'a', 'plot-', 'three', 'guys', 'have', 'to', 'bring', 'back', 'some', 'weed', 'to', 'London', '.', 'Hardly', 'satisfying', 'for', 'her', '.', 'There', 'is', 'no', 'mugging', 'going', 'on', 'here', 'for', 'the', 'camera', 'which', 'I', \"'d\", 'been', 'expecting', 'after', 'reading', 'a', 'number', 'of', 'the', 'comments', '.', 'I', 'do', 'take', 'exception', 'however', 'to', 'comparisons', 'with', 'Withnail', 'and', 'I', ';', 'not', 'in', 'the', 'same', 'league', ',', 'and', 'I', 'doubt', 'was', 'it', 'intended', 'to', '.', 'www.imperialflags.blogspot.com']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oXz2lvB37Vm"
      },
      "source": [
        "### データセットの語彙とラベルを作る\n",
        "* TEXTラベルのほうでは、最大語彙サイズを指定する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBQeD7yC37x4"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000 # この値は適当。\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iv6RSh3HmLf"
      },
      "source": [
        "なぜ語彙サイズが25,000ではなく25,002なのかについては、少し下の説明を参照。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWuYQthC4Ml8",
        "outputId": "7a8bc91e-1364-4f87-9775-5c7349cfdb80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW4eR-K44Rba"
      },
      "source": [
        "### 出現頻度順で上位２０単語を見てみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jan98ffr4PXP",
        "outputId": "a61b35c1-c7b4-4375-a1ca-74ba8d865197",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 232468), (',', 220692), ('.', 190092), ('a', 125458), ('and', 125391), ('of', 115472), ('to', 107502), ('is', 87667), ('in', 70419), ('I', 62409), ('it', 61426), ('that', 56428), ('\"', 50636), (\"'s\", 49514), ('this', 48315), ('-', 42246), ('/><br', 40827), ('was', 39860), ('as', 34976), ('with', 34256)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKQojOuv4Z38"
      },
      "source": [
        "### 単語ID順に最初の１０単語を見てみる\n",
        "* IDのうち、0と1は、未知語とパディング用の単語という特殊な単語に割り振られている。\n",
        " * 未知語は`<unk>`という特殊な単語に置き換えられる。これのIDが0。\n",
        " * パディングとは、長さが不揃いの複数の文書を同じミニバッチにまとめるとき、すべての文書の長さを無理やりそろえるため、文書末尾に特殊な単語（元々の語彙にない、人工的に用意した単語）を追加すること。\n",
        " * パディング用の単語が`<pad>`になっているのは、上のほうで使ったFieldクラスのインスタンスを作るときのデフォルトの値がこの`<pad>`になっているため。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlhXRT3g4Xad",
        "outputId": "8dc01b28-dff5-421f-dfd9-08550ef23486",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vJfHTdR4qd4"
      },
      "source": [
        "### ラベルのほうのIDを確認する\n",
        "* こちらはnegとposに対応する２つのIDしかない。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI7Pz_6R4bYM",
        "outputId": "c0c9acb8-7dc4-4e11-e501-10531c5492d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7faa4ac121e0>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14_znTjp4w5s"
      },
      "source": [
        "### ミニバッチを取り出すためのiteratorを作る\n",
        "* ミニバッチのサイズを指定する。\n",
        " * ミニバッチのサイズは、性能を出すためにチューニングすべきハイパーパラメータのひとつ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUED86Jb4tUy"
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator = data.BucketIterator(train_data, batch_size=BATCH_SIZE, device=device,\n",
        "                                     sort_within_batch=True, shuffle=True, sort_key=lambda x: len(x.text))\n",
        "valid_iterator = data.BucketIterator(valid_data, batch_size=BATCH_SIZE, device=device)\n",
        "test_iterator = data.BucketIterator(test_data, batch_size=BATCH_SIZE, device=device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a45QA7ncg_Qv"
      },
      "source": [
        "### ミニバッチの中身を確認する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAW9Ec5q6BQO"
      },
      "source": [
        "* 訓練データのiteratorを回してミニバッチをすべて取得してみる\n",
        " * ミニバッチのshapeを表示してみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpn4tfWl42kY",
        "outputId": "2d8fec38-cd02-49d6-ae54-e0e50699f393",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "  print(i, batch.text.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([132, 100])\n",
            "1 torch.Size([462, 100])\n",
            "2 torch.Size([251, 100])\n",
            "3 torch.Size([214, 100])\n",
            "4 torch.Size([106, 100])\n",
            "5 torch.Size([386, 100])\n",
            "6 torch.Size([95, 100])\n",
            "7 torch.Size([188, 100])\n",
            "8 torch.Size([291, 100])\n",
            "9 torch.Size([113, 100])\n",
            "10 torch.Size([50, 100])\n",
            "11 torch.Size([544, 100])\n",
            "12 torch.Size([191, 100])\n",
            "13 torch.Size([162, 100])\n",
            "14 torch.Size([229, 100])\n",
            "15 torch.Size([135, 100])\n",
            "16 torch.Size([395, 100])\n",
            "17 torch.Size([832, 100])\n",
            "18 torch.Size([182, 100])\n",
            "19 torch.Size([170, 100])\n",
            "20 torch.Size([246, 100])\n",
            "21 torch.Size([929, 100])\n",
            "22 torch.Size([1054, 100])\n",
            "23 torch.Size([71, 100])\n",
            "24 torch.Size([304, 100])\n",
            "25 torch.Size([273, 100])\n",
            "26 torch.Size([335, 100])\n",
            "27 torch.Size([218, 100])\n",
            "28 torch.Size([623, 100])\n",
            "29 torch.Size([128, 100])\n",
            "30 torch.Size([279, 100])\n",
            "31 torch.Size([226, 100])\n",
            "32 torch.Size([155, 100])\n",
            "33 torch.Size([480, 100])\n",
            "34 torch.Size([65, 100])\n",
            "35 torch.Size([175, 100])\n",
            "36 torch.Size([407, 100])\n",
            "37 torch.Size([447, 100])\n",
            "38 torch.Size([121, 100])\n",
            "39 torch.Size([704, 100])\n",
            "40 torch.Size([419, 100])\n",
            "41 torch.Size([202, 100])\n",
            "42 torch.Size([166, 100])\n",
            "43 torch.Size([158, 100])\n",
            "44 torch.Size([354, 100])\n",
            "45 torch.Size([595, 100])\n",
            "46 torch.Size([433, 100])\n",
            "47 torch.Size([267, 100])\n",
            "48 torch.Size([146, 100])\n",
            "49 torch.Size([58, 100])\n",
            "50 torch.Size([100, 100])\n",
            "51 torch.Size([142, 100])\n",
            "52 torch.Size([298, 100])\n",
            "53 torch.Size([149, 100])\n",
            "54 torch.Size([262, 100])\n",
            "55 torch.Size([160, 100])\n",
            "56 torch.Size([256, 100])\n",
            "57 torch.Size([373, 100])\n",
            "58 torch.Size([180, 100])\n",
            "59 torch.Size([117, 100])\n",
            "60 torch.Size([498, 100])\n",
            "61 torch.Size([163, 100])\n",
            "62 torch.Size([185, 100])\n",
            "63 torch.Size([208, 100])\n",
            "64 torch.Size([754, 100])\n",
            "65 torch.Size([212, 100])\n",
            "66 torch.Size([177, 100])\n",
            "67 torch.Size([153, 100])\n",
            "68 torch.Size([237, 100])\n",
            "69 torch.Size([285, 100])\n",
            "70 torch.Size([663, 100])\n",
            "71 torch.Size([141, 100])\n",
            "72 torch.Size([233, 100])\n",
            "73 torch.Size([156, 100])\n",
            "74 torch.Size([242, 100])\n",
            "75 torch.Size([205, 100])\n",
            "76 torch.Size([364, 100])\n",
            "77 torch.Size([344, 100])\n",
            "78 torch.Size([151, 100])\n",
            "79 torch.Size([320, 100])\n",
            "80 torch.Size([168, 100])\n",
            "81 torch.Size([78, 100])\n",
            "82 torch.Size([199, 100])\n",
            "83 torch.Size([83, 100])\n",
            "84 torch.Size([221, 100])\n",
            "85 torch.Size([90, 100])\n",
            "86 torch.Size([147, 100])\n",
            "87 torch.Size([130, 100])\n",
            "88 torch.Size([1827, 100])\n",
            "89 torch.Size([568, 100])\n",
            "90 torch.Size([144, 100])\n",
            "91 torch.Size([137, 100])\n",
            "92 torch.Size([139, 100])\n",
            "93 torch.Size([172, 100])\n",
            "94 torch.Size([196, 100])\n",
            "95 torch.Size([125, 100])\n",
            "96 torch.Size([328, 100])\n",
            "97 torch.Size([312, 100])\n",
            "98 torch.Size([519, 100])\n",
            "99 torch.Size([193, 100])\n",
            "100 torch.Size([239, 100])\n",
            "101 torch.Size([199, 100])\n",
            "102 torch.Size([222, 100])\n",
            "103 torch.Size([230, 100])\n",
            "104 torch.Size([105, 100])\n",
            "105 torch.Size([134, 100])\n",
            "106 torch.Size([153, 100])\n",
            "107 torch.Size([219, 100])\n",
            "108 torch.Size([553, 100])\n",
            "109 torch.Size([112, 100])\n",
            "110 torch.Size([188, 100])\n",
            "111 torch.Size([226, 100])\n",
            "112 torch.Size([383, 100])\n",
            "113 torch.Size([186, 100])\n",
            "114 torch.Size([268, 100])\n",
            "115 torch.Size([156, 100])\n",
            "116 torch.Size([319, 100])\n",
            "117 torch.Size([141, 100])\n",
            "118 torch.Size([155, 100])\n",
            "119 torch.Size([252, 100])\n",
            "120 torch.Size([1061, 100])\n",
            "121 torch.Size([194, 100])\n",
            "122 torch.Size([527, 100])\n",
            "123 torch.Size([657, 100])\n",
            "124 torch.Size([247, 100])\n",
            "125 torch.Size([170, 100])\n",
            "126 torch.Size([304, 100])\n",
            "127 torch.Size([2789, 100])\n",
            "128 torch.Size([581, 100])\n",
            "129 torch.Size([145, 100])\n",
            "130 torch.Size([335, 100])\n",
            "131 torch.Size([149, 100])\n",
            "132 torch.Size([406, 100])\n",
            "133 torch.Size([212, 100])\n",
            "134 torch.Size([468, 100])\n",
            "135 torch.Size([92, 100])\n",
            "136 torch.Size([166, 100])\n",
            "137 torch.Size([62, 100])\n",
            "138 torch.Size([183, 100])\n",
            "139 torch.Size([205, 100])\n",
            "140 torch.Size([831, 100])\n",
            "141 torch.Size([196, 100])\n",
            "142 torch.Size([298, 100])\n",
            "143 torch.Size([215, 100])\n",
            "144 torch.Size([67, 100])\n",
            "145 torch.Size([485, 100])\n",
            "146 torch.Size([434, 100])\n",
            "147 torch.Size([372, 100])\n",
            "148 torch.Size([362, 100])\n",
            "149 torch.Size([125, 100])\n",
            "150 torch.Size([235, 100])\n",
            "151 torch.Size([129, 100])\n",
            "152 torch.Size([263, 100])\n",
            "153 torch.Size([285, 100])\n",
            "154 torch.Size([291, 100])\n",
            "155 torch.Size([121, 100])\n",
            "156 torch.Size([73, 100])\n",
            "157 torch.Size([86, 100])\n",
            "158 torch.Size([344, 100])\n",
            "159 torch.Size([143, 100])\n",
            "160 torch.Size([168, 100])\n",
            "161 torch.Size([191, 100])\n",
            "162 torch.Size([172, 100])\n",
            "163 torch.Size([622, 100])\n",
            "164 torch.Size([420, 100])\n",
            "165 torch.Size([758, 100])\n",
            "166 torch.Size([148, 100])\n",
            "167 torch.Size([138, 100])\n",
            "168 torch.Size([79, 100])\n",
            "169 torch.Size([146, 100])\n",
            "170 torch.Size([99, 100])\n",
            "171 torch.Size([49, 100])\n",
            "172 torch.Size([117, 100])\n",
            "173 torch.Size([174, 100])\n",
            "174 torch.Size([202, 100])\n",
            "175 torch.Size([274, 100])\n",
            "176 torch.Size([136, 100])\n",
            "177 torch.Size([326, 100])\n",
            "178 torch.Size([164, 100])\n",
            "179 torch.Size([181, 100])\n",
            "180 torch.Size([393, 100])\n",
            "181 torch.Size([160, 100])\n",
            "182 torch.Size([162, 100])\n",
            "183 torch.Size([353, 100])\n",
            "184 torch.Size([177, 100])\n",
            "185 torch.Size([158, 100])\n",
            "186 torch.Size([132, 100])\n",
            "187 torch.Size([920, 100])\n",
            "188 torch.Size([310, 100])\n",
            "189 torch.Size([208, 100])\n",
            "190 torch.Size([179, 100])\n",
            "191 torch.Size([279, 100])\n",
            "192 torch.Size([243, 100])\n",
            "193 torch.Size([55, 100])\n",
            "194 torch.Size([151, 100])\n",
            "195 torch.Size([504, 100])\n",
            "196 torch.Size([701, 100])\n",
            "197 torch.Size([257, 100])\n",
            "198 torch.Size([452, 100])\n",
            "199 torch.Size([140, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWW1np1P6OQg"
      },
      "source": [
        "* ミニバッチの形は、[ミニバッチ内での最大文書長, ミニバッチのサイズ]になっていることに注意！\n",
        " * ミニバッチのサイズが最初に来ているのではない！\n",
        " * [ミニバッチのサイズ, ミニバッチ内での最大文書長]という形にしたいなら、テキストのfieldを作るとき以下のようにする。\n",
        "\n",
        "__`TEXT = data.Field(tokenize=\"spacy\", batch_first=True)`__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHytOsiSUdeS"
      },
      "source": [
        "* 上記のループを抜けたあとには、変数batchには最後のミニバッチが代入されている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d78vJW616H7m",
        "outputId": "914d591f-3402-4c3b-e564-45885b50b062",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch.text.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([140, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHMHkR73VuCD"
      },
      "source": [
        "* このミニバッチに含まれる文書のうち、最初の文書の単語ID列を表示させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tZLm0hQVjZE",
        "outputId": "7d47a7b0-b5c7-429c-b6a2-5a5e72f69a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(batch.text[:, 0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  501,  3773,     2,    24,     3,    14,    56,    15,   146,    33,\n",
            "            8,   137,     4,  5846,   157,     8,  1002,     4,  1263,     7,\n",
            "           42,     8,    36,  2781,     4,    14,   741,     3,     2,     0,\n",
            "           18,   890,  1668,    74,    21,    42,     2,  1836,     0,     7,\n",
            "            5,   363,   221,    24,     3,    26,     0,    96,   434,   139,\n",
            "            2,   106,  7428,     7,     2,    24,     3,     6,    31,   253,\n",
            "           47,    31,   198,   130, 20297,     8,    45,     2, 15686,    18,\n",
            "          409,    15,    20,    72,     2,   942,    50,     0,   121,   434,\n",
            "           69,    36,  8870,    64,    41,    96,  1120,   269,     6,     5,\n",
            "         1527,  6545,   141,     4,     0,     3,   457,     3,    22,     5,\n",
            "           24,    47,    25,     0,     3,    33,     5,  5099,    17,   291,\n",
            "          221,    24,     4,    25,   953,     9,    13,     5,  4846,   103,\n",
            "          971,     6,    59,  4846,   103,   661,   158,   167,     8,   459,\n",
            "            6,   422,    54,   748,     3,    33,   730,    51,  3564,     4],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcXV1WLCdax1"
      },
      "source": [
        "* このミニバッチに含まれる文書のうち、最初の文書の単語ID列を単語列に戻したものを表示させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjaS-Mjadf63",
        "outputId": "fdf67d7b-df80-46cd-d540-4d51c59837a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(' '.join([TEXT.vocab.itos[i] for i in batch.text[:, 0]]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To quote the film , \" It 's better not to know . Better still to forget . Best of all to be abandoned . \" Oh , the <unk> /><br />A ghost story with all the technical <unk> of a Hollywood horror film , but <unk> bad dialogue after the first quarter of the film , and you feel like you 're being preached to from the start.<br /><br />It 's as if the writers ' <unk> character dialogue can be summed up by bad cop TV and a Jerry Springer show . <unk> , maybe , for a film like The <unk> , not a Russia - set horror film . The result is that a potentially great setting and some potentially great gore scenes go to waste and become just silly , not scary or meaningful .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uoslpyTgz8w"
      },
      "source": [
        "* このミニバッチに含まれる文書のうち、最後の文書の単語ID列を表示させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcdyIhK0TUac",
        "outputId": "42ca310a-3459-4015-a6d7-8d079e12e378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(batch.text[:, BATCH_SIZE-1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  155,   442,    16,    23,     5,   192,     4,    11,  1654,    16,\n",
            "         1050,   163,    33,   116,    96,     8,  1156,    43,  2736,     4,\n",
            "           56,   679,    55,     5,   616,  2481,   621,     4,   594,   158,\n",
            "           79,   716,     6,  1349,     8,    36,    48,    10,     5,    23,\n",
            "           33,  1468,     8,    36,    54,     5,   416,  2829,   238,    26,\n",
            "           21,    59,  1252,     6,  1676,  1277,     4,    56,  1035,    30,\n",
            "          245,  5874,     4,    25,   861,    32,    42,    60,    26,   295,\n",
            "            2,   262,    44,   420,     3,   108,  1084,     6,  1096,     2,\n",
            "           23,     4, 15229,   133,   125,   115,     7,   169,   175,   188,\n",
            "            3,    26,    46,    79,  1458,     6,   105,    84,   497,    53,\n",
            "           65,   598,     8,   109,    10,     2,   150,    70,     9,   684,\n",
            "            5,   192,     4,    25,   251,     9,  1135,     6,  1228,     6,\n",
            "           52,     5,  2569,   253,     8,    12,     4,    11,   119,    31,\n",
            "          492,  1260,    36,   770,     8,   129,    16,     4,     1,     1],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtDXRKPMT9KW"
      },
      "source": [
        "最後の文書の末尾は「1」で埋められていることが分かる。\n",
        "\n",
        "この1は、パディング用単語のIDだったことを想起されたい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDzk2ghCUD8N"
      },
      "source": [
        "ミニバッチに含まれる文書の長さを調べると、文書が文書長の降順に並べられていることが分かる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PutP_EU4Tca-",
        "outputId": "09edc9dc-5d67-4782-94c5-0c210a2f5d78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(batch.text != 1).sum(0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([140, 140, 140, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
              "        139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
              "        139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
              "        139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
              "        139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 138, 138, 138,\n",
              "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
              "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
              "        138, 138], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PDZlF0O6doP"
      },
      "source": [
        "## 07-02 MLPによる文書分類の準備\n",
        "* 今回は、ごく簡単なMLPで文書分類をする。\n",
        "* 文書中の全単語トークンの埋め込みベクトルの平均を、MLPの入力とする。\n",
        " * 当然、語順の情報は使われない。\n",
        " * つまり、bag-of-wordsモデルになっている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjpel2i46gbD"
      },
      "source": [
        "### 定数の設定\n",
        "* 単語埋め込みベクトルの次元数は128にする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQPXVLC66NUM",
        "outputId": "dcf81671-9ef1-4c94-f603-a68b08602faa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "NUM_CLASS = len(LABEL.vocab)\n",
        "EMBED_DIM = 128\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "print(f'語彙サイズ {INPUT_DIM}, クラス数 {NUM_CLASS}, 単語埋め込み次元 {EMBED_DIM}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "語彙サイズ 25002, クラス数 2, 単語埋め込み次元 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsuHjuNp6tvt"
      },
      "source": [
        "### モデルを定義する前にPyTorchの単語埋め込みがどんなものかを見てみる\n",
        "* 埋め込みとは、単語IDから単語ベクトルへのマッピング。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3J7TzxFVMsR"
      },
      "source": [
        "* 以下のように、語彙サイズと埋め込みの次元数を指定しつつ、torch.nn.Embeddingのインスタンスを作ればよい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP7jJVYT6tBg"
      },
      "source": [
        "embed = nn.Embedding(INPUT_DIM, EMBED_DIM, padding_idx=PAD_IDX).to(device)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUl6lR8JVWTu"
      },
      "source": [
        "* パディング用の単語の埋め込みはゼロベクトルになる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3ZCr9Ll61m8",
        "outputId": "6549fd48-9898-434f-ed24-fa8a705a1725",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(embed(torch.tensor([21,1])))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 6.8744e-02,  4.2849e-01,  2.1481e-01,  8.7952e-01, -1.7290e+00,\n",
            "         -2.2350e+00, -5.4192e-01, -1.3365e+00, -2.2437e+00,  1.9041e+00,\n",
            "          2.1003e+00,  2.1210e+00, -8.0829e-02, -8.6538e-02, -2.0858e-01,\n",
            "         -3.8659e-01,  1.2082e+00, -5.3790e-01, -7.1226e-01,  9.7439e-01,\n",
            "         -1.2953e+00,  1.4643e+00, -5.7980e-01,  1.0861e+00, -7.8486e-01,\n",
            "         -1.2188e+00, -1.7692e+00,  1.5884e+00,  2.3673e+00, -1.7137e+00,\n",
            "         -8.2795e-03,  5.4360e-01, -2.5634e-01,  1.0775e+00,  7.8097e-01,\n",
            "          1.2306e-03,  6.7369e-01,  1.8175e+00,  7.9229e-01,  1.9029e-01,\n",
            "          2.2103e+00, -2.0936e+00,  1.4660e+00, -5.3831e-01, -1.3515e+00,\n",
            "          4.0773e-01,  8.7801e-01, -1.2269e+00, -8.7526e-01,  1.6439e+00,\n",
            "          3.0164e+00,  1.0737e+00,  1.7512e+00, -1.8375e+00,  8.7735e-01,\n",
            "         -1.5085e-01,  2.1493e+00, -3.1661e-01, -1.0365e+00, -1.1609e+00,\n",
            "         -6.0594e-01, -1.3657e+00,  4.2652e-01,  3.7043e-01, -3.0607e-01,\n",
            "         -7.3270e-01, -1.6886e+00,  3.1509e-01,  2.0236e-02, -9.1919e-01,\n",
            "          7.1070e-01,  1.0090e+00, -9.7812e-01, -1.5494e+00,  1.1967e+00,\n",
            "         -1.1551e+00,  8.2954e-01, -2.9682e-01, -4.6308e-01, -6.3972e-02,\n",
            "         -1.3412e-01,  8.5298e-02,  8.1036e-01,  1.1083e+00,  7.6871e-01,\n",
            "          3.1744e-01,  1.8592e+00, -1.1116e+00,  1.3303e+00, -8.9231e-01,\n",
            "         -1.3349e+00,  6.4343e-01,  5.0710e-01, -5.9709e-01, -3.8404e-01,\n",
            "         -9.1011e-01, -1.7221e+00, -3.9928e-02,  8.1378e-01, -9.9617e-01,\n",
            "         -5.5759e-02, -5.5511e-01, -1.5183e-01,  7.9090e-01, -1.1041e+00,\n",
            "          7.0395e-01, -5.3875e-01,  1.1734e+00,  1.0209e+00,  1.4524e+00,\n",
            "         -8.2232e-01, -5.2819e-01, -7.4140e-01, -4.4835e-01, -5.1967e-01,\n",
            "         -5.4887e-01,  8.1246e-01,  2.9479e-01, -1.4988e-01,  7.3759e-01,\n",
            "         -1.9749e+00,  1.3722e+00, -4.0007e-01,  8.4267e-01,  6.3310e-01,\n",
            "         -1.4181e+00,  4.0816e-01,  7.6677e-02],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00]], grad_fn=<EmbeddingBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN0kM3urr-Il"
      },
      "source": [
        "* 埋め込みの効果を見てみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ0FqJRcr6Vo",
        "outputId": "2ca3fca1-8ea4-42b2-8999-c3e6e313bc99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "  print(i, embed(batch.text).shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([315, 100, 128])\n",
            "1 torch.Size([212, 100, 128])\n",
            "2 torch.Size([435, 100, 128])\n",
            "3 torch.Size([209, 100, 128])\n",
            "4 torch.Size([194, 100, 128])\n",
            "5 torch.Size([365, 100, 128])\n",
            "6 torch.Size([146, 100, 128])\n",
            "7 torch.Size([143, 100, 128])\n",
            "8 torch.Size([178, 100, 128])\n",
            "9 torch.Size([81, 100, 128])\n",
            "10 torch.Size([1054, 100, 128])\n",
            "11 torch.Size([165, 100, 128])\n",
            "12 torch.Size([239, 100, 128])\n",
            "13 torch.Size([191, 100, 128])\n",
            "14 torch.Size([247, 100, 128])\n",
            "15 torch.Size([2789, 100, 128])\n",
            "16 torch.Size([139, 100, 128])\n",
            "17 torch.Size([141, 100, 128])\n",
            "18 torch.Size([338, 100, 128])\n",
            "19 torch.Size([386, 100, 128])\n",
            "20 torch.Size([222, 100, 128])\n",
            "21 torch.Size([216, 100, 128])\n",
            "22 torch.Size([206, 100, 128])\n",
            "23 torch.Size([294, 100, 128])\n",
            "24 torch.Size([63, 100, 128])\n",
            "25 torch.Size([57, 100, 128])\n",
            "26 torch.Size([528, 100, 128])\n",
            "27 torch.Size([288, 100, 128])\n",
            "28 torch.Size([276, 100, 128])\n",
            "29 torch.Size([181, 100, 128])\n",
            "30 torch.Size([931, 100, 128])\n",
            "31 torch.Size([257, 100, 128])\n",
            "32 torch.Size([171, 100, 128])\n",
            "33 torch.Size([203, 100, 128])\n",
            "34 torch.Size([243, 100, 128])\n",
            "35 torch.Size([153, 100, 128])\n",
            "36 torch.Size([186, 100, 128])\n",
            "37 torch.Size([839, 100, 128])\n",
            "38 torch.Size([162, 100, 128])\n",
            "39 torch.Size([330, 100, 128])\n",
            "40 torch.Size([763, 100, 128])\n",
            "41 torch.Size([76, 100, 128])\n",
            "42 torch.Size([226, 100, 128])\n",
            "43 torch.Size([230, 100, 128])\n",
            "44 torch.Size([301, 100, 128])\n",
            "45 torch.Size([235, 100, 128])\n",
            "46 torch.Size([147, 100, 128])\n",
            "47 torch.Size([154, 100, 128])\n",
            "48 torch.Size([308, 100, 128])\n",
            "49 torch.Size([199, 100, 128])\n",
            "50 torch.Size([450, 100, 128])\n",
            "51 torch.Size([88, 100, 128])\n",
            "52 torch.Size([135, 100, 128])\n",
            "53 torch.Size([269, 100, 128])\n",
            "54 torch.Size([137, 100, 128])\n",
            "55 torch.Size([554, 100, 128])\n",
            "56 torch.Size([101, 100, 128])\n",
            "57 torch.Size([144, 100, 128])\n",
            "58 torch.Size([396, 100, 128])\n",
            "59 torch.Size([174, 100, 128])\n",
            "60 torch.Size([581, 100, 128])\n",
            "61 torch.Size([50, 100, 128])\n",
            "62 torch.Size([407, 100, 128])\n",
            "63 torch.Size([149, 100, 128])\n",
            "64 torch.Size([106, 100, 128])\n",
            "65 torch.Size([118, 100, 128])\n",
            "66 torch.Size([323, 100, 128])\n",
            "67 torch.Size([468, 100, 128])\n",
            "68 torch.Size([163, 100, 128])\n",
            "69 torch.Size([356, 100, 128])\n",
            "70 torch.Size([169, 100, 128])\n",
            "71 torch.Size([189, 100, 128])\n",
            "72 torch.Size([421, 100, 128])\n",
            "73 torch.Size([95, 100, 128])\n",
            "74 torch.Size([125, 100, 128])\n",
            "75 torch.Size([158, 100, 128])\n",
            "76 torch.Size([113, 100, 128])\n",
            "77 torch.Size([374, 100, 128])\n",
            "78 torch.Size([167, 100, 128])\n",
            "79 torch.Size([156, 100, 128])\n",
            "80 torch.Size([197, 100, 128])\n",
            "81 torch.Size([705, 100, 128])\n",
            "82 torch.Size([151, 100, 128])\n",
            "83 torch.Size([177, 100, 128])\n",
            "84 torch.Size([183, 100, 128])\n",
            "85 torch.Size([281, 100, 128])\n",
            "86 torch.Size([219, 100, 128])\n",
            "87 torch.Size([160, 100, 128])\n",
            "88 torch.Size([133, 100, 128])\n",
            "89 torch.Size([252, 100, 128])\n",
            "90 torch.Size([128, 100, 128])\n",
            "91 torch.Size([622, 100, 128])\n",
            "92 torch.Size([263, 100, 128])\n",
            "93 torch.Size([122, 100, 128])\n",
            "94 torch.Size([661, 100, 128])\n",
            "95 torch.Size([505, 100, 128])\n",
            "96 torch.Size([485, 100, 128])\n",
            "97 torch.Size([131, 100, 128])\n",
            "98 torch.Size([69, 100, 128])\n",
            "99 torch.Size([346, 100, 128])\n",
            "100 torch.Size([155, 100, 128])\n",
            "101 torch.Size([185, 100, 128])\n",
            "102 torch.Size([177, 100, 128])\n",
            "103 torch.Size([623, 100, 128])\n",
            "104 torch.Size([480, 100, 128])\n",
            "105 torch.Size([315, 100, 128])\n",
            "106 torch.Size([64, 100, 128])\n",
            "107 torch.Size([139, 100, 128])\n",
            "108 torch.Size([392, 100, 128])\n",
            "109 torch.Size([162, 100, 128])\n",
            "110 torch.Size([158, 100, 128])\n",
            "111 torch.Size([406, 100, 128])\n",
            "112 torch.Size([595, 100, 128])\n",
            "113 torch.Size([196, 100, 128])\n",
            "114 torch.Size([124, 100, 128])\n",
            "115 torch.Size([697, 100, 128])\n",
            "116 torch.Size([128, 100, 128])\n",
            "117 torch.Size([145, 100, 128])\n",
            "118 torch.Size([199, 100, 128])\n",
            "119 torch.Size([417, 100, 128])\n",
            "120 torch.Size([193, 100, 128])\n",
            "121 torch.Size([167, 100, 128])\n",
            "122 torch.Size([661, 100, 128])\n",
            "123 torch.Size([295, 100, 128])\n",
            "124 torch.Size([1063, 100, 128])\n",
            "125 torch.Size([160, 100, 128])\n",
            "126 torch.Size([229, 100, 128])\n",
            "127 torch.Size([2142, 100, 128])\n",
            "128 torch.Size([138, 100, 128])\n",
            "129 torch.Size([190, 100, 128])\n",
            "130 torch.Size([748, 100, 128])\n",
            "131 torch.Size([211, 100, 128])\n",
            "132 torch.Size([214, 100, 128])\n",
            "133 torch.Size([131, 100, 128])\n",
            "134 torch.Size([920, 100, 128])\n",
            "135 torch.Size([324, 100, 128])\n",
            "136 torch.Size([141, 100, 128])\n",
            "137 torch.Size([251, 100, 128])\n",
            "138 torch.Size([88, 100, 128])\n",
            "139 torch.Size([49, 100, 128])\n",
            "140 torch.Size([241, 100, 128])\n",
            "141 torch.Size([498, 100, 128])\n",
            "142 torch.Size([207, 100, 128])\n",
            "143 torch.Size([272, 100, 128])\n",
            "144 torch.Size([93, 100, 128])\n",
            "145 torch.Size([149, 100, 128])\n",
            "146 torch.Size([117, 100, 128])\n",
            "147 torch.Size([204, 100, 128])\n",
            "148 torch.Size([237, 100, 128])\n",
            "149 torch.Size([182, 100, 128])\n",
            "150 torch.Size([180, 100, 128])\n",
            "151 torch.Size([233, 100, 128])\n",
            "152 torch.Size([175, 100, 128])\n",
            "153 torch.Size([544, 100, 128])\n",
            "154 torch.Size([431, 100, 128])\n",
            "155 torch.Size([146, 100, 128])\n",
            "156 torch.Size([222, 100, 128])\n",
            "157 torch.Size([331, 100, 128])\n",
            "158 torch.Size([289, 100, 128])\n",
            "159 torch.Size([56, 100, 128])\n",
            "160 torch.Size([821, 100, 128])\n",
            "161 torch.Size([278, 100, 128])\n",
            "162 torch.Size([172, 100, 128])\n",
            "163 torch.Size([105, 100, 128])\n",
            "164 torch.Size([168, 100, 128])\n",
            "165 torch.Size([112, 100, 128])\n",
            "166 torch.Size([351, 100, 128])\n",
            "167 torch.Size([120, 100, 128])\n",
            "168 torch.Size([218, 100, 128])\n",
            "169 torch.Size([307, 100, 128])\n",
            "170 torch.Size([148, 100, 128])\n",
            "171 torch.Size([463, 100, 128])\n",
            "172 torch.Size([301, 100, 128])\n",
            "173 torch.Size([81, 100, 128])\n",
            "174 torch.Size([361, 100, 128])\n",
            "175 torch.Size([246, 100, 128])\n",
            "176 torch.Size([517, 100, 128])\n",
            "177 torch.Size([371, 100, 128])\n",
            "178 torch.Size([342, 100, 128])\n",
            "179 torch.Size([171, 100, 128])\n",
            "180 torch.Size([256, 100, 128])\n",
            "181 torch.Size([226, 100, 128])\n",
            "182 torch.Size([136, 100, 128])\n",
            "183 torch.Size([133, 100, 128])\n",
            "184 torch.Size([201, 100, 128])\n",
            "185 torch.Size([568, 100, 128])\n",
            "186 torch.Size([382, 100, 128])\n",
            "187 torch.Size([267, 100, 128])\n",
            "188 torch.Size([69, 100, 128])\n",
            "189 torch.Size([75, 100, 128])\n",
            "190 torch.Size([143, 100, 128])\n",
            "191 torch.Size([153, 100, 128])\n",
            "192 torch.Size([188, 100, 128])\n",
            "193 torch.Size([263, 100, 128])\n",
            "194 torch.Size([151, 100, 128])\n",
            "195 torch.Size([99, 100, 128])\n",
            "196 torch.Size([446, 100, 128])\n",
            "197 torch.Size([164, 100, 128])\n",
            "198 torch.Size([157, 100, 128])\n",
            "199 torch.Size([283, 100, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyngitc78hv"
      },
      "source": [
        "### モデルの定義\n",
        "* MLP（多層パーセプトロン）だが、入り口に単語埋め込み層が挿入されている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9asdLYng7DOu"
      },
      "source": [
        "class EmbedTextSentiment(nn.Module):\n",
        "  def __init__(self, embed_dim, num_class, vocab_size, padding_idx):\n",
        "    super(EmbedTextSentiment, self).__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
        "    self.fc1 = nn.Linear(embed_dim, 500)\n",
        "    self.fc2 = nn.Linear(500, 100)\n",
        "    self.fc3 = nn.Linear(100, num_class)\n",
        "\n",
        "  def forward(self, text):\n",
        "    x = self.embed(text)\n",
        "    x = x.mean(0) # 文書に含まれる全単語トークンの単語ベクトルの平均\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foU72cB48IO9"
      },
      "source": [
        "### モデルを作る\n",
        "* モデル（のインスタンス）をGPUに移動させている点に注意。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0BHCGAZ8F18"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX).to(device)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wylQOq8N8cqI"
      },
      "source": [
        "### 損失関数とoptimizerとschedulerを作る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw34INS78cIW"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilWLfu8Z8MzW"
      },
      "source": [
        "### 訓練用の関数\n",
        "* 最初の`model.train()`に注意。こうやって、モデルを訓練モードに設定する。\n",
        " * 例えば、dropoutを含むモデルなど、訓練時と評価時で、ふるまい方を変える必要があるときがあるため、こういうことをする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR2R4Lqh8J7n"
      },
      "source": [
        "def train(data_iterator, model, optimizer, scheduler, criterion):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  for batch in data_iterator:\n",
        "    optimizer.zero_grad()\n",
        "    text, cls = batch.text, batch.label\n",
        "    output = model(text)\n",
        "    loss = criterion(output, cls)\n",
        "    train_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_acc += (output.argmax(1) == cls).float().mean().item()\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  num_batch = len(data_iterator)\n",
        "  return train_loss / num_batch, train_acc / num_batch"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftuX8e1W8iRh"
      },
      "source": [
        "### 評価用の関数\n",
        "* 最初の`model.eval()`に注意。こうやって、モデルを評価モードに設定する。\n",
        " * 例えば、dropoutを含むモデルなど、訓練時と評価時で、ふるまい方を変える必要があるときがあるため、こういうことをする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGUnsJlq8Ue3"
      },
      "source": [
        "def test(data_iterator, model, criterion):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  for batch in data_iterator:\n",
        "    text, cls = batch.text, batch.label\n",
        "    with torch.no_grad():\n",
        "      output = model(text)\n",
        "      loss = criterion(output, cls)\n",
        "      loss += loss.item()\n",
        "      acc += (output.argmax(1) == cls).float().mean().item()\n",
        "\n",
        "  num_batch = len(data_iterator)\n",
        "  return loss / num_batch, acc / num_batch"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8o_jDAg8osP"
      },
      "source": [
        "## 07-03 分類器の訓練と検証セットでの評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJJFv4k-8mH1",
        "outputId": "3d5d5659-968f-4a2c-dea2-a0fa8da1cafa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | time in 0 minutes, 2 seconds | lr=0.009500\n",
            "\tLoss: 0.38066(train)\t|\tAcc: 82.44%(train)\n",
            "\tLoss: 0.02088(valid)\t|\tAcc: 80.12%(valid)\n",
            "Epoch 2 | time in 0 minutes, 2 seconds | lr=0.009025\n",
            "\tLoss: 0.16610(train)\t|\tAcc: 93.88%(train)\n",
            "\tLoss: 0.01925(valid)\t|\tAcc: 87.10%(valid)\n",
            "Epoch 3 | time in 0 minutes, 2 seconds | lr=0.008574\n",
            "\tLoss: 0.07470(train)\t|\tAcc: 97.33%(train)\n",
            "\tLoss: 0.01066(valid)\t|\tAcc: 87.26%(valid)\n",
            "Epoch 4 | time in 0 minutes, 2 seconds | lr=0.008145\n",
            "\tLoss: 0.04084(train)\t|\tAcc: 98.58%(train)\n",
            "\tLoss: 0.01672(valid)\t|\tAcc: 83.78%(valid)\n",
            "Epoch 5 | time in 0 minutes, 2 seconds | lr=0.007738\n",
            "\tLoss: 0.02609(train)\t|\tAcc: 99.02%(train)\n",
            "\tLoss: 0.01654(valid)\t|\tAcc: 86.76%(valid)\n",
            "Epoch 6 | time in 0 minutes, 2 seconds | lr=0.007351\n",
            "\tLoss: 0.01718(train)\t|\tAcc: 99.40%(train)\n",
            "\tLoss: 0.01959(valid)\t|\tAcc: 85.54%(valid)\n",
            "Epoch 7 | time in 0 minutes, 2 seconds | lr=0.006983\n",
            "\tLoss: 0.01117(train)\t|\tAcc: 99.62%(train)\n",
            "\tLoss: 0.01200(valid)\t|\tAcc: 83.84%(valid)\n",
            "Epoch 8 | time in 0 minutes, 2 seconds | lr=0.006634\n",
            "\tLoss: 0.01013(train)\t|\tAcc: 99.60%(train)\n",
            "\tLoss: 0.01479(valid)\t|\tAcc: 87.38%(valid)\n",
            "Epoch 9 | time in 0 minutes, 2 seconds | lr=0.006302\n",
            "\tLoss: 0.00718(train)\t|\tAcc: 99.79%(train)\n",
            "\tLoss: 0.02384(valid)\t|\tAcc: 86.12%(valid)\n",
            "Epoch 10 | time in 0 minutes, 2 seconds | lr=0.005987\n",
            "\tLoss: 0.01226(train)\t|\tAcc: 99.82%(train)\n",
            "\tLoss: 0.03174(valid)\t|\tAcc: 86.78%(valid)\n",
            "Epoch 11 | time in 0 minutes, 2 seconds | lr=0.005688\n",
            "\tLoss: 0.00749(train)\t|\tAcc: 99.73%(train)\n",
            "\tLoss: 0.02828(valid)\t|\tAcc: 87.14%(valid)\n",
            "Epoch 12 | time in 0 minutes, 2 seconds | lr=0.005404\n",
            "\tLoss: 0.00388(train)\t|\tAcc: 99.86%(train)\n",
            "\tLoss: 0.01147(valid)\t|\tAcc: 86.32%(valid)\n",
            "Epoch 13 | time in 0 minutes, 2 seconds | lr=0.005133\n",
            "\tLoss: 0.00245(train)\t|\tAcc: 99.91%(train)\n",
            "\tLoss: 0.02364(valid)\t|\tAcc: 86.68%(valid)\n",
            "Epoch 14 | time in 0 minutes, 2 seconds | lr=0.004877\n",
            "\tLoss: 0.00190(train)\t|\tAcc: 99.94%(train)\n",
            "\tLoss: 0.02197(valid)\t|\tAcc: 87.18%(valid)\n",
            "Epoch 15 | time in 0 minutes, 2 seconds | lr=0.004633\n",
            "\tLoss: 0.00052(train)\t|\tAcc: 99.99%(train)\n",
            "\tLoss: 0.03025(valid)\t|\tAcc: 87.48%(valid)\n",
            "Epoch 16 | time in 0 minutes, 2 seconds | lr=0.004401\n",
            "\tLoss: 0.00003(train)\t|\tAcc: 100.00%(train)\n",
            "\tLoss: 0.01226(valid)\t|\tAcc: 87.26%(valid)\n",
            "Epoch 17 | time in 0 minutes, 2 seconds | lr=0.004181\n",
            "\tLoss: 0.00001(train)\t|\tAcc: 100.00%(train)\n",
            "\tLoss: 0.02268(valid)\t|\tAcc: 87.28%(valid)\n",
            "Epoch 18 | time in 0 minutes, 2 seconds | lr=0.003972\n",
            "\tLoss: 0.00001(train)\t|\tAcc: 100.00%(train)\n",
            "\tLoss: 0.02329(valid)\t|\tAcc: 87.30%(valid)\n",
            "Epoch 19 | time in 0 minutes, 2 seconds | lr=0.003774\n",
            "\tLoss: 0.00001(train)\t|\tAcc: 100.00%(train)\n",
            "\tLoss: 0.02925(valid)\t|\tAcc: 87.24%(valid)\n",
            "Epoch 20 | time in 0 minutes, 2 seconds | lr=0.003585\n",
            "\tLoss: 0.00001(train)\t|\tAcc: 100.00%(train)\n",
            "\tLoss: 0.02396(valid)\t|\tAcc: 87.18%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPux8PReWTXG"
      },
      "source": [
        "## 07-04 再検討\n",
        "* 訓練データ上での分類精度がほぼ100%になってしまっている。\n",
        "* 検証データでの分類精度と大きな差があり、明らかにオーバーフィッティング。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23jMgtmoWkty"
      },
      "source": [
        "### ドロップアウトを使う\n",
        "* モデルのインスタンスを作るときにdropoutの確率を引数pで指定できるようにする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khps3ZuBWntq"
      },
      "source": [
        "class EmbedTextSentiment(nn.Module):\n",
        "  def __init__(self, embed_dim, num_class, vocab_size, padding_idx, p=0.0):\n",
        "    super(EmbedTextSentiment, self).__init__()\n",
        "    self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
        "    self.dropout = nn.Dropout(p=p)\n",
        "    self.fc1 = nn.Linear(embed_dim, 500)\n",
        "    self.fc2 = nn.Linear(500, 100)\n",
        "    self.fc3 = nn.Linear(100, num_class)\n",
        "\n",
        "  def forward(self, text):\n",
        "    x = self.dropout(self.embed(text)) #埋め込み層の直後にdropout\n",
        "    x = x.mean(0)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVXbkt6qXxNt"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXkBDXc6X1mp"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu3Y-wjwb0po"
      },
      "source": [
        "### L２正則化を使う\n",
        "* optimizerのweight_decayパラメータを0より大きな値にする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmxEuSFJazCJ"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0Zr2S7ga3J4"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIHA64UTdmBj"
      },
      "source": [
        "### early stopping\n",
        "* dev setでのaccuracyが4回連続で最高値を下回ったら訓練を終えることにする。\n",
        "* early stoppingの実現については、PyTorch Lightningを使う手もある。\n",
        " * https://pytorch-lightning.readthedocs.io/en/latest/early_stopping.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0zclQnVdlVZ"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3E_I5sRc3FF"
      },
      "source": [
        "patience = 4\n",
        "early_stop_count = 0\n",
        "best_valid_acc = 0.0\n",
        "\n",
        "MIN_N_EPOCHS = 10 # 最低このエポック数は実行する\n",
        "N_EPOCHS = 50 # エポック数を増やしておく\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')\n",
        "\n",
        "  # early stopping\n",
        "  if epoch + 1 > MIN_N_EPOCHS:\n",
        "    if best_valid_acc <= valid_acc:\n",
        "      best_valid_acc = valid_acc\n",
        "      early_stop_count = 0\n",
        "    else:\n",
        "      early_stop_count += 1\n",
        "      if early_stop_count == patience:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRvkncN09MKk"
      },
      "source": [
        "## 07-05 テストセット上で評価\n",
        "* 見つけ出したベストな設定を使って、テストセット上での最終的な評価をおこなう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_gHj4x38y8h"
      },
      "source": [
        "print('Checking the results of test dataset...')\n",
        "test_loss, test_acc = test(test_iterator, model, criterion)\n",
        "print(f'\\tLoss: {test_loss:.5f}(test)\\t|\\tAcc: {test_acc * 100:.2f}%(test)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1M_VQ1xhcWq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}