{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_document_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOseP2iX9ENI9isDfpwMeSd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/07_document_classification_20201219.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_0ZZ8bo1mgH"
      },
      "source": [
        "# 07 単語埋め込みを使った文書分類\n",
        "* 今回も、IMDbデータセットの感情分析を文書分類問題として解く。\n",
        "* ただし今回は、fastTextのような学習済みの単語埋め込みは使わない。\n",
        "* 単語埋め込み自体の学習も、ネットワークの学習と同時におこなう。\n",
        "* IMDbデータの準備も、`torch.torchtext`を使っておこなう。\n",
        " * つまりすべてをPyTorchのなかでおこなう。\n",
        "* 参考資料\n",
        " * https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
        " * https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb\n",
        " * https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyjU004LNbMt"
      },
      "source": [
        "## データをどう扱うか\n",
        "* ネットワークへの入力は、単語埋め込みを、単語の出現順どおりに並べた列にする。\n",
        " * ミニバッチは[ミニバッチのなかでの最大文書長, ミニバッチのサイズ, 単語埋め込み次元数]という形の3階のテンソルになる。\n",
        "* そして、前向き計算のなかではじめて、単語埋め込みの平均をとることにする。\n",
        " * `.mean(0)`と、軸0で平均をとることになる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_puYg6Zi8x3"
      },
      "source": [
        "## 07-00 Google Colabのランタイムのタイプを変更する\n",
        "* Google ColabのランタイムのタイプをGPUに変更しておこう。\n",
        " * 上のメニューの「ランタイム」→「ランタイムのタイプを変更」→「ハードウェア　アクセラレータ」から「GPU」を選択"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLEeO0fw23Xp"
      },
      "source": [
        "## 07-01 torchtextを使ってIMDbデータを読み込む\n",
        "* ここでIMDbデータセットの読み込みにつかう`torchtext.datasets`については、下記を参照。\n",
        " * https://torchtext.readthedocs.io/en/latest/datasets.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go7epLZe3JmF"
      },
      "source": [
        "### 実験の再現性確保のための設定など\n",
        "* https://pytorch.org/docs/stable/notes/randomness.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nSqNzof1lTJ"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.data import Field, LabelField, BucketIterator\n",
        "\n",
        "SEED = 123\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.set_deterministic(True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y1_GyXg22f6"
      },
      "source": [
        "### torchtextのフィールド\n",
        "* TEXTフィールドと、LABELフィールドという２種類のFieldオブジェクトのインスタンスを作る。\n",
        " * Fieldクラスの詳細については[ここ](https://github.com/pytorch/text/blob/master/torchtext/data/field.py)を参照。\n",
        "* TEXTフィールドは、テキストの前処理の仕方を決めておくのに使う。\n",
        " * tokenizerは、デフォルトでは単にstring型のsplitメソッドを適用するだけになる。これは高速だが、tokenizationとしては雑。\n",
        "* LABELフィールドは、ラベルの前処理に使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjq8oooE2uQY"
      },
      "source": [
        "TEXT = Field(tokenize=\"spacy\")\n",
        "LABEL = LabelField()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtEq23GS3Vxl"
      },
      "source": [
        "### IMDbデータセットをダウンロードした後、前処理しつつ読み込む\n",
        "* ダウンロードはすぐ終わるが、解凍に少し時間がかかる。\n",
        "* また、TEXTフィールドでspaCyのtokenizationを使うように設定したので、少し時間がかかる。\n",
        " * string型のsplitメソッドでtokenizeすると、時間はあまりかからない。（そのかわり、やや雑なtokenizationになる。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzgVXf3G3YPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f6bae8-d0d0-4929-8874-151832e32ae3"
      },
      "source": [
        "train_valid_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 23.2MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0sltPjT3j36"
      },
      "source": [
        "### 最初の文書を見てみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrXwYMVH3orf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2954d89-3907-4d00-99d6-f289e84e5fa1"
      },
      "source": [
        "print(train_valid_data[0].text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Not', 'sure', 'one', 'can', 'call', 'this', 'an', 'anti', '-', 'war', 'film', ',', 'it', 'shows', 'war', 'at', 'an', 'elite', 'level', '.', 'These', 'are', 'elite', 'troops', 'that', 'know', 'what', 'they', 'are', 'doing', 'and', 'take', 'great', 'pride', 'in', 'it', '.', 'Even', 'when', 'they', 'are', 'pacifist', ',', 'they', 'still', 'enjoy', 'the', 'skill', 'level', 'and', 'defeating', 'their', 'foes', ',', 'even', 'if', 'it', 'does', 'go', 'against', 'being', 'a', 'pacifist', '.', 'The', 'movies', 'is', 'slow', 'and', 'rather', 'uneventful', 'and', 'in', 'many', 'ways', 'is', 'rather', 'tame', 'as', 'war', 'movies', 'go', '-', 'more', 'so', 'by', 'todays', 'standards', ',', 'no', 'body', 'parts', 'flying', 'off', 'as', 'in', 'modern', 'movies', '.', 'It', 'is', 'brutal', 'in', 'other', 'ways', 'though', 'as', 'you', 'see', 'killing', 'at', 'a', 'personal', 'level', '.', 'This', 'is', 'more', 'of', 'a', 'thinking', 'man', \"'s\", 'movie', '.', 'Once', 'you', 'start', 'to', 'watch', 'you', 'do', \"n't\", 'want', 'to', 'miss', 'anything', '.', 'The', 'thoughts', 'of', 'the', 'men', 'in', 'the', 'movie', 'and', 'their', 'interactions', ',', 'is', 'what', 'the', 'movie', 'is', 'about-', 'not', 'the', 'combat', 'itself', 'or', 'a', 'big', 'exciting', 'storyline', '.', 'This', 'maybe', 'called', 'a', 'war', 'triller.<br', '/><br', '/>If', 'you', 'are', 'into', 'the', 'skill', 'of', 'war', ',', 'if', 'you', 'are', 'into', 'reading', 'or', 'seeing', 'programs', 'about', 'the', 'SAS', 'and', 'so', 'on', ',', 'YOU', 'WANT', 'TO', 'WATCH', 'THIS', 'MOVIE!!!!!<br', '/><br', '/>Comparable', 'movies', 'are', 'The', 'Hill', '(', '1965', ')', 'with', 'Sean', 'Connery', ',', '49th', 'Parallel', '(', '1941', ')', 'with', 'an', 'all', 'star', 'cast', ',', 'The', 'Naked', 'and', 'the', 'Dead', '(', '1958', ')', 'with', 'Cliff', 'Robertson', '.', 'All', 'are', 'unusual', 'in', 'their', 'way', 'and', 'show', 'war', 'at', 'a', 'personal', 'level', '.', 'Enjoy', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRMuAOum3rB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8f54a2-fb21-403c-d2f3-af8d955f55e7"
      },
      "source": [
        "print(train_valid_data[0].label)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgZgQbyD3u9D"
      },
      "source": [
        "### テストセット以外の部分を訓練データと検証データに分ける"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2FtnEKZ32hM"
      },
      "source": [
        "train_data, valid_data = train_valid_data.split(split_ratio=0.8)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fzsi9ZC36eR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f00aaa-a794-47a7-a60c-60fa51b1540a"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsLNP7pGaNtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f2e0ec-3b55-4788-e125-73535256d878"
      },
      "source": [
        "print(train_data[0].text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ahh', ',', 'yes', ',', 'the', 'all', '-', 'star', 'blockbuster', '.', 'Take', 'a', 'so', '-', 'so', 'concept', ',', 'stuff', 'it', 'into', 'a', 'script', 'and', 'load', 'it', 'down', 'with', 'every', 'single', 'freakin', \"'\", 'special', 'effect', 'that', 'the', 'Wizards', 'of', 'Hollyweird', 'can', 'conjure', 'up', ',', 'then', 'round', 'up', 'the', 'usual', 'suspects', ':', 'hot', 'up', '-', 'and', '-', 'comers', ',', 'has', '-', 'beens', ',', 'wanna', '-', 'be', \"'s\", 'and', 'never', '-', 'wuzzes', ',', 'and', 'stick', \"'em\", 'all', 'in', 'ensemble', 'roles', 'of', 'various', 'sizes', 'in', 'front', 'of', 'the', 'unforgiving', 'eye', 'of', 'the', 'cameras', '.', 'And', 'hope', 'to', 'gawd', 'that', 'some', 'of', 'them', 'are', \"n't\", 'too', 'old', 'to', 'remember', 'their', 'lines.<br', '/><br', '/>Leave', 'it', 'to', 'the', 'bishops', 'of', 'Box', 'Office', 'to', 'apply', 'the', 'concept', 'to', 'horror', 'films', 'at', 'last', ',', 'as', 'was', 'the', 'case', 'with', 'the', 'post', '-', 'EXORCIST', 'thriller', 'THE', 'SENTINEL', '.', 'Novelist', 'Jeffrey', 'Konvitz', 'decided', 'to', 'try', 'and', 'one', '-', 'up', 'Ira', 'Levin', \"'s\", 'ROSEMARY', \"'S\", 'BABY', 'scenario', 'of', 'creepy', '(', 'and', 'ultimately', 'satanic', ')', 'neighbors', 'in', 'a', 'New', 'York', 'brownstone', '.', 'The', 'result', 'was', 'a', 'controversial', 'best', '-', 'seller', 'that', 'some', 'claimed', 'bordered', 'on', 'the', 'plagiaristic', ',', 'and', 'an', 'equally', 'controversial', ',', 'top', '-', 'heavy', '/', 'star', '-', 'laden', 'vehicle', 'co', '-', 'written', 'and', 'directed', 'by', 'DEATH', 'WISH', \"'s\", 'Michael', 'Winner', ',', 'but', 'for', 'many', 'unsettlingly', 'different', 'reasons.<br', '/><br', '/>Cristina', 'Raines', '(', 'NASHVILLE', ')', 'plays', 'successful', 'model', 'Alison', 'Parker', ',', 'who', 'is', 'pretty', 'much', 'over-', 'stressed', 'and', 'over', '-', 'worked', ',', '(', 'I', 'wo', \"n't\", 'add', '\"', 'overpaid', '.', '\"', 'I', 'mean', 'she', 'IS', 'a', 'model', ',', 'so', 'that', 'would', 'be', 'redundant', ')', ',', 'not', 'just', 'by', 'her', '24/7', 'schedule', ',', 'by', 'also', 'by', 'her', 'insistent', ',', \"'\", 'wanna', '-', 'get', '-', 'married-', 'right', '-', 'NOW', \"'\", 'boyfriend', 'Michael', '(', 'Chris', 'Sarandon', 'of', 'DOG', 'DAY', 'AFTERNOON', 'and', 'the', 'classic', 'SOB.I.G.', 'movie', 'LIPSTICK', ')', '.', 'One', 'of', 'the', 'ways', 'she', 'decides', 'to', 'try', 'to', 'get', 'away', 'from', 'it', 'all', 'is', 'to', 'move', 'into', 'her', 'own', 'place', ';', 'a', 'big', ',', 'beautiful', 'brownstone', 'in', 'Manhattan', 'which', 'she', \"'s\", 'able', 'to', 'get', 'dirt', '-', 'cheap', ',', '(', 'that', 'should', \"'ve\", 'been', 'the', 'BIG', 'red', 'flag', '-', 'cheap', 'real', 'estate', 'in', 'New', 'York', '!', ')', ',', 'from', 'the', 'mysteriously', 'accommodating', 'broker', 'Miss', 'Logan', '(', 'Golden', 'Age', 'screen', 'vet', 'Ava', 'Gardner', ',', 'fresh', 'from', 'the', 'storm', 'drain', 'in', 'EARTHQUAKE.)<br', '/><br', '/>Things', 'seem', 'fine', 'at', 'first', ',', 'but', 'ah', ',', 'yes', '...', 'then', 'comes', 'the', 'noises', 'and', 'the', 'loud', 'pounding', 'from', 'the', 'apartment', 'upstairs', 'at', 'night', '.', 'And', 'what', 'about', 'the', 'REALLY', 'strange', 'neighbors', 'like', 'Gerde', '(', 'Sylvia', 'Miles', ')', 'and', 'Sandra', '(', 'a', 'VERY', 'early', 'Beverly', \"D'Angelo\", ')', ',', 'the', 'nice', '\"', 'single', 'friends', '\"', '(', 'read', ':', 'lesbians', ')', 'living', 'together', ',', 'and', 'kindly', 'old', 'Mr.', 'Charles', 'Chazen', '(', 'a', 'nicely', 'creepy', 'Burgess', 'Meredith', ')', ',', 'who', 'seems', 'maybe', 'a', 'little', 'too', 'concerned', 'with', 'Alison', \"'s\", 'welfare', '?', 'And', 'that', \"'s\", 'not', 'to', 'mention', 'other', 'assorted', 'squirrelly', 'cohabitants', '(', 'You', \"'ll\", 'never', 'hear', 'the', 'phrase', '\"', 'Black', 'and', 'white', 'cat', ',', 'black', 'and', 'white', 'cake', '\"', 'again', 'without', 'wanting', 'to', 'laugh', 'milk', 'through', 'your', 'nose', 'and', 'possibly', 'vomit', 'simultaneously', '.', ')', 'Especially', 'the', 'old', 'blind', 'priest', 'living', 'in', 'the', 'penthouse', '...', '<br', '/><br', '/>Things', 'really', 'start', 'to', 'go', 'downhill', 'when', 'an', 'apparition', '-', 'laden', 'nightmare', 'of', 'Alison', \"'s\", 'morphs', 'into', 'a', 'grisly', 'murder', ',', '(', 'in', 'one', 'of', 'the', 'movie', \"'s\", 'most', 'underwear', '-', 'staining', 'scares', ')', ',', 'and', 'both', 'Alison', 'and', 'Michael', ',', 'with', 'some', 'assistance', 'from', 'Alison', \"'s\", 'BFF', ',', 'Jennifer', '(', 'Deborah', 'Raffin', ')', ',', 'begin', 'to', 'piece', 'together', 'the', 'puzzle', 'that', 'reveals', 'the', 'brownstone', \"'s\", 'dark', 'origins', ',', 'as', 'well', 'as', 'the', 'murderous', 'agenda', 'of', 'its', 'other', '-', 'worldly', 'inhabitants', ',', 'not', 'to', 'mention', 'Alison', \"'s\", 'connection', 'to', 'them', ',', 'which', 'as', 'it', 'turns', 'out', 'is', 'anything', 'but', 'coincidental.<br', '/><br', '/>Although', 'there', \"'s\", 'nothing', 'controversial', 'about', 'the', 'overstuffed', 'cast', ',', 'which', 'seems', 'to', 'feature', 'every', 'actor', 'of', 'diverse', 'genres', 'looking', 'for', 'work', 'at', 'the', 'time', ',', '(', 'Arthur', 'Kennedy', ',', 'Jose', 'Ferrer', ',', 'Martin', 'Balsam', ',', 'Eli', 'Wallach', ',', 'John', 'Carradine', ',', 'and', 'even', 'early', 'appearances', 'by', 'Christopher', 'Walken', ',', 'Jeff', 'Goldblum', 'and', 'Nana', 'Visitor', '!', ')', 'Winner', 'and', 'company', 'went', 'back', 'to', 'bombastic', 'basics', 'and', 'pulled', 'a', '\"', 'Tod', 'Browning\"', '...', 'by', 'enlisting', 'real', '-', 'life', 'physically', '-', 'challenged', 'actors', 'to', 'appear', 'in', 'THE', 'SENTINEL', \"'S\", 'climactic', 'everything', '-', 'and', '-', 'everybody', '-', 'goes', '-', 'to', '-', 'Hell', 'sequence', ',', 'which', 'I', 'guess', 'any', 'ballsy', 'director', 'would', 'do', ',', 'finding', 'himself', 'unable', 'to', 'access', 'Linda', 'Blair', 'and', 'a', 'case', 'of', 'green', '-', 'pea', 'soup', '.', 'It', 'does', 'definitely', 'leave', 'you', 'with', 'arctic', 'fingers', 'playing', 'your', 'spinal', 'cord', 'like', 'a', 'zither', ',', 'knowing', 'this', 'juicy', 'little', 'tidbit', 'of', 'info', 'as', 'you', 'watch', '.', 'And', 'it', 'does', 'feature', 'a', 'technique', 'to', 'which', 'filmmakers', 'have', 'only', 'begun', 'to', 'return', 'very', 'recently', ':', 'live', 'on', '-', 'set', 'makeup', 'and', 'special', 'effects', 'that', 'do', \"n't\", 'involve', 'CGI', ',', '(', 'which', 'was', 'pretty', 'much', 'non', '-', 'existent', 'back', 'then.)<br', '/><br', '/>THE', 'SENTINEL', 'has', 'that', 'kitschy', ',', 'late', '-', 'Seventies', 'cheese', 'factor', ',', 'but', 'does', 'manage', 'to', 'distinguish', 'itself', 'from', 'time', 'to', 'time', 'with', 'some', 'gasp', '-', 'inducing', 'moments', 'like', 'the', 'one', 'mentioned', 'above', ',', 'not', 'to', 'mention', 'that', 'queasy', 'feeling', 'of', 'dread', 'that', 'horror', 'writers', 'find', 'it', 'easy', 'to', 'play', 'upon', ',', 'of', 'isolation', 'and', 'things', 'that', 'go', 'bump', '-', 'and', '-', 'shriek', 'in', 'the', 'night', '.', 'After', 'all', ',', 'what', 'living', '-', 'single', '-', 'in-', 'the', '-', 'big', '-', 'city', 'person', 'has', \"n't\", 'lain', 'in', 'bed', 'in', 'the', 'dark', ',', 'and', 'listened', 'intently', 'to', 'the', 'sounds', 'of', 'what', 'they', 'HOPE', 'is', '\"', 'the', 'building', 'settling?\"<br', '/><br', '/>Konvitz', 'followed', 'up', 'THE', 'SENTINEL', 'with', 'an', 'inevitable', 'sequel', ',', 'THE', 'GUARDIAN', '(', 'not', 'to', 'be', 'confused', 'with', 'the', 'William', 'Friedkin', 'supernatural', 'thriller', 'namesake', ')', ',', 'that', 'was', 'never', 'adapted', 'for', 'the', 'screen', '.', '=', 'sigh', 'of', 'relief=']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oXz2lvB37Vm"
      },
      "source": [
        "### データセットの語彙とラベルを作る\n",
        "* TEXTラベルのほうでは、最大語彙サイズを指定する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBQeD7yC37x4"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000 # この値は適当。\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iv6RSh3HmLf"
      },
      "source": [
        "なぜ語彙サイズが25,000ではなく25,002なのかについては、少し下の説明を参照。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWuYQthC4Ml8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df6b1579-ce16-474e-c847-a00d49777d53"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW4eR-K44Rba"
      },
      "source": [
        "### 出現頻度順で上位２０単語を見てみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jan98ffr4PXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89114cd-c26b-4d03-9d70-70d6ab4a67a0"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 231967), (',', 220822), ('.', 189768), ('a', 125308), ('and', 125211), ('of', 115201), ('to', 107546), ('is', 87468), ('in', 70357), ('I', 62046), ('it', 61426), ('that', 56383), ('\"', 50715), (\"'s\", 49689), ('this', 48354), ('-', 42279), ('/><br', 40939), ('was', 40261), ('as', 34887), ('with', 34271)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKQojOuv4Z38"
      },
      "source": [
        "### 単語ID順に最初の１０単語を見てみる\n",
        "* IDのうち、0と1は、未知語とパディング用の単語という特殊な単語に割り振られている。\n",
        " * 未知語は`<unk>`という特殊な単語に置き換えられる。これのIDが0。\n",
        " * パディングとは、長さが不揃いの複数の文書を同じミニバッチにまとめるとき、すべての文書の長さを無理やりそろえるため、文書末尾に特殊な単語（元々の語彙にない、人工的に用意した単語）を追加すること。\n",
        " * パディング用の単語が`<pad>`になっているのは、上のほうで使ったFieldクラスのインスタンスを作るときのデフォルトの値がこの`<pad>`になっているため。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlhXRT3g4Xad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "213b6de8-b2f1-479f-f241-edf711760b90"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vJfHTdR4qd4"
      },
      "source": [
        "### ラベルのほうのIDを確認する\n",
        "* こちらはnegとposに対応する２つのIDしかない。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI7Pz_6R4bYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f013d10-164d-437b-924e-187bc4b5210b"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fb4e9e62ea0>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14_znTjp4w5s"
      },
      "source": [
        "### ミニバッチを取り出すためのiteratorを作る\n",
        "* ミニバッチのサイズを指定する。\n",
        " * ミニバッチのサイズは、性能を出すためにチューニングすべきハイパーパラメータのひとつ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUED86Jb4tUy"
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator = BucketIterator(train_data, batch_size=BATCH_SIZE, device=device,\n",
        "                                     sort_within_batch=True, shuffle=True, sort_key=lambda x: len(x.text))\n",
        "valid_iterator = BucketIterator(valid_data, batch_size=BATCH_SIZE, device=device)\n",
        "test_iterator = BucketIterator(test_data, batch_size=BATCH_SIZE, device=device)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a45QA7ncg_Qv"
      },
      "source": [
        "### ミニバッチの中身を確認する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAW9Ec5q6BQO"
      },
      "source": [
        "* 訓練データのiteratorを回してミニバッチをすべて取得してみる\n",
        " * ミニバッチのshapeを表示してみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpn4tfWl42kY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e11c70-9483-418f-fbf4-42dd19c320a2"
      },
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "  print(i, batch.text.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([133, 100])\n",
            "1 torch.Size([455, 100])\n",
            "2 torch.Size([251, 100])\n",
            "3 torch.Size([213, 100])\n",
            "4 torch.Size([106, 100])\n",
            "5 torch.Size([381, 100])\n",
            "6 torch.Size([94, 100])\n",
            "7 torch.Size([187, 100])\n",
            "8 torch.Size([289, 100])\n",
            "9 torch.Size([113, 100])\n",
            "10 torch.Size([49, 100])\n",
            "11 torch.Size([536, 100])\n",
            "12 torch.Size([189, 100])\n",
            "13 torch.Size([162, 100])\n",
            "14 torch.Size([228, 100])\n",
            "15 torch.Size([135, 100])\n",
            "16 torch.Size([390, 100])\n",
            "17 torch.Size([834, 100])\n",
            "18 torch.Size([182, 100])\n",
            "19 torch.Size([170, 100])\n",
            "20 torch.Size([245, 100])\n",
            "21 torch.Size([934, 100])\n",
            "22 torch.Size([1070, 100])\n",
            "23 torch.Size([70, 100])\n",
            "24 torch.Size([303, 100])\n",
            "25 torch.Size([271, 100])\n",
            "26 torch.Size([332, 100])\n",
            "27 torch.Size([218, 100])\n",
            "28 torch.Size([623, 100])\n",
            "29 torch.Size([128, 100])\n",
            "30 torch.Size([277, 100])\n",
            "31 torch.Size([225, 100])\n",
            "32 torch.Size([155, 100])\n",
            "33 torch.Size([473, 100])\n",
            "34 torch.Size([64, 100])\n",
            "35 torch.Size([175, 100])\n",
            "36 torch.Size([403, 100])\n",
            "37 torch.Size([439, 100])\n",
            "38 torch.Size([121, 100])\n",
            "39 torch.Size([707, 100])\n",
            "40 torch.Size([413, 100])\n",
            "41 torch.Size([200, 100])\n",
            "42 torch.Size([166, 100])\n",
            "43 torch.Size([159, 100])\n",
            "44 torch.Size([350, 100])\n",
            "45 torch.Size([590, 100])\n",
            "46 torch.Size([426, 100])\n",
            "47 torch.Size([266, 100])\n",
            "48 torch.Size([146, 100])\n",
            "49 torch.Size([56, 100])\n",
            "50 torch.Size([100, 100])\n",
            "51 torch.Size([143, 100])\n",
            "52 torch.Size([296, 100])\n",
            "53 torch.Size([149, 100])\n",
            "54 torch.Size([261, 100])\n",
            "55 torch.Size([161, 100])\n",
            "56 torch.Size([256, 100])\n",
            "57 torch.Size([370, 100])\n",
            "58 torch.Size([179, 100])\n",
            "59 torch.Size([118, 100])\n",
            "60 torch.Size([494, 100])\n",
            "61 torch.Size([164, 100])\n",
            "62 torch.Size([184, 100])\n",
            "63 torch.Size([207, 100])\n",
            "64 torch.Size([761, 100])\n",
            "65 torch.Size([210, 100])\n",
            "66 torch.Size([177, 100])\n",
            "67 torch.Size([153, 100])\n",
            "68 torch.Size([237, 100])\n",
            "69 torch.Size([282, 100])\n",
            "70 torch.Size([661, 100])\n",
            "71 torch.Size([141, 100])\n",
            "72 torch.Size([233, 100])\n",
            "73 torch.Size([157, 100])\n",
            "74 torch.Size([241, 100])\n",
            "75 torch.Size([203, 100])\n",
            "76 torch.Size([361, 100])\n",
            "77 torch.Size([342, 100])\n",
            "78 torch.Size([151, 100])\n",
            "79 torch.Size([317, 100])\n",
            "80 torch.Size([168, 100])\n",
            "81 torch.Size([76, 100])\n",
            "82 torch.Size([197, 100])\n",
            "83 torch.Size([82, 100])\n",
            "84 torch.Size([221, 100])\n",
            "85 torch.Size([88, 100])\n",
            "86 torch.Size([148, 100])\n",
            "87 torch.Size([131, 100])\n",
            "88 torch.Size([2789, 100])\n",
            "89 torch.Size([561, 100])\n",
            "90 torch.Size([144, 100])\n",
            "91 torch.Size([137, 100])\n",
            "92 torch.Size([139, 100])\n",
            "93 torch.Size([172, 100])\n",
            "94 torch.Size([195, 100])\n",
            "95 torch.Size([125, 100])\n",
            "96 torch.Size([324, 100])\n",
            "97 torch.Size([310, 100])\n",
            "98 torch.Size([513, 100])\n",
            "99 torch.Size([192, 100])\n",
            "100 torch.Size([239, 100])\n",
            "101 torch.Size([199, 100])\n",
            "102 torch.Size([222, 100])\n",
            "103 torch.Size([230, 100])\n",
            "104 torch.Size([106, 100])\n",
            "105 torch.Size([133, 100])\n",
            "106 torch.Size([152, 100])\n",
            "107 torch.Size([219, 100])\n",
            "108 torch.Size([560, 100])\n",
            "109 torch.Size([113, 100])\n",
            "110 torch.Size([188, 100])\n",
            "111 torch.Size([226, 100])\n",
            "112 torch.Size([389, 100])\n",
            "113 torch.Size([186, 100])\n",
            "114 torch.Size([268, 100])\n",
            "115 torch.Size([156, 100])\n",
            "116 torch.Size([321, 100])\n",
            "117 torch.Size([141, 100])\n",
            "118 torch.Size([154, 100])\n",
            "119 torch.Size([252, 100])\n",
            "120 torch.Size([1062, 100])\n",
            "121 torch.Size([193, 100])\n",
            "122 torch.Size([536, 100])\n",
            "123 torch.Size([661, 100])\n",
            "124 torch.Size([247, 100])\n",
            "125 torch.Size([169, 100])\n",
            "126 torch.Size([305, 100])\n",
            "127 torch.Size([1646, 100])\n",
            "128 torch.Size([586, 100])\n",
            "129 torch.Size([144, 100])\n",
            "130 torch.Size([338, 100])\n",
            "131 torch.Size([149, 100])\n",
            "132 torch.Size([413, 100])\n",
            "133 torch.Size([212, 100])\n",
            "134 torch.Size([477, 100])\n",
            "135 torch.Size([95, 100])\n",
            "136 torch.Size([165, 100])\n",
            "137 torch.Size([63, 100])\n",
            "138 torch.Size([183, 100])\n",
            "139 torch.Size([205, 100])\n",
            "140 torch.Size([811, 100])\n",
            "141 torch.Size([196, 100])\n",
            "142 torch.Size([298, 100])\n",
            "143 torch.Size([215, 100])\n",
            "144 torch.Size([69, 100])\n",
            "145 torch.Size([494, 100])\n",
            "146 torch.Size([443, 100])\n",
            "147 torch.Size([377, 100])\n",
            "148 torch.Size([367, 100])\n",
            "149 torch.Size([124, 100])\n",
            "150 torch.Size([235, 100])\n",
            "151 torch.Size([128, 100])\n",
            "152 torch.Size([263, 100])\n",
            "153 torch.Size([286, 100])\n",
            "154 torch.Size([292, 100])\n",
            "155 torch.Size([122, 100])\n",
            "156 torch.Size([75, 100])\n",
            "157 torch.Size([87, 100])\n",
            "158 torch.Size([347, 100])\n",
            "159 torch.Size([142, 100])\n",
            "160 torch.Size([167, 100])\n",
            "161 torch.Size([191, 100])\n",
            "162 torch.Size([171, 100])\n",
            "163 torch.Size([622, 100])\n",
            "164 torch.Size([426, 100])\n",
            "165 torch.Size([744, 100])\n",
            "166 torch.Size([147, 100])\n",
            "167 torch.Size([137, 100])\n",
            "168 torch.Size([81, 100])\n",
            "169 torch.Size([146, 100])\n",
            "170 torch.Size([101, 100])\n",
            "171 torch.Size([50, 100])\n",
            "172 torch.Size([118, 100])\n",
            "173 torch.Size([174, 100])\n",
            "174 torch.Size([202, 100])\n",
            "175 torch.Size([274, 100])\n",
            "176 torch.Size([135, 100])\n",
            "177 torch.Size([329, 100])\n",
            "178 torch.Size([163, 100])\n",
            "179 torch.Size([181, 100])\n",
            "180 torch.Size([399, 100])\n",
            "181 torch.Size([159, 100])\n",
            "182 torch.Size([161, 100])\n",
            "183 torch.Size([358, 100])\n",
            "184 torch.Size([176, 100])\n",
            "185 torch.Size([158, 100])\n",
            "186 torch.Size([131, 100])\n",
            "187 torch.Size([897, 100])\n",
            "188 torch.Size([312, 100])\n",
            "189 torch.Size([209, 100])\n",
            "190 torch.Size([178, 100])\n",
            "191 torch.Size([280, 100])\n",
            "192 torch.Size([242, 100])\n",
            "193 torch.Size([56, 100])\n",
            "194 torch.Size([150, 100])\n",
            "195 torch.Size([512, 100])\n",
            "196 torch.Size([696, 100])\n",
            "197 torch.Size([258, 100])\n",
            "198 torch.Size([462, 100])\n",
            "199 torch.Size([139, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWW1np1P6OQg"
      },
      "source": [
        "* ミニバッチの形は、[ミニバッチ内での最大文書長, ミニバッチのサイズ]になっていることに注意！\n",
        " * ミニバッチのサイズが最初に来ているのではない！\n",
        " * [ミニバッチのサイズ, ミニバッチ内での最大文書長]という形にしたいなら、テキストのfieldを作るとき以下のようにする。\n",
        "\n",
        "__`TEXT = data.Field(tokenize=\"spacy\", batch_first=True)`__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHytOsiSUdeS"
      },
      "source": [
        "* 上記のループを抜けたあとには、変数batchには最後のミニバッチが代入されている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d78vJW616H7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c283572b-ef0e-4f97-a036-1b9c504f6ab4"
      },
      "source": [
        "batch.text.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([139, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHMHkR73VuCD"
      },
      "source": [
        "* このミニバッチに含まれる文書のうち、最初の文書の単語ID列を表示させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tZLm0hQVjZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba0160b-184f-4afc-cc24-4cd6077a47d7"
      },
      "source": [
        "print(batch.text[:, 0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  744,    16,    24,     9,   654,  1108,    21,  4948,  3217,   154,\n",
            "           34,     5,   308,    23,    12,    10,    84,   305, 10421,     6,\n",
            "          154,    57,    29,   134,   190,     4,    11,   119,   154,    47,\n",
            "           12,    99,     2,  1596,     7,     2,    77,     9,    50,   750,\n",
            "            9,  1367,    48,   488,    12,   143,     6,   163,     6,    93,\n",
            "            5,   139,    50,     4,   382,   173,     7,    31,    44,    57,\n",
            "         1198,     8, 15563,     2,   759,   122,    31,   153,   380,   988,\n",
            "            2,   302,     3,   113,   194,    47,     2,    24,    40,    42,\n",
            "            4,   512,  2554,    12,    23,    31,    40,     2,   152,     7,\n",
            "            2,    77,     5, 11962,  5466,  5493,   678,    64,  7521,     5,\n",
            "         1787,    94,     2,  3662,  1505,     3,   925,   321,     3,   355,\n",
            "         1068,     6, 16377,   207,     2,  3662,    40,     2,   189,    68,\n",
            "            4,    11,   361,    12,   131,   175,   629,    26,   576,    12,\n",
            "           63,   278,    33,     8,  1842,    12,     8,  5077,     4],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcXV1WLCdax1"
      },
      "source": [
        "* このミニバッチに含まれる文書のうち、最初の文書の単語ID列を単語列に戻したものを表示させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjaS-Mjadf63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5255fe-c24f-4290-e16a-514693edefdd"
      },
      "source": [
        "print(' '.join([TEXT.vocab.itos[i] for i in batch.text[:, 0]]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Although this film is somewhat filled with eighties cheese i have a place for it in my DVD rack and i do n't know why . I think i like it because the moral of the story is ' television is garbage so turn it off and go and get a life ' . For those of you who do decide to heed the message then you should try reading the book , its nothing like the film at all . To ruin it for you at the end of the story a fatally wounded Richards ends up crashing a plane into the network building , killing himself , everyone inside and shutting down the network at the same time . I read it many years ago but today it would hard not to compare it to 9/11 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uoslpyTgz8w"
      },
      "source": [
        "* このミニバッチに含まれる文書のうち、最後の文書の単語ID列を表示させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcdyIhK0TUac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb36bf7-5959-41fd-80fd-4dde04585966"
      },
      "source": [
        "print(batch.text[:, BATCH_SIZE-1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  547,   203,    29,    16,   605,     7, 24728,     3,   472,   919,\n",
            "           36,   872,    10,     2,   248,  1417,    58,    54,   953,     2,\n",
            "          532,   579,     6,  3322,    42,     2,   110,     4,    25,   197,\n",
            "            9,     5,   103,  3151,     4,  1024,  2307, 11955,   333,   447,\n",
            "          525,     4,   866,   708,   188,   568,    37,    19, 21774,    23,\n",
            "           35,   775,    20,  1945,  1409,     4,   155,     9,     5,  2071,\n",
            "            8,   128,     4,   358,   108,    69,    81,   190,  6001,     0,\n",
            "          104,    61,    88,  7340,   124,     4,   155,     9,     5,   103,\n",
            "          748,   121,   298,     6,    35,   351,  1181,    21,  2307,     9,\n",
            "          276,     8,   128,     4,  1094, 13993,    85,   791,   908,   179,\n",
            "           10,     5,    33,    62, 18018,   237,     4,   400,   101,  1007,\n",
            "        10606,    10,     8,   107,    16,     5,  1658,   797,   110,     8,\n",
            "         1208,  6352,   258,     4,    11,  1810,   516, 12170,    74,     5,\n",
            "         2484,   962,    35,    38,     4,  7610,    41,     1,     1],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtDXRKPMT9KW"
      },
      "source": [
        "最後の文書の末尾は「1」で埋められていることが分かる。\n",
        "\n",
        "この1は、パディング用単語のIDだったことを想起されたい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDzk2ghCUD8N"
      },
      "source": [
        "ミニバッチに含まれる文書の長さを調べると、文書が文書長の降順に並べられていることが分かる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PutP_EU4Tca-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea6ce69-ceab-4125-9c19-6129aa9c2996"
      },
      "source": [
        "(batch.text != 1).sum(0)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
              "        139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139,\n",
              "        139, 139, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
              "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
              "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
              "        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138,\n",
              "        138, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137, 137,\n",
              "        137, 137], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PDZlF0O6doP"
      },
      "source": [
        "## 07-02 MLPによる文書分類の準備\n",
        "* 今回は、ごく簡単なMLPで文書分類をする。\n",
        "* 文書中の全単語トークンの埋め込みベクトルの平均を、MLPの入力とする。\n",
        " * 当然、語順の情報は使われない。\n",
        " * つまり、bag-of-wordsモデルになっている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjpel2i46gbD"
      },
      "source": [
        "### 定数の設定\n",
        "* 単語埋め込みベクトルの次元数は128にする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQPXVLC66NUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38541916-59af-449e-d820-5651746fd780"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "NUM_CLASS = len(LABEL.vocab)\n",
        "EMBED_DIM = 128\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "print(f'語彙サイズ {INPUT_DIM}, クラス数 {NUM_CLASS}, 単語埋め込み次元 {EMBED_DIM}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "語彙サイズ 25002, クラス数 2, 単語埋め込み次元 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsuHjuNp6tvt"
      },
      "source": [
        "### モデルを定義する前にPyTorchの単語埋め込みがどんなものかを見てみる\n",
        "* 埋め込みとは、単語IDから単語ベクトルへのマッピング。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3J7TzxFVMsR"
      },
      "source": [
        "* 以下のように、語彙サイズと埋め込みの次元数を指定しつつ、torch.nn.Embeddingのインスタンスを作ればよい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP7jJVYT6tBg"
      },
      "source": [
        "embed = nn.Embedding(INPUT_DIM, EMBED_DIM, padding_idx=PAD_IDX).to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUl6lR8JVWTu"
      },
      "source": [
        "* パディング用の単語の埋め込みはゼロベクトルになる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3ZCr9Ll61m8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d447c7ab-5057-4f4b-fafd-98d8a4d035f5"
      },
      "source": [
        "print(embed(torch.tensor([21,1]).to(device)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.4663,  0.3888,  0.5244, -0.6720,  1.2702,  0.1475, -0.6756,  1.0647,\n",
            "          0.4122,  0.4360,  0.4711,  1.7838, -0.2890, -0.1943, -0.4321,  0.1552,\n",
            "         -0.2901,  0.6956,  0.3870,  1.3461,  3.0132,  0.9346, -2.4039, -0.0521,\n",
            "         -0.7123, -0.9902,  1.6379,  0.2446, -0.4733,  1.0840, -0.1715, -1.9957,\n",
            "         -0.7140,  0.2289, -0.5881,  2.2581, -0.5802,  1.4646,  0.0392, -0.7295,\n",
            "          0.4982, -1.1848,  0.4286, -0.0767,  1.2760, -1.3223,  0.0627,  0.3617,\n",
            "         -0.7071,  0.0949, -0.5615, -0.6247,  1.0816,  0.7235, -0.9131,  0.6759,\n",
            "          0.0999, -0.9366,  1.9773,  1.2333,  0.1287, -1.0535, -1.6376,  0.7970,\n",
            "          0.1361, -0.0714, -0.2324, -0.8216,  1.4716, -0.0678,  0.4309, -0.1257,\n",
            "          0.2348, -1.3550,  0.3339,  2.1095,  1.8534, -0.8028,  0.6104,  0.8844,\n",
            "         -0.4362,  0.4587,  0.4177,  1.4428,  0.0063, -0.2002,  0.4557,  0.4221,\n",
            "         -1.5692, -0.5961, -0.7103, -0.9230,  0.1227, -0.0557, -0.0169,  0.9816,\n",
            "          0.1775,  0.8781, -2.7163, -0.1170, -0.4895, -0.4243,  0.5754, -0.2282,\n",
            "          0.2867,  0.4296, -1.3569, -0.4296,  0.5040, -1.0372,  1.0028, -1.2460,\n",
            "         -0.1285, -1.9543, -1.0806,  2.8702,  0.3659, -1.1613,  0.4680,  0.1308,\n",
            "          1.0111, -1.1194, -1.4237, -1.2461, -0.2059, -1.8122, -2.5448, -0.5135],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
            "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN0kM3urr-Il"
      },
      "source": [
        "* 埋め込みの効果を見てみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ0FqJRcr6Vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac813a0-1235-482f-8edf-f48442194a43"
      },
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "  print(i, embed(batch.text).shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([404, 100, 128])\n",
            "1 torch.Size([144, 100, 128])\n",
            "2 torch.Size([282, 100, 128])\n",
            "3 torch.Size([106, 100, 128])\n",
            "4 torch.Size([209, 100, 128])\n",
            "5 torch.Size([172, 100, 128])\n",
            "6 torch.Size([515, 100, 128])\n",
            "7 torch.Size([88, 100, 128])\n",
            "8 torch.Size([82, 100, 128])\n",
            "9 torch.Size([137, 100, 128])\n",
            "10 torch.Size([231, 100, 128])\n",
            "11 torch.Size([200, 100, 128])\n",
            "12 torch.Size([351, 100, 128])\n",
            "13 torch.Size([213, 100, 128])\n",
            "14 torch.Size([747, 100, 128])\n",
            "15 torch.Size([203, 100, 128])\n",
            "16 torch.Size([916, 100, 128])\n",
            "17 torch.Size([371, 100, 128])\n",
            "18 torch.Size([149, 100, 128])\n",
            "19 torch.Size([302, 100, 128])\n",
            "20 torch.Size([589, 100, 128])\n",
            "21 torch.Size([294, 100, 128])\n",
            "22 torch.Size([197, 100, 128])\n",
            "23 torch.Size([448, 100, 128])\n",
            "24 torch.Size([621, 100, 128])\n",
            "25 torch.Size([223, 100, 128])\n",
            "26 torch.Size([64, 100, 128])\n",
            "27 torch.Size([239, 100, 128])\n",
            "28 torch.Size([823, 100, 128])\n",
            "29 torch.Size([265, 100, 128])\n",
            "30 torch.Size([220, 100, 128])\n",
            "31 torch.Size([184, 100, 128])\n",
            "32 torch.Size([194, 100, 128])\n",
            "33 torch.Size([1064, 100, 128])\n",
            "34 torch.Size([189, 100, 128])\n",
            "35 torch.Size([76, 100, 128])\n",
            "36 torch.Size([126, 100, 128])\n",
            "37 torch.Size([277, 100, 128])\n",
            "38 torch.Size([163, 100, 128])\n",
            "39 torch.Size([158, 100, 128])\n",
            "40 torch.Size([175, 100, 128])\n",
            "41 torch.Size([332, 100, 128])\n",
            "42 torch.Size([147, 100, 128])\n",
            "43 torch.Size([481, 100, 128])\n",
            "44 torch.Size([113, 100, 128])\n",
            "45 torch.Size([324, 100, 128])\n",
            "46 torch.Size([170, 100, 128])\n",
            "47 torch.Size([118, 100, 128])\n",
            "48 torch.Size([177, 100, 128])\n",
            "49 torch.Size([316, 100, 128])\n",
            "50 torch.Size([133, 100, 128])\n",
            "51 torch.Size([391, 100, 128])\n",
            "52 torch.Size([135, 100, 128])\n",
            "53 torch.Size([287, 100, 128])\n",
            "54 torch.Size([160, 100, 128])\n",
            "55 torch.Size([143, 100, 128])\n",
            "56 torch.Size([217, 100, 128])\n",
            "57 torch.Size([661, 100, 128])\n",
            "58 torch.Size([270, 100, 128])\n",
            "59 torch.Size([382, 100, 128])\n",
            "60 torch.Size([146, 100, 128])\n",
            "61 torch.Size([182, 100, 128])\n",
            "62 torch.Size([227, 100, 128])\n",
            "63 torch.Size([156, 100, 128])\n",
            "64 torch.Size([165, 100, 128])\n",
            "65 torch.Size([155, 100, 128])\n",
            "66 torch.Size([151, 100, 128])\n",
            "67 torch.Size([342, 100, 128])\n",
            "68 torch.Size([236, 100, 128])\n",
            "69 torch.Size([187, 100, 128])\n",
            "70 torch.Size([538, 100, 128])\n",
            "71 torch.Size([162, 100, 128])\n",
            "72 torch.Size([249, 100, 128])\n",
            "73 torch.Size([700, 100, 128])\n",
            "74 torch.Size([206, 100, 128])\n",
            "75 torch.Size([309, 100, 128])\n",
            "76 torch.Size([139, 100, 128])\n",
            "77 torch.Size([465, 100, 128])\n",
            "78 torch.Size([254, 100, 128])\n",
            "79 torch.Size([168, 100, 128])\n",
            "80 torch.Size([131, 100, 128])\n",
            "81 torch.Size([49, 100, 128])\n",
            "82 torch.Size([100, 100, 128])\n",
            "83 torch.Size([94, 100, 128])\n",
            "84 torch.Size([70, 100, 128])\n",
            "85 torch.Size([56, 100, 128])\n",
            "86 torch.Size([260, 100, 128])\n",
            "87 torch.Size([562, 100, 128])\n",
            "88 torch.Size([244, 100, 128])\n",
            "89 torch.Size([122, 100, 128])\n",
            "90 torch.Size([1989, 100, 128])\n",
            "91 torch.Size([191, 100, 128])\n",
            "92 torch.Size([141, 100, 128])\n",
            "93 torch.Size([418, 100, 128])\n",
            "94 torch.Size([129, 100, 128])\n",
            "95 torch.Size([179, 100, 128])\n",
            "96 torch.Size([432, 100, 128])\n",
            "97 torch.Size([498, 100, 128])\n",
            "98 torch.Size([153, 100, 128])\n",
            "99 torch.Size([361, 100, 128])\n",
            "100 torch.Size([156, 100, 128])\n",
            "101 torch.Size([830, 100, 128])\n",
            "102 torch.Size([356, 100, 128])\n",
            "103 torch.Size([421, 100, 128])\n",
            "104 torch.Size([259, 100, 128])\n",
            "105 torch.Size([194, 100, 128])\n",
            "106 torch.Size([188, 100, 128])\n",
            "107 torch.Size([169, 100, 128])\n",
            "108 torch.Size([141, 100, 128])\n",
            "109 torch.Size([171, 100, 128])\n",
            "110 torch.Size([209, 100, 128])\n",
            "111 torch.Size([124, 100, 128])\n",
            "112 torch.Size([920, 100, 128])\n",
            "113 torch.Size([223, 100, 128])\n",
            "114 torch.Size([220, 100, 128])\n",
            "115 torch.Size([661, 100, 128])\n",
            "116 torch.Size([314, 100, 128])\n",
            "117 torch.Size([56, 100, 128])\n",
            "118 torch.Size([236, 100, 128])\n",
            "119 torch.Size([216, 100, 128])\n",
            "120 torch.Size([535, 100, 128])\n",
            "121 torch.Size([133, 100, 128])\n",
            "122 torch.Size([626, 100, 128])\n",
            "123 torch.Size([294, 100, 128])\n",
            "124 torch.Size([322, 100, 128])\n",
            "125 torch.Size([142, 100, 128])\n",
            "126 torch.Size([178, 100, 128])\n",
            "127 torch.Size([181, 100, 128])\n",
            "128 torch.Size([174, 100, 128])\n",
            "129 torch.Size([489, 100, 128])\n",
            "130 torch.Size([165, 100, 128])\n",
            "131 torch.Size([128, 100, 128])\n",
            "132 torch.Size([275, 100, 128])\n",
            "133 torch.Size([152, 100, 128])\n",
            "134 torch.Size([113, 100, 128])\n",
            "135 torch.Size([212, 100, 128])\n",
            "136 torch.Size([227, 100, 128])\n",
            "137 torch.Size([139, 100, 128])\n",
            "138 torch.Size([206, 100, 128])\n",
            "139 torch.Size([409, 100, 128])\n",
            "140 torch.Size([376, 100, 128])\n",
            "141 torch.Size([117, 100, 128])\n",
            "142 torch.Size([453, 100, 128])\n",
            "143 torch.Size([398, 100, 128])\n",
            "144 torch.Size([329, 100, 128])\n",
            "145 torch.Size([176, 100, 128])\n",
            "146 torch.Size([240, 100, 128])\n",
            "147 torch.Size([270, 100, 128])\n",
            "148 torch.Size([281, 100, 128])\n",
            "149 torch.Size([87, 100, 128])\n",
            "150 torch.Size([75, 100, 128])\n",
            "151 torch.Size([469, 100, 128])\n",
            "152 torch.Size([69, 100, 128])\n",
            "153 torch.Size([149, 100, 128])\n",
            "154 torch.Size([167, 100, 128])\n",
            "155 torch.Size([435, 100, 128])\n",
            "156 torch.Size([106, 100, 128])\n",
            "157 torch.Size([191, 100, 128])\n",
            "158 torch.Size([147, 100, 128])\n",
            "159 torch.Size([121, 100, 128])\n",
            "160 torch.Size([231, 100, 128])\n",
            "161 torch.Size([202, 100, 128])\n",
            "162 torch.Size([254, 100, 128])\n",
            "163 torch.Size([197, 100, 128])\n",
            "164 torch.Size([50, 100, 128])\n",
            "165 torch.Size([135, 100, 128])\n",
            "166 torch.Size([137, 100, 128])\n",
            "167 torch.Size([244, 100, 128])\n",
            "168 torch.Size([163, 100, 128])\n",
            "169 torch.Size([162, 100, 128])\n",
            "170 torch.Size([758, 100, 128])\n",
            "171 torch.Size([249, 100, 128])\n",
            "172 torch.Size([160, 100, 128])\n",
            "173 torch.Size([158, 100, 128])\n",
            "174 torch.Size([131, 100, 128])\n",
            "175 torch.Size([94, 100, 128])\n",
            "176 torch.Size([154, 100, 128])\n",
            "177 torch.Size([151, 100, 128])\n",
            "178 torch.Size([366, 100, 128])\n",
            "179 torch.Size([186, 100, 128])\n",
            "180 torch.Size([587, 100, 128])\n",
            "181 torch.Size([558, 100, 128])\n",
            "182 torch.Size([100, 100, 128])\n",
            "183 torch.Size([1068, 100, 128])\n",
            "184 torch.Size([287, 100, 128])\n",
            "185 torch.Size([146, 100, 128])\n",
            "186 torch.Size([64, 100, 128])\n",
            "187 torch.Size([388, 100, 128])\n",
            "188 torch.Size([299, 100, 128])\n",
            "189 torch.Size([705, 100, 128])\n",
            "190 torch.Size([305, 100, 128])\n",
            "191 torch.Size([199, 100, 128])\n",
            "192 torch.Size([346, 100, 128])\n",
            "193 torch.Size([338, 100, 128])\n",
            "194 torch.Size([2789, 100, 128])\n",
            "195 torch.Size([183, 100, 128])\n",
            "196 torch.Size([509, 100, 128])\n",
            "197 torch.Size([144, 100, 128])\n",
            "198 torch.Size([264, 100, 128])\n",
            "199 torch.Size([81, 100, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyngitc78hv"
      },
      "source": [
        "### モデルの定義\n",
        "* MLP（多層パーセプトロン）だが、入り口に単語埋め込み層が挿入されている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9asdLYng7DOu"
      },
      "source": [
        "class EmbedTextSentiment(nn.Module):\n",
        "  def __init__(self, embed_dim, num_class, vocab_size, padding_idx):\n",
        "    super(EmbedTextSentiment, self).__init__()\n",
        "    self.padding_idx = padding_idx # 2020/12/19追加\n",
        "    self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
        "    self.fc1 = nn.Linear(embed_dim, 500)\n",
        "    self.fc2 = nn.Linear(500, 100)\n",
        "    self.fc3 = nn.Linear(100, num_class)\n",
        "\n",
        "  def forward(self, text):\n",
        "    x = self.embed(text)\n",
        "    #x = x.mean(0) # 文書に含まれる全単語トークンの単語ベクトルの平均\n",
        "    #上の平均の計算を正確に書くと、以下の2行のようになります。（2020/12/19追加）\n",
        "    mask = (text != self.padding_idx)\n",
        "    x = (x * mask.unsqueeze(2)).sum(0) / mask.sum(0).unsqueeze(1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foU72cB48IO9"
      },
      "source": [
        "### モデルを作る\n",
        "* モデル（のインスタンス）をGPUに移動させている点に注意。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0BHCGAZ8F18"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX).to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wylQOq8N8cqI"
      },
      "source": [
        "### 損失関数とoptimizerとschedulerを作る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw34INS78cIW"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilWLfu8Z8MzW"
      },
      "source": [
        "### 訓練用の関数\n",
        "* 最初の`model.train()`に注意。こうやって、モデルを訓練モードに設定する。\n",
        " * 例えば、dropoutを含むモデルなど、訓練時と評価時で、ふるまい方を変える必要があるときがあるため、こういうことをする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR2R4Lqh8J7n"
      },
      "source": [
        "def train(data_iterator, model, optimizer, scheduler, criterion):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  for batch in data_iterator:\n",
        "    optimizer.zero_grad()\n",
        "    text, cls = batch.text, batch.label\n",
        "    output = model(text)\n",
        "    loss = criterion(output, cls)\n",
        "    train_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_acc += (output.argmax(1) == cls).float().mean().item()\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "  num_batch = len(data_iterator)\n",
        "  return train_loss / num_batch, train_acc / num_batch"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftuX8e1W8iRh"
      },
      "source": [
        "### 評価用の関数\n",
        "* 最初の`model.eval()`に注意。こうやって、モデルを評価モードに設定する。\n",
        " * 例えば、dropoutを含むモデルなど、訓練時と評価時で、ふるまい方を変える必要があるときがあるため、こういうことをする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGUnsJlq8Ue3"
      },
      "source": [
        "def test(data_iterator, model, criterion):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  for batch in data_iterator:\n",
        "    text, cls = batch.text, batch.label\n",
        "    with torch.no_grad():\n",
        "      output = model(text)\n",
        "      loss = criterion(output, cls)\n",
        "      loss += loss.item()\n",
        "      acc += (output.argmax(1) == cls).float().mean().item()\n",
        "\n",
        "  num_batch = len(data_iterator)\n",
        "  return loss / num_batch, acc / num_batch"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8o_jDAg8osP"
      },
      "source": [
        "## 07-03 分類器の訓練と検証セットでの評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJJFv4k-8mH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d741b71-b62c-40cc-ee8e-9a38bb9e748d"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | time in 0 minutes, 2 seconds | lr=0.009500\n",
            "\tLoss: 0.37151(train)\t|\tAcc: 83.24%(train)\n",
            "\tLoss: 0.01162(valid)\t|\tAcc: 88.08%(valid)\n",
            "Epoch 2 | time in 0 minutes, 2 seconds | lr=0.009025\n",
            "\tLoss: 0.15511(train)\t|\tAcc: 94.36%(train)\n",
            "\tLoss: 0.01306(valid)\t|\tAcc: 87.58%(valid)\n",
            "Epoch 3 | time in 0 minutes, 2 seconds | lr=0.008574\n",
            "\tLoss: 0.07948(train)\t|\tAcc: 97.24%(train)\n",
            "\tLoss: 0.00866(valid)\t|\tAcc: 87.48%(valid)\n",
            "Epoch 4 | time in 0 minutes, 2 seconds | lr=0.008145\n",
            "\tLoss: 0.04204(train)\t|\tAcc: 98.50%(train)\n",
            "\tLoss: 0.02709(valid)\t|\tAcc: 86.52%(valid)\n",
            "Epoch 5 | time in 0 minutes, 2 seconds | lr=0.007738\n",
            "\tLoss: 0.02673(train)\t|\tAcc: 99.06%(train)\n",
            "\tLoss: 0.01558(valid)\t|\tAcc: 86.86%(valid)\n",
            "Epoch 6 | time in 0 minutes, 2 seconds | lr=0.007351\n",
            "\tLoss: 0.01378(train)\t|\tAcc: 99.52%(train)\n",
            "\tLoss: 0.01376(valid)\t|\tAcc: 87.06%(valid)\n",
            "Epoch 7 | time in 0 minutes, 2 seconds | lr=0.006983\n",
            "\tLoss: 0.00854(train)\t|\tAcc: 99.69%(train)\n",
            "\tLoss: 0.05389(valid)\t|\tAcc: 86.06%(valid)\n",
            "Epoch 8 | time in 0 minutes, 2 seconds | lr=0.006634\n",
            "\tLoss: 0.01295(train)\t|\tAcc: 99.59%(train)\n",
            "\tLoss: 0.04888(valid)\t|\tAcc: 86.00%(valid)\n",
            "Epoch 9 | time in 0 minutes, 2 seconds | lr=0.006302\n",
            "\tLoss: 0.00672(train)\t|\tAcc: 99.76%(train)\n",
            "\tLoss: 0.05766(valid)\t|\tAcc: 86.80%(valid)\n",
            "Epoch 10 | time in 0 minutes, 2 seconds | lr=0.005987\n",
            "\tLoss: 0.00304(train)\t|\tAcc: 99.87%(train)\n",
            "\tLoss: 0.04167(valid)\t|\tAcc: 86.54%(valid)\n",
            "Epoch 11 | time in 0 minutes, 2 seconds | lr=0.005688\n",
            "\tLoss: 0.00433(train)\t|\tAcc: 99.86%(train)\n",
            "\tLoss: 0.06501(valid)\t|\tAcc: 86.44%(valid)\n",
            "Epoch 12 | time in 0 minutes, 2 seconds | lr=0.005404\n",
            "\tLoss: 0.00595(train)\t|\tAcc: 99.81%(train)\n",
            "\tLoss: 0.04955(valid)\t|\tAcc: 86.58%(valid)\n",
            "Epoch 13 | time in 0 minutes, 2 seconds | lr=0.005133\n",
            "\tLoss: 0.00190(train)\t|\tAcc: 99.94%(train)\n",
            "\tLoss: 0.05784(valid)\t|\tAcc: 86.64%(valid)\n",
            "Epoch 14 | time in 0 minutes, 2 seconds | lr=0.004877\n",
            "\tLoss: 0.00238(train)\t|\tAcc: 99.93%(train)\n",
            "\tLoss: 0.06248(valid)\t|\tAcc: 86.34%(valid)\n",
            "Epoch 15 | time in 0 minutes, 2 seconds | lr=0.004633\n",
            "\tLoss: 0.00136(train)\t|\tAcc: 99.95%(train)\n",
            "\tLoss: 0.05861(valid)\t|\tAcc: 86.96%(valid)\n",
            "Epoch 16 | time in 0 minutes, 2 seconds | lr=0.004401\n",
            "\tLoss: 0.00318(train)\t|\tAcc: 99.90%(train)\n",
            "\tLoss: 0.08924(valid)\t|\tAcc: 86.74%(valid)\n",
            "Epoch 17 | time in 0 minutes, 2 seconds | lr=0.004181\n",
            "\tLoss: 0.00300(train)\t|\tAcc: 99.89%(train)\n",
            "\tLoss: 0.05514(valid)\t|\tAcc: 86.44%(valid)\n",
            "Epoch 18 | time in 0 minutes, 2 seconds | lr=0.003972\n",
            "\tLoss: 0.00135(train)\t|\tAcc: 99.95%(train)\n",
            "\tLoss: 0.07379(valid)\t|\tAcc: 87.00%(valid)\n",
            "Epoch 19 | time in 0 minutes, 2 seconds | lr=0.003774\n",
            "\tLoss: 0.00005(train)\t|\tAcc: 100.00%(train)\n",
            "\tLoss: 0.08411(valid)\t|\tAcc: 86.72%(valid)\n",
            "Epoch 20 | time in 0 minutes, 2 seconds | lr=0.003585\n",
            "\tLoss: 0.00001(train)\t|\tAcc: 100.00%(train)\n",
            "\tLoss: 0.10841(valid)\t|\tAcc: 86.62%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPux8PReWTXG"
      },
      "source": [
        "## 07-04 再検討\n",
        "* 訓練データ上での分類精度がほぼ100%になってしまっている。\n",
        "* 検証データでの分類精度と大きな差があり、明らかにオーバーフィッティング。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23jMgtmoWkty"
      },
      "source": [
        "### ドロップアウトを使う\n",
        "* モデルのインスタンスを作るときにdropoutの確率を引数pで指定できるようにする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khps3ZuBWntq"
      },
      "source": [
        "class EmbedTextSentiment(nn.Module):\n",
        "  def __init__(self, embed_dim, num_class, vocab_size, padding_idx, p=0.0):\n",
        "    super(EmbedTextSentiment, self).__init__()\n",
        "    self.padding_idx = padding_idx # 2020/12/19追加\n",
        "    self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
        "    self.dropout = nn.Dropout(p=p)\n",
        "    self.fc1 = nn.Linear(embed_dim, 500)\n",
        "    self.fc2 = nn.Linear(500, 100)\n",
        "    self.fc3 = nn.Linear(100, num_class)\n",
        "\n",
        "  def forward(self, text):\n",
        "    x = self.dropout(self.embed(text)) #埋め込み層の直後にdropout\n",
        "    #x = x.mean(0)\n",
        "    #上の平均の計算を正確に書くと、以下の2行のようになります。（2020/12/19追加）\n",
        "    mask = (text != self.padding_idx)\n",
        "    x = (x * mask.unsqueeze(2)).sum(0) / mask.sum(0).unsqueeze(1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVXbkt6qXxNt"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXkBDXc6X1mp",
        "outputId": "e1f33a37-9de3-4b37-8742-84451b45c2e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | time in 0 minutes, 2 seconds | lr=0.009500\n",
            "\tLoss: 0.42817(train)\t|\tAcc: 79.67%(train)\n",
            "\tLoss: 0.01726(valid)\t|\tAcc: 88.28%(valid)\n",
            "Epoch 2 | time in 0 minutes, 2 seconds | lr=0.009025\n",
            "\tLoss: 0.21941(train)\t|\tAcc: 91.53%(train)\n",
            "\tLoss: 0.00776(valid)\t|\tAcc: 88.22%(valid)\n",
            "Epoch 3 | time in 0 minutes, 2 seconds | lr=0.008574\n",
            "\tLoss: 0.14934(train)\t|\tAcc: 94.38%(train)\n",
            "\tLoss: 0.01548(valid)\t|\tAcc: 88.48%(valid)\n",
            "Epoch 4 | time in 0 minutes, 2 seconds | lr=0.008145\n",
            "\tLoss: 0.10527(train)\t|\tAcc: 96.12%(train)\n",
            "\tLoss: 0.01569(valid)\t|\tAcc: 88.24%(valid)\n",
            "Epoch 5 | time in 0 minutes, 2 seconds | lr=0.007738\n",
            "\tLoss: 0.07221(train)\t|\tAcc: 97.24%(train)\n",
            "\tLoss: 0.01256(valid)\t|\tAcc: 88.18%(valid)\n",
            "Epoch 6 | time in 0 minutes, 2 seconds | lr=0.007351\n",
            "\tLoss: 0.05581(train)\t|\tAcc: 98.00%(train)\n",
            "\tLoss: 0.02577(valid)\t|\tAcc: 87.58%(valid)\n",
            "Epoch 7 | time in 0 minutes, 2 seconds | lr=0.006983\n",
            "\tLoss: 0.04255(train)\t|\tAcc: 98.41%(train)\n",
            "\tLoss: 0.02043(valid)\t|\tAcc: 87.94%(valid)\n",
            "Epoch 8 | time in 0 minutes, 2 seconds | lr=0.006634\n",
            "\tLoss: 0.03702(train)\t|\tAcc: 98.69%(train)\n",
            "\tLoss: 0.01868(valid)\t|\tAcc: 87.78%(valid)\n",
            "Epoch 9 | time in 0 minutes, 2 seconds | lr=0.006302\n",
            "\tLoss: 0.02887(train)\t|\tAcc: 98.88%(train)\n",
            "\tLoss: 0.02108(valid)\t|\tAcc: 87.64%(valid)\n",
            "Epoch 10 | time in 0 minutes, 2 seconds | lr=0.005987\n",
            "\tLoss: 0.02489(train)\t|\tAcc: 99.12%(train)\n",
            "\tLoss: 0.03597(valid)\t|\tAcc: 87.74%(valid)\n",
            "Epoch 11 | time in 0 minutes, 2 seconds | lr=0.005688\n",
            "\tLoss: 0.01699(train)\t|\tAcc: 99.35%(train)\n",
            "\tLoss: 0.03266(valid)\t|\tAcc: 87.78%(valid)\n",
            "Epoch 12 | time in 0 minutes, 2 seconds | lr=0.005404\n",
            "\tLoss: 0.01485(train)\t|\tAcc: 99.43%(train)\n",
            "\tLoss: 0.02888(valid)\t|\tAcc: 87.90%(valid)\n",
            "Epoch 13 | time in 0 minutes, 2 seconds | lr=0.005133\n",
            "\tLoss: 0.01811(train)\t|\tAcc: 99.42%(train)\n",
            "\tLoss: 0.02314(valid)\t|\tAcc: 87.66%(valid)\n",
            "Epoch 14 | time in 0 minutes, 2 seconds | lr=0.004877\n",
            "\tLoss: 0.01131(train)\t|\tAcc: 99.59%(train)\n",
            "\tLoss: 0.04007(valid)\t|\tAcc: 87.94%(valid)\n",
            "Epoch 15 | time in 0 minutes, 2 seconds | lr=0.004633\n",
            "\tLoss: 0.01071(train)\t|\tAcc: 99.63%(train)\n",
            "\tLoss: 0.02589(valid)\t|\tAcc: 87.62%(valid)\n",
            "Epoch 16 | time in 0 minutes, 2 seconds | lr=0.004401\n",
            "\tLoss: 0.00999(train)\t|\tAcc: 99.64%(train)\n",
            "\tLoss: 0.04757(valid)\t|\tAcc: 87.60%(valid)\n",
            "Epoch 17 | time in 0 minutes, 2 seconds | lr=0.004181\n",
            "\tLoss: 0.01092(train)\t|\tAcc: 99.68%(train)\n",
            "\tLoss: 0.03199(valid)\t|\tAcc: 87.76%(valid)\n",
            "Epoch 18 | time in 0 minutes, 2 seconds | lr=0.003972\n",
            "\tLoss: 0.00826(train)\t|\tAcc: 99.71%(train)\n",
            "\tLoss: 0.02639(valid)\t|\tAcc: 87.94%(valid)\n",
            "Epoch 19 | time in 0 minutes, 2 seconds | lr=0.003774\n",
            "\tLoss: 0.00669(train)\t|\tAcc: 99.80%(train)\n",
            "\tLoss: 0.04187(valid)\t|\tAcc: 87.62%(valid)\n",
            "Epoch 20 | time in 0 minutes, 2 seconds | lr=0.003585\n",
            "\tLoss: 0.00733(train)\t|\tAcc: 99.79%(train)\n",
            "\tLoss: 0.02977(valid)\t|\tAcc: 87.46%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu3Y-wjwb0po"
      },
      "source": [
        "### L２正則化を使う\n",
        "* optimizerのweight_decayパラメータを0より大きな値にする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmxEuSFJazCJ"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0Zr2S7ga3J4",
        "outputId": "6ce52deb-c6b3-468d-d488-28aa9e28ee53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 20\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | time in 0 minutes, 2 seconds | lr=0.009500\n",
            "\tLoss: 0.57730(train)\t|\tAcc: 69.35%(train)\n",
            "\tLoss: 0.01858(valid)\t|\tAcc: 75.04%(valid)\n",
            "Epoch 2 | time in 0 minutes, 2 seconds | lr=0.009025\n",
            "\tLoss: 0.44230(train)\t|\tAcc: 79.48%(train)\n",
            "\tLoss: 0.01357(valid)\t|\tAcc: 82.70%(valid)\n",
            "Epoch 3 | time in 0 minutes, 2 seconds | lr=0.008574\n",
            "\tLoss: 0.38614(train)\t|\tAcc: 83.05%(train)\n",
            "\tLoss: 0.01318(valid)\t|\tAcc: 84.78%(valid)\n",
            "Epoch 4 | time in 0 minutes, 2 seconds | lr=0.008145\n",
            "\tLoss: 0.36366(train)\t|\tAcc: 84.40%(train)\n",
            "\tLoss: 0.01520(valid)\t|\tAcc: 86.22%(valid)\n",
            "Epoch 5 | time in 0 minutes, 2 seconds | lr=0.007738\n",
            "\tLoss: 0.33946(train)\t|\tAcc: 85.94%(train)\n",
            "\tLoss: 0.01635(valid)\t|\tAcc: 86.66%(valid)\n",
            "Epoch 6 | time in 0 minutes, 2 seconds | lr=0.007351\n",
            "\tLoss: 0.32933(train)\t|\tAcc: 86.28%(train)\n",
            "\tLoss: 0.01078(valid)\t|\tAcc: 86.84%(valid)\n",
            "Epoch 7 | time in 0 minutes, 2 seconds | lr=0.006983\n",
            "\tLoss: 0.32275(train)\t|\tAcc: 86.46%(train)\n",
            "\tLoss: 0.01018(valid)\t|\tAcc: 86.40%(valid)\n",
            "Epoch 8 | time in 0 minutes, 2 seconds | lr=0.006634\n",
            "\tLoss: 0.30908(train)\t|\tAcc: 87.31%(train)\n",
            "\tLoss: 0.01375(valid)\t|\tAcc: 85.86%(valid)\n",
            "Epoch 9 | time in 0 minutes, 2 seconds | lr=0.006302\n",
            "\tLoss: 0.31260(train)\t|\tAcc: 86.93%(train)\n",
            "\tLoss: 0.01324(valid)\t|\tAcc: 86.98%(valid)\n",
            "Epoch 10 | time in 0 minutes, 2 seconds | lr=0.005987\n",
            "\tLoss: 0.29510(train)\t|\tAcc: 87.97%(train)\n",
            "\tLoss: 0.00914(valid)\t|\tAcc: 87.60%(valid)\n",
            "Epoch 11 | time in 0 minutes, 2 seconds | lr=0.005688\n",
            "\tLoss: 0.29428(train)\t|\tAcc: 88.10%(train)\n",
            "\tLoss: 0.00894(valid)\t|\tAcc: 87.82%(valid)\n",
            "Epoch 12 | time in 0 minutes, 2 seconds | lr=0.005404\n",
            "\tLoss: 0.28183(train)\t|\tAcc: 88.41%(train)\n",
            "\tLoss: 0.01170(valid)\t|\tAcc: 87.02%(valid)\n",
            "Epoch 13 | time in 0 minutes, 2 seconds | lr=0.005133\n",
            "\tLoss: 0.27339(train)\t|\tAcc: 89.22%(train)\n",
            "\tLoss: 0.01179(valid)\t|\tAcc: 87.64%(valid)\n",
            "Epoch 14 | time in 0 minutes, 2 seconds | lr=0.004877\n",
            "\tLoss: 0.27285(train)\t|\tAcc: 88.94%(train)\n",
            "\tLoss: 0.01467(valid)\t|\tAcc: 87.44%(valid)\n",
            "Epoch 15 | time in 0 minutes, 2 seconds | lr=0.004633\n",
            "\tLoss: 0.26370(train)\t|\tAcc: 89.44%(train)\n",
            "\tLoss: 0.01102(valid)\t|\tAcc: 87.42%(valid)\n",
            "Epoch 16 | time in 0 minutes, 2 seconds | lr=0.004401\n",
            "\tLoss: 0.26073(train)\t|\tAcc: 89.37%(train)\n",
            "\tLoss: 0.01035(valid)\t|\tAcc: 86.84%(valid)\n",
            "Epoch 17 | time in 0 minutes, 2 seconds | lr=0.004181\n",
            "\tLoss: 0.25271(train)\t|\tAcc: 89.88%(train)\n",
            "\tLoss: 0.00954(valid)\t|\tAcc: 86.14%(valid)\n",
            "Epoch 18 | time in 0 minutes, 2 seconds | lr=0.003972\n",
            "\tLoss: 0.24731(train)\t|\tAcc: 90.35%(train)\n",
            "\tLoss: 0.01503(valid)\t|\tAcc: 87.62%(valid)\n",
            "Epoch 19 | time in 0 minutes, 2 seconds | lr=0.003774\n",
            "\tLoss: 0.24126(train)\t|\tAcc: 90.41%(train)\n",
            "\tLoss: 0.01606(valid)\t|\tAcc: 87.26%(valid)\n",
            "Epoch 20 | time in 0 minutes, 2 seconds | lr=0.003585\n",
            "\tLoss: 0.23534(train)\t|\tAcc: 90.57%(train)\n",
            "\tLoss: 0.01240(valid)\t|\tAcc: 87.40%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIHA64UTdmBj"
      },
      "source": [
        "### early stopping\n",
        "* validation setでのaccuracyが4回連続で最高値を下回ったら訓練を終えることにする。\n",
        "* early stoppingの実現については、PyTorch Lightningを使う手もある。\n",
        " * https://pytorch-lightning.readthedocs.io/en/latest/early_stopping.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0zclQnVdlVZ"
      },
      "source": [
        "model = EmbedTextSentiment(EMBED_DIM, NUM_CLASS, INPUT_DIM, padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3E_I5sRc3FF",
        "outputId": "42642acb-f5ea-4b16-85e8-caf2c69fb7f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "patience = 4\n",
        "early_stop_count = 0\n",
        "best_valid_acc = 0.0\n",
        "\n",
        "MIN_N_EPOCHS = 10 # 最低このエポック数は実行する\n",
        "N_EPOCHS = 50 # エポック数を増やしておく\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(train_iterator, model, optimizer, scheduler, criterion)\n",
        "  valid_loss, valid_acc = test(valid_iterator, model, criterion)\n",
        "\n",
        "  secs = int(time.time() - start_time)\n",
        "  mins = secs // 60\n",
        "  secs = secs % 60\n",
        "\n",
        "  print(f'Epoch {epoch + 1} | time in {mins:d} minutes, {secs:d} seconds | ', end='')\n",
        "  for param_group in optimizer.param_groups:\n",
        "    print(f'lr={param_group[\"lr\"]:.6f}')\n",
        "    break\n",
        "  print(f'\\tLoss: {train_loss:.5f}(train)\\t|\\tAcc: {train_acc * 100:.2f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.5f}(valid)\\t|\\tAcc: {valid_acc * 100:.2f}%(valid)')\n",
        "\n",
        "  # early stopping\n",
        "  if epoch + 1 > MIN_N_EPOCHS:\n",
        "    if best_valid_acc <= valid_acc:\n",
        "      best_valid_acc = valid_acc\n",
        "      early_stop_count = 0\n",
        "    else:\n",
        "      early_stop_count += 1\n",
        "      if early_stop_count == patience:\n",
        "        break"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | time in 0 minutes, 2 seconds | lr=0.009500\n",
            "\tLoss: 0.58522(train)\t|\tAcc: 68.47%(train)\n",
            "\tLoss: 0.02286(valid)\t|\tAcc: 75.24%(valid)\n",
            "Epoch 2 | time in 0 minutes, 2 seconds | lr=0.009025\n",
            "\tLoss: 0.46134(train)\t|\tAcc: 78.34%(train)\n",
            "\tLoss: 0.01269(valid)\t|\tAcc: 84.08%(valid)\n",
            "Epoch 3 | time in 0 minutes, 2 seconds | lr=0.008574\n",
            "\tLoss: 0.39208(train)\t|\tAcc: 82.79%(train)\n",
            "\tLoss: 0.01358(valid)\t|\tAcc: 84.64%(valid)\n",
            "Epoch 4 | time in 0 minutes, 2 seconds | lr=0.008145\n",
            "\tLoss: 0.35059(train)\t|\tAcc: 84.91%(train)\n",
            "\tLoss: 0.01191(valid)\t|\tAcc: 86.76%(valid)\n",
            "Epoch 5 | time in 0 minutes, 2 seconds | lr=0.007738\n",
            "\tLoss: 0.34777(train)\t|\tAcc: 85.09%(train)\n",
            "\tLoss: 0.01754(valid)\t|\tAcc: 86.82%(valid)\n",
            "Epoch 6 | time in 0 minutes, 2 seconds | lr=0.007351\n",
            "\tLoss: 0.32731(train)\t|\tAcc: 86.26%(train)\n",
            "\tLoss: 0.01219(valid)\t|\tAcc: 86.92%(valid)\n",
            "Epoch 7 | time in 0 minutes, 2 seconds | lr=0.006983\n",
            "\tLoss: 0.31185(train)\t|\tAcc: 87.31%(train)\n",
            "\tLoss: 0.01402(valid)\t|\tAcc: 85.74%(valid)\n",
            "Epoch 8 | time in 0 minutes, 2 seconds | lr=0.006634\n",
            "\tLoss: 0.31248(train)\t|\tAcc: 87.15%(train)\n",
            "\tLoss: 0.01085(valid)\t|\tAcc: 86.38%(valid)\n",
            "Epoch 9 | time in 0 minutes, 2 seconds | lr=0.006302\n",
            "\tLoss: 0.30168(train)\t|\tAcc: 87.32%(train)\n",
            "\tLoss: 0.01157(valid)\t|\tAcc: 87.50%(valid)\n",
            "Epoch 10 | time in 0 minutes, 2 seconds | lr=0.005987\n",
            "\tLoss: 0.29423(train)\t|\tAcc: 88.11%(train)\n",
            "\tLoss: 0.00894(valid)\t|\tAcc: 87.30%(valid)\n",
            "Epoch 11 | time in 0 minutes, 2 seconds | lr=0.005688\n",
            "\tLoss: 0.28473(train)\t|\tAcc: 88.31%(train)\n",
            "\tLoss: 0.01400(valid)\t|\tAcc: 85.94%(valid)\n",
            "Epoch 12 | time in 0 minutes, 2 seconds | lr=0.005404\n",
            "\tLoss: 0.28735(train)\t|\tAcc: 88.03%(train)\n",
            "\tLoss: 0.01334(valid)\t|\tAcc: 87.02%(valid)\n",
            "Epoch 13 | time in 0 minutes, 2 seconds | lr=0.005133\n",
            "\tLoss: 0.27042(train)\t|\tAcc: 89.06%(train)\n",
            "\tLoss: 0.00976(valid)\t|\tAcc: 87.62%(valid)\n",
            "Epoch 14 | time in 0 minutes, 2 seconds | lr=0.004877\n",
            "\tLoss: 0.27138(train)\t|\tAcc: 89.25%(train)\n",
            "\tLoss: 0.01147(valid)\t|\tAcc: 86.80%(valid)\n",
            "Epoch 15 | time in 0 minutes, 2 seconds | lr=0.004633\n",
            "\tLoss: 0.26162(train)\t|\tAcc: 89.48%(train)\n",
            "\tLoss: 0.00952(valid)\t|\tAcc: 87.90%(valid)\n",
            "Epoch 16 | time in 0 minutes, 2 seconds | lr=0.004401\n",
            "\tLoss: 0.25619(train)\t|\tAcc: 89.91%(train)\n",
            "\tLoss: 0.01195(valid)\t|\tAcc: 87.58%(valid)\n",
            "Epoch 17 | time in 0 minutes, 2 seconds | lr=0.004181\n",
            "\tLoss: 0.25205(train)\t|\tAcc: 89.78%(train)\n",
            "\tLoss: 0.01684(valid)\t|\tAcc: 87.04%(valid)\n",
            "Epoch 18 | time in 0 minutes, 2 seconds | lr=0.003972\n",
            "\tLoss: 0.24445(train)\t|\tAcc: 90.08%(train)\n",
            "\tLoss: 0.01710(valid)\t|\tAcc: 87.04%(valid)\n",
            "Epoch 19 | time in 0 minutes, 2 seconds | lr=0.003774\n",
            "\tLoss: 0.23108(train)\t|\tAcc: 90.96%(train)\n",
            "\tLoss: 0.01233(valid)\t|\tAcc: 87.54%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRvkncN09MKk"
      },
      "source": [
        "## 07-05 テストセット上で評価\n",
        "* 見つけ出したベストな設定を使って、テストセット上での最終的な評価をおこなう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_gHj4x38y8h",
        "outputId": "471964c0-2621-43e6-8799-499b17f5db99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Checking the results of test dataset...')\n",
        "test_loss, test_acc = test(test_iterator, model, criterion)\n",
        "print(f'\\tLoss: {test_loss:.5f}(test)\\t|\\tAcc: {test_acc * 100:.2f}%(test)')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset...\n",
            "\tLoss: 0.00203(test)\t|\tAcc: 87.52%(test)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1M_VQ1xhcWq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}