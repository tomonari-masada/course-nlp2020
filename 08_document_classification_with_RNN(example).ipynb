{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_document_classification_with_RNN(example).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YuXSNk4hZvSEWs-EOnuLB0EyNzBToxpe",
      "authorship_tag": "ABX9TyNtJ+7xZRcZKDOqP2vmK4bI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/08_document_classification_with_RNN(example).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtbbXGNJnJQB"
      },
      "source": [
        "# 08 RNNを使った文書分類\n",
        "* RNNの出力を文書の潜在表現として利用し、文書分類を行う"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6pvVYxeoOqB"
      },
      "source": [
        "## 08-01 torchtextを使ってIMDbデータを読み込む\n",
        "* ここでIMDbデータセットの読み込みにつかう`torchtext.datasets`については、下記を参照。\n",
        " * https://torchtext.readthedocs.io/en/latest/datasets.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8X-GEo5nqdK"
      },
      "source": [
        "### 実験の再現性確保のための設定など\n",
        "* https://pytorch.org/docs/stable/notes/randomness.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VicF1RrhJfa"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext import datasets\n",
        "from torchtext.data import Field, LabelField, BucketIterator\n",
        "\n",
        "SEED = 123\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.set_deterministic(True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeCGHBNAojNh"
      },
      "source": [
        "### torchtextのフィールド\n",
        "* TEXTフィールドと、LABELフィールドという２種類のFieldオブジェクトのインスタンスを作る。\n",
        " * Fieldクラスの詳細については[ここ](https://github.com/pytorch/text/blob/master/torchtext/data/field.py)を参照。\n",
        "* TEXTフィールドは、テキストの前処理の仕方を決めておくのに使う。\n",
        "* LABELフィールドは、ラベルの前処理に使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jug86Tt9hMMD"
      },
      "source": [
        "TEXT = Field(tokenize=\"spacy\")\n",
        "LABEL = LabelField()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TaaTUp6on2x"
      },
      "source": [
        "### IMDbデータセットをダウンロードした後、前処理しつつ読み込む\n",
        "* ダウンロードはすぐ終わるが、解凍に少し時間がかかる。\n",
        "* また、TEXTフィールドでspaCyのtokenizationを使うように設定したので、少し時間がかかる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj6XmwLXhVKv"
      },
      "source": [
        "train_valid_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11FpCyLWotGK"
      },
      "source": [
        "### テストセット以外の部分を訓練データと検証データに分ける"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Xd-UDohXcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62900710-23bd-424c-8684-1af2841687b0"
      },
      "source": [
        "train_data, valid_data = train_valid_data.split(split_ratio=0.8)\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lohYcCzUo2K6"
      },
      "source": [
        "### データセットの語彙とラベルを作る\n",
        "* TEXTラベルのほうでは、最大語彙サイズを指定する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zblGelVrheSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e36f63b-ed20-4da7-b835-311b4de96829"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rEsKP_u3fVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de7064ae-b52e-470b-93a2-e94d0042cee3"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyr7J_E4hg6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d330cd1-cc01-410e-f677-da9538785bad"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 231681), (',', 220513), ('.', 189315), ('and', 125380), ('a', 124937), ('of', 115088), ('to', 107165), ('is', 87305), ('in', 70009), ('I', 61800), ('it', 61302), ('that', 56289), ('\"', 50495), (\"'s\", 49496), ('this', 48345), ('-', 42165), ('/><br', 40918), ('was', 39731), ('as', 34712), ('with', 34376)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqr48rCVp1Tf"
      },
      "source": [
        "### デバイスの取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fXYLKJvkX1m"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDjU2ykppyi2"
      },
      "source": [
        "### ミニバッチを取り出すためのiteratorを作る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZKysnlAhjGS"
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "\n",
        "train_iterator = BucketIterator(train_data, batch_size=BATCH_SIZE, device=device,\n",
        "                                     sort_within_batch=True, shuffle=True, sort_key=lambda x: len(x.text))\n",
        "valid_iterator = BucketIterator(valid_data, batch_size=BATCH_SIZE, device=device)\n",
        "test_iterator = BucketIterator(test_data, batch_size=BATCH_SIZE, device=device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ0yHMt4puyA"
      },
      "source": [
        "### 定数の設定\n",
        "* 単語埋め込みの次元もRNNの隠れ状態の次元も128に増やす。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_3KWMr4hwxl"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "NUM_CLASS = len(LABEL.vocab)\n",
        "EMBED_DIM = 128\n",
        "HIDDEN_DIM = 128\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57xqsnpTnE_c"
      },
      "source": [
        "### モデルの定義\n",
        "* GRUを使う。\n",
        "* レイヤー数は2にする。\n",
        "* gradientのクリッピングはしないことにしたので削除。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1wcVHcmg9KI"
      },
      "source": [
        "class RNNTextSentiment(nn.Module):\n",
        "  def __init__(self, emb_dim, hid_dim,\n",
        "               num_class, vocab_size, padding_idx, p=0.0):\n",
        "    super().__init__()\n",
        "\n",
        "    self.input_dim = vocab_size\n",
        "    self.emb_dim = emb_dim\n",
        "    self.hid_dim = hid_dim\n",
        "    self.padding_idx = padding_idx\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=padding_idx)\n",
        "    self.rnn = nn.GRU(emb_dim, hid_dim, num_layers=2)\n",
        "    self.fc = nn.Linear(hid_dim * 2, num_class)\n",
        "    self.dropout = nn.Dropout(p=p)\n",
        "\n",
        "  def forward(self, src):\n",
        "    # srcの形は[単語列長, バッチサイズ]\n",
        "\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "    # embeddedの形は[単語列長, バッチサイズ, 埋め込み次元数]\n",
        "\n",
        "    outputs, hidden = self.rnn(embedded)\n",
        "    # outputsの形は[単語列長, バッチサイズ, 隠れ状態の次元数]\n",
        "    # hiddenの形は[レイヤー数, バッチサイズ, 隠れ状態の次元数]\n",
        "\n",
        "    # 平均を正確に計算する\n",
        "    mask = (src != self.padding_idx)\n",
        "    mean_outputs = (outputs * mask.unsqueeze(2)).sum(0) / mask.sum(0).unsqueeze(1)\n",
        "    hidden = hidden[-1,:,:].squeeze()\n",
        "    # mean_outputsの形は[バッチサイズ, 隠れ状態の次元数]\n",
        "    # hiddenの形は[バッチサイズ, 隠れ状態の次元数]\n",
        "    output = self.fc(torch.cat((mean_outputs, hidden), dim=1))\n",
        "\n",
        "    return output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLo4vO0IrR62"
      },
      "source": [
        "* モデルのインスタンスを得る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuW6ghef34R4"
      },
      "source": [
        "model = RNNTextSentiment(EMBED_DIM, HIDDEN_DIM, NUM_CLASS, INPUT_DIM,\n",
        "                         padding_idx=PAD_IDX, p=0.5).to(device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEJuFU2p4HWf"
      },
      "source": [
        "* 重みの初期化もデフォルトのままで使う。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S9TDJpIraUM"
      },
      "source": [
        "### 最適化アルゴリズムの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaEbLC9T4pxb"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t427SeakeqVP"
      },
      "source": [
        "パラメータの数を数えてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h06O037X4vRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab667e5-8406-4b07-e832-30f58d46e23f"
      },
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,398,914 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwMV61kTri4-"
      },
      "source": [
        "### 文書分類の損失関数の設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5w-1q7u47Ax"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iScb7iZSs2nY"
      },
      "source": [
        "### 訓練用の関数\n",
        "* gradientクリッピングはしないことにする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg1tuw6y4-Or"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  model.train()\n",
        "  epoch_loss = 0.\n",
        "  epoch_acc = 0.\n",
        "  for batch in iterator:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(batch.text)\n",
        "    loss = criterion(output, batch.label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += (output.argmax(1) == batch.label).sum().item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator.dataset)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBoo_Ez6s9Gs"
      },
      "source": [
        "### 評価用の関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qmfP-By5fOm"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0.\n",
        "  epoch_acc = 0.\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      output = model(batch.text)\n",
        "      loss = criterion(output, batch.label)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += (output.argmax(1) == batch.label).sum().item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator.dataset)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcPnwzJz5rnV"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-zS3zIa4roH"
      },
      "source": [
        "### 学習の実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioV2XRKG5tf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b59718a-71d3-46d8-e3ef-5c2f0fa74dd4"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  print(f'Epoch {epoch} | time in {epoch_mins} minutes, {epoch_secs} seconds')\n",
        "  print(f'\\tLoss {train_loss:.4f} (train)\\t|\\tAcc {train_acc * 100:.1f}% (train)')\n",
        "  print(f'\\tLoss {valid_loss:.4f} (valid)\\t|\\tAcc {valid_acc * 100:.1f}% (valid)')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.5992 (train)\t|\tAcc 66.3% (train)\n",
            "\tLoss 0.5069 (valid)\t|\tAcc 76.1% (valid)\n",
            "Epoch 2 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.4455 (train)\t|\tAcc 79.4% (train)\n",
            "\tLoss 0.4076 (valid)\t|\tAcc 82.7% (valid)\n",
            "Epoch 3 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.3592 (train)\t|\tAcc 84.4% (train)\n",
            "\tLoss 0.4468 (valid)\t|\tAcc 80.7% (valid)\n",
            "Epoch 4 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.3084 (train)\t|\tAcc 86.8% (train)\n",
            "\tLoss 0.3131 (valid)\t|\tAcc 88.1% (valid)\n",
            "Epoch 5 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.2734 (train)\t|\tAcc 88.9% (train)\n",
            "\tLoss 0.2964 (valid)\t|\tAcc 88.6% (valid)\n",
            "Epoch 6 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.2549 (train)\t|\tAcc 89.7% (train)\n",
            "\tLoss 0.3079 (valid)\t|\tAcc 88.8% (valid)\n",
            "Epoch 7 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.2258 (train)\t|\tAcc 90.9% (train)\n",
            "\tLoss 0.2982 (valid)\t|\tAcc 89.1% (valid)\n",
            "Epoch 8 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.2086 (train)\t|\tAcc 91.9% (train)\n",
            "\tLoss 0.3062 (valid)\t|\tAcc 88.6% (valid)\n",
            "Epoch 9 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.1802 (train)\t|\tAcc 92.8% (train)\n",
            "\tLoss 0.3038 (valid)\t|\tAcc 89.3% (valid)\n",
            "Epoch 10 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.1715 (train)\t|\tAcc 93.4% (train)\n",
            "\tLoss 0.3194 (valid)\t|\tAcc 89.5% (valid)\n",
            "Epoch 11 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.1607 (train)\t|\tAcc 93.9% (train)\n",
            "\tLoss 0.3133 (valid)\t|\tAcc 89.8% (valid)\n",
            "Epoch 12 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.1484 (train)\t|\tAcc 94.3% (train)\n",
            "\tLoss 0.3260 (valid)\t|\tAcc 90.0% (valid)\n",
            "Epoch 13 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.1346 (train)\t|\tAcc 95.1% (train)\n",
            "\tLoss 0.3022 (valid)\t|\tAcc 90.1% (valid)\n",
            "Epoch 14 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.1218 (train)\t|\tAcc 95.4% (train)\n",
            "\tLoss 0.3368 (valid)\t|\tAcc 89.6% (valid)\n",
            "Epoch 15 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.1119 (train)\t|\tAcc 95.7% (train)\n",
            "\tLoss 0.3469 (valid)\t|\tAcc 89.3% (valid)\n",
            "Epoch 16 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.1073 (train)\t|\tAcc 96.0% (train)\n",
            "\tLoss 0.3555 (valid)\t|\tAcc 89.7% (valid)\n",
            "Epoch 17 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.1010 (train)\t|\tAcc 96.2% (train)\n",
            "\tLoss 0.3659 (valid)\t|\tAcc 90.3% (valid)\n",
            "Epoch 18 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.0854 (train)\t|\tAcc 96.8% (train)\n",
            "\tLoss 0.3614 (valid)\t|\tAcc 89.9% (valid)\n",
            "Epoch 19 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.0869 (train)\t|\tAcc 96.7% (train)\n",
            "\tLoss 0.3851 (valid)\t|\tAcc 89.5% (valid)\n",
            "Epoch 20 | time in 0 minutes, 21 seconds\n",
            "\tLoss 0.0775 (train)\t|\tAcc 97.1% (train)\n",
            "\tLoss 0.3579 (valid)\t|\tAcc 90.3% (valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6YesZ-c4mZ-"
      },
      "source": [
        "### テストデータで評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8ju77-HEhVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc43a65-b331-428c-fd61-551005cc0633"
      },
      "source": [
        "print('Checking the results of test dataset...')\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "print(f'\\tLoss: {test_loss:.5f}(test)\\t|\\tAcc: {test_acc * 100:.2f}%(test)')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset...\n",
            "\tLoss: 0.42087(test)\t|\tAcc: 88.10%(test)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoRugHpg2fwC"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}