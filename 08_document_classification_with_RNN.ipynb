{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_document_classification_with_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1HaIOpOtFSc4pjrdAglJT6cjgfkrJQIQ4",
      "authorship_tag": "ABX9TyPTbyJ2txUlu/c9kgd6gwEa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/08_document_classification_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtbbXGNJnJQB"
      },
      "source": [
        "# 08 RNNを使った文書分類\n",
        "* RNNの出力を文書の潜在表現として利用し、文書分類を行う"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6pvVYxeoOqB"
      },
      "source": [
        "## 08-01 torchtextを使ってIMDbデータを読み込む\n",
        "* ここでIMDbデータセットの読み込みにつかう`torchtext.datasets`については、下記を参照。\n",
        " * https://torchtext.readthedocs.io/en/latest/datasets.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8X-GEo5nqdK"
      },
      "source": [
        "### 実験の再現性確保のための設定など\n",
        "* https://pytorch.org/docs/stable/notes/randomness.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VicF1RrhJfa"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext import datasets\n",
        "from torchtext.data import Field, LabelField, BucketIterator\n",
        "\n",
        "SEED = 123\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.set_deterministic(True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeCGHBNAojNh"
      },
      "source": [
        "### torchtextのフィールド\n",
        "* TEXTフィールドと、LABELフィールドという２種類のFieldオブジェクトのインスタンスを作る。\n",
        " * Fieldクラスの詳細については[ここ](https://github.com/pytorch/text/blob/master/torchtext/data/field.py)を参照。\n",
        "* TEXTフィールドは、テキストの前処理の仕方を決めておくのに使う。\n",
        "* LABELフィールドは、ラベルの前処理に使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jug86Tt9hMMD"
      },
      "source": [
        "TEXT = Field(tokenize=\"spacy\")\n",
        "LABEL = LabelField()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TaaTUp6on2x"
      },
      "source": [
        "### IMDbデータセットをダウンロードした後、前処理しつつ読み込む\n",
        "* ダウンロードはすぐ終わるが、解凍に少し時間がかかる。\n",
        "* また、TEXTフィールドでspaCyのtokenizationを使うように設定したので、少し時間がかかる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj6XmwLXhVKv",
        "outputId": "c3a4a902-e644-4ede-e791-d11f22cb9cbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_valid_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 23.0MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11FpCyLWotGK"
      },
      "source": [
        "### テストセット以外の部分を訓練データと検証データに分ける"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Xd-UDohXcx",
        "outputId": "e965adc9-e4de-449e-d70a-b8288375592a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data, valid_data = train_valid_data.split(split_ratio=0.8)\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lohYcCzUo2K6"
      },
      "source": [
        "### データセットの語彙とラベルを作る\n",
        "* TEXTラベルのほうでは、最大語彙サイズを指定する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zblGelVrheSs",
        "outputId": "b05eec68-c028-4d35-8e1b-9bf51c59a27b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rEsKP_u3fVu",
        "outputId": "ea99010c-4584-4b75-bc35-3b44bffd9a4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyr7J_E4hg6V",
        "outputId": "c05a6dac-adae-45b8-ef3c-a66d18633e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 231967), (',', 220822), ('.', 189768), ('a', 125308), ('and', 125211), ('of', 115201), ('to', 107546), ('is', 87468), ('in', 70357), ('I', 62046), ('it', 61426), ('that', 56383), ('\"', 50715), (\"'s\", 49689), ('this', 48354), ('-', 42279), ('/><br', 40939), ('was', 40261), ('as', 34887), ('with', 34271)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqr48rCVp1Tf"
      },
      "source": [
        "### デバイスの取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fXYLKJvkX1m"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDjU2ykppyi2"
      },
      "source": [
        "### ミニバッチを取り出すためのiteratorを作る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZKysnlAhjGS"
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "\n",
        "train_iterator = BucketIterator(train_data, batch_size=BATCH_SIZE, device=device,\n",
        "                                     sort_within_batch=True, shuffle=True, sort_key=lambda x: len(x.text))\n",
        "valid_iterator = BucketIterator(valid_data, batch_size=BATCH_SIZE, device=device)\n",
        "test_iterator = BucketIterator(test_data, batch_size=BATCH_SIZE, device=device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ0yHMt4puyA"
      },
      "source": [
        "### 定数の設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_3KWMr4hwxl"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "NUM_CLASS = len(LABEL.vocab)\n",
        "EMBED_DIM = 64\n",
        "HIDDEN_DIM = 64\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57xqsnpTnE_c"
      },
      "source": [
        "### モデルの定義\n",
        "* LSTMを使う（GRUに変えても良い）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1wcVHcmg9KI"
      },
      "source": [
        "class RNNTextSentiment(nn.Module):\n",
        "  def __init__(self, emb_dim, hid_dim,\n",
        "               num_class, vocab_size, padding_idx, p=0.0):\n",
        "    super().__init__()\n",
        "\n",
        "    self.input_dim = vocab_size\n",
        "    self.emb_dim = emb_dim\n",
        "    self.hid_dim = hid_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=padding_idx)\n",
        "    self.rnn = nn.LSTM(emb_dim, hid_dim)\n",
        "    self.fc = nn.Linear(hid_dim * 2, num_class)\n",
        "    self.dropout = nn.Dropout(p=p)\n",
        "\n",
        "  def forward(self, src):\n",
        "    # srcの形は[単語列長, バッチサイズ]\n",
        "\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "    # embeddedの形は[単語列長, バッチサイズ, 埋め込み次元数]\n",
        "\n",
        "    outputs, (hidden, _) = self.rnn(embedded)\n",
        "    # outputsの形は[単語列長, バッチサイズ, 隠れ状態の次元数]\n",
        "    # hiddenの形は[1, バッチサイズ, 隠れ状態の次元数]\n",
        "\n",
        "    mean_outputs = outputs.mean(0)\n",
        "    hidden = hidden.squeeze()\n",
        "    # mean_outputsの形は[バッチサイズ, 隠れ状態の次元数]\n",
        "    # hiddenの形は[バッチサイズ, 隠れ状態の次元数]\n",
        "    output = self.fc(torch.cat((mean_outputs, hidden), dim=1))\n",
        "\n",
        "    return output"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZLDlFWMqsZj"
      },
      "source": [
        "### 重みの初期化はこのような方法でも可能\n",
        "* 関数を定義しておき、applyする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0nkUyLx3xDZ"
      },
      "source": [
        "def init_weights(m):\n",
        "  for name, param in m.named_parameters():\n",
        "    if 'weight' in name:\n",
        "      nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "    else:\n",
        "      nn.init.constant_(param.data, 0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLo4vO0IrR62"
      },
      "source": [
        "* モデルのインスタンスを得る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuW6ghef34R4"
      },
      "source": [
        "model = RNNTextSentiment(EMBED_DIM, HIDDEN_DIM, NUM_CLASS, INPUT_DIM,\n",
        "                         padding_idx=PAD_IDX, p=0.5).to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fJkM3QLrUGN"
      },
      "source": [
        "* 重みの初期化を実行する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnUstTZe4X2x",
        "outputId": "c3152206-86b7-49fe-b12c-eb89fa3e1d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.apply(init_weights)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNTextSentiment(\n",
              "  (embedding): Embedding(25002, 64, padding_idx=1)\n",
              "  (rnn): LSTM(64, 64)\n",
              "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRp5h3wQrMib"
      },
      "source": [
        "* バイアスがゼロに初期化されているか確認してみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8pvIjJ2rC_g",
        "outputId": "dbcae7d7-f4cd-4b6b-bd8d-b19694deb6f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "  for name, param in model.named_parameters():\n",
        "    if 'weight' not in name:\n",
        "      print(param.data)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0')\n",
            "tensor([0., 0.], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S9TDJpIraUM"
      },
      "source": [
        "### 最適化アルゴリズムの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaEbLC9T4pxb"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t427SeakeqVP"
      },
      "source": [
        "パラメータの数を数えてみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h06O037X4vRV",
        "outputId": "58594067-d216-4cb6-c237-2054b5a72f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,633,666 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwMV61kTri4-"
      },
      "source": [
        "### 文書分類の損失関数の設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5w-1q7u47Ax"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iScb7iZSs2nY"
      },
      "source": [
        "### 訓練用の関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg1tuw6y4-Or"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "  model.train()\n",
        "  epoch_loss = 0.\n",
        "  epoch_acc = 0.\n",
        "  for batch in iterator:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(batch.text)\n",
        "    loss = criterion(output, batch.label)\n",
        "    loss.backward()\n",
        "\n",
        "    # RNNではgradientのクリッピングをよく行う\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += (output.argmax(1) == batch.label).sum().item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator.dataset)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBoo_Ez6s9Gs"
      },
      "source": [
        "### 評価用の関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qmfP-By5fOm"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0.\n",
        "  epoch_acc = 0.\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      output = model(batch.text)\n",
        "      loss = criterion(output, batch.label)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += (output.argmax(1) == batch.label).sum().item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator.dataset)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcPnwzJz5rnV"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time // 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioV2XRKG5tf-",
        "outputId": "7ff709d0-ee87-43e9-bf8d-a93078bb50a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1.\n",
        "\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  print(f'Epoch {epoch} | time in {epoch_mins} minutes, {epoch_secs} seconds')\n",
        "  print(f'\\tLoss {train_loss:.4f} (train)\\t|\\tAcc {train_acc * 100:.1f}% (train)')\n",
        "  print(f'\\tLoss {valid_loss:.4f} (valid)\\t|\\tAcc {valid_acc * 100:.1f}% (valid)')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 | time in 0 minutes, 5 seconds\n",
            "\tLoss 0.4897 (train)\t|\tAcc 73.6% (train)\n",
            "\tLoss 0.4209 (valid)\t|\tAcc 84.7% (valid)\n",
            "Epoch 2 | time in 0 minutes, 5 seconds\n",
            "\tLoss 0.2259 (train)\t|\tAcc 91.3% (train)\n",
            "\tLoss 0.3947 (valid)\t|\tAcc 84.6% (valid)\n",
            "Epoch 3 | time in 0 minutes, 5 seconds\n",
            "\tLoss 0.1476 (train)\t|\tAcc 94.6% (train)\n",
            "\tLoss 1.2046 (valid)\t|\tAcc 58.9% (valid)\n",
            "Epoch 4 | time in 0 minutes, 5 seconds\n",
            "\tLoss 0.1040 (train)\t|\tAcc 96.5% (train)\n",
            "\tLoss 2.4215 (valid)\t|\tAcc 50.9% (valid)\n",
            "Epoch 5 | time in 0 minutes, 5 seconds\n",
            "\tLoss 0.0923 (train)\t|\tAcc 97.1% (train)\n",
            "\tLoss 2.9550 (valid)\t|\tAcc 51.7% (valid)\n",
            "Epoch 6 | time in 0 minutes, 5 seconds\n",
            "\tLoss 0.0552 (train)\t|\tAcc 98.1% (train)\n",
            "\tLoss 1.1674 (valid)\t|\tAcc 58.4% (valid)\n",
            "Epoch 7 | time in 0 minutes, 5 seconds\n",
            "\tLoss 0.0459 (train)\t|\tAcc 98.4% (train)\n",
            "\tLoss 0.3531 (valid)\t|\tAcc 85.6% (valid)\n",
            "Epoch 8 | time in 0 minutes, 5 seconds\n",
            "\tLoss 0.0335 (train)\t|\tAcc 98.9% (train)\n",
            "\tLoss 1.3724 (valid)\t|\tAcc 83.4% (valid)\n",
            "Epoch 9 | time in 0 minutes, 5 seconds\n",
            "\tLoss 0.0223 (train)\t|\tAcc 99.2% (train)\n",
            "\tLoss 0.8068 (valid)\t|\tAcc 61.1% (valid)\n",
            "Epoch 10 | time in 0 minutes, 5 seconds\n",
            "\tLoss 0.0228 (train)\t|\tAcc 99.3% (train)\n",
            "\tLoss 0.3660 (valid)\t|\tAcc 85.1% (valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8ju77-HEhVW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}