{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_document_classification_with_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1HaIOpOtFSc4pjrdAglJT6cjgfkrJQIQ4",
      "authorship_tag": "ABX9TyMEflv2rpLd9ZJ6Z99YLswo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/08_document_classification_with_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VicF1RrhJfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "SEED = 123\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jug86Tt9hMMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = Field(tokenize = \"spacy\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj6XmwLXhVKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_valid_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Xd-UDohXcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ca21f917-4ab9-40ba-c609-5ebd24516a22"
      },
      "source": [
        "train_data, valid_data = train_valid_data.split(split_ratio=0.8, random_state = random.seed(SEED))\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zblGelVrheSs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "53ee17e5-947c-4a12-8e7e-4b73d5f29b28"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25004\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rEsKP_u3fVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ec68c98-79a9-428e-aded-f6be390ddb9f"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', '<sos>', '<eos>', 'the', ',', '.', 'and', 'a', 'of']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyr7J_E4hg6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5eeb9dac-14a8-49ec-be13-a8552f813779"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 263353), (',', 220515), ('.', 189706), ('and', 130737), ('a', 129741), ('of', 116262), ('to', 108619), ('is', 87772), ('it', 74780), ('in', 74341), ('i', 66293), ('this', 58689), ('that', 58620), ('\"', 50102), (\"'s\", 49819), ('-', 42239), ('/><br', 40900), ('was', 40501), ('as', 37056), ('with', 35260)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fXYLKJvkX1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZKysnlAhjGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_3KWMr4hwxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "NUM_CLASS = len(LABEL.vocab)\n",
        "EMBED_DIM = 64\n",
        "HIDDEN_DIM = 64\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlrQK9hh2_KN",
        "colab_type": "text"
      },
      "source": [
        "### 念のためモデルを定義する前に埋め込み層の動作を確認\n",
        "* padding用のトークンがどのように埋め込まれるかを確認。\n",
        "* また、埋め込み層を通ったあとにミニバッチの形がどうなるかを確認。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK1k_4oQLS54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed = nn.Embedding(INPUT_DIM, EMBED_DIM, padding_idx=PAD_IDX).to(device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQHlxKpohxQY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a16e317b-23b9-46b2-fbf4-b35006da77f1"
      },
      "source": [
        "for batch in valid_iterator:\n",
        "  pass\n",
        "print(batch)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[torchtext.data.batch.Batch of size 100]\n",
            "\t[.text]:[torch.cuda.LongTensor of size 1991x100 (GPU 0)]\n",
            "\t[.label]:[torch.cuda.LongTensor of size 100 (GPU 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teSjeZJGMVGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a6c4527-0077-4bbb-a7ae-79c225807da5"
      },
      "source": [
        "embed(batch.text).shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1991, 100, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1wcVHcmg9KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNTextSentiment(nn.Module):\n",
        "  def __init__(self, emb_dim, hid_dim,\n",
        "               num_class, vocab_size, padding_idx, p=0.0):\n",
        "    super().__init__()\n",
        "\n",
        "    self.input_dim = vocab_size\n",
        "    self.emb_dim = emb_dim\n",
        "    self.hid_dim = hid_dim\n",
        "    self.dropout = p\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=padding_idx)\n",
        "    self.rnn = nn.LSTM(emb_dim, hid_dim)\n",
        "    self.fc = nn.Linear(hid_dim * 2, num_class)\n",
        "    self.dropout = nn.Dropout(p=p)\n",
        "\n",
        "  def forward(self, src):\n",
        "    # srcの形は[単語列長, バッチサイズ]\n",
        "\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "    # embeddedの形は[単語列長, バッチサイズ, 埋め込み次元数]\n",
        "\n",
        "    outputs, (hidden, _) = self.rnn(embedded)\n",
        "    # outputsの形は[単語列長, バッチサイズ, 隠れ状態の次元数]\n",
        "    # hiddenの形は[1, バッチサイズ, 隠れ状態の次元数]\n",
        "\n",
        "    mean_outputs = outputs.mean(0)\n",
        "    hidden = hidden.squeeze()\n",
        "    # mean_outputsの形は[バッチサイズ, 隠れ状態の次元数]\n",
        "    # hiddenの形は[バッチサイズ, 隠れ状態の次元数]\n",
        "    output = self.fc(torch.cat((mean_outputs, hidden), dim=1))\n",
        "\n",
        "    return output"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0nkUyLx3xDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "  for name, param in m.named_parameters():\n",
        "    if 'weight' in name:\n",
        "      nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "    else:\n",
        "      nn.init.constant_(param.data, 0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuW6ghef34R4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RNNTextSentiment(EMBED_DIM, HIDDEN_DIM, NUM_CLASS, INPUT_DIM,\n",
        "                         padding_idx=PAD_IDX, p=0.5).to(device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnUstTZe4X2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "64e3d872-ff0b-4fcc-efdd-558a02512762"
      },
      "source": [
        "model.apply(init_weights)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNTextSentiment(\n",
              "  (embedding): Embedding(25004, 64, padding_idx=1)\n",
              "  (rnn): LSTM(64, 64)\n",
              "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaEbLC9T4pxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h06O037X4vRV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d728546f-b625-42a3-bee9-958eef235303"
      },
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,633,794 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5w-1q7u47Ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg1tuw6y4-Or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "  model.train()\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  for batch in iterator:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(batch.text)\n",
        "    loss = criterion(output, batch.label)\n",
        "    loss.backward()\n",
        "\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += (output.argmax(1) == batch.label).sum().item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator.dataset)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qmfP-By5fOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "  model.eval()\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      output = model(batch.text)\n",
        "      loss = criterion(output, batch.label)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += (output.argmax(1) == batch.label).sum().item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator.dataset)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcPnwzJz5rnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioV2XRKG5tf-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "52d0fdcf-d24c-4ee6-bf6e-9cc07a90b8bf"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  print('Epoch: %d' %(epoch), \" | time in %d minutes, %d seconds\" %(epoch_mins, epoch_secs))\n",
        "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.5937(train)\t|\tAcc: 67.1%(train)\n",
            "\tLoss: 0.4733(valid)\t|\tAcc: 78.9%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.3863(train)\t|\tAcc: 85.6%(train)\n",
            "\tLoss: 0.4109(valid)\t|\tAcc: 82.7%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.3101(train)\t|\tAcc: 89.3%(train)\n",
            "\tLoss: 0.4228(valid)\t|\tAcc: 82.5%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.2854(train)\t|\tAcc: 89.6%(train)\n",
            "\tLoss: 0.5056(valid)\t|\tAcc: 81.8%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.2450(train)\t|\tAcc: 91.8%(train)\n",
            "\tLoss: 0.5643(valid)\t|\tAcc: 81.8%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 12 seconds\n",
            "\tLoss: 0.2341(train)\t|\tAcc: 92.7%(train)\n",
            "\tLoss: 0.4690(valid)\t|\tAcc: 81.6%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.2112(train)\t|\tAcc: 93.7%(train)\n",
            "\tLoss: 0.5632(valid)\t|\tAcc: 80.2%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 12 seconds\n",
            "\tLoss: 0.2332(train)\t|\tAcc: 92.2%(train)\n",
            "\tLoss: 0.5567(valid)\t|\tAcc: 82.1%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.1636(train)\t|\tAcc: 95.3%(train)\n",
            "\tLoss: 0.6356(valid)\t|\tAcc: 81.6%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.1335(train)\t|\tAcc: 96.1%(train)\n",
            "\tLoss: 0.6208(valid)\t|\tAcc: 81.9%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjinWg5C59Bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBED_DIM = 32\n",
        "HIDDEN_DIM = 32\n",
        "model = RNNTextSentiment(EMBED_DIM, HIDDEN_DIM, NUM_CLASS, INPUT_DIM,\n",
        "                         padding_idx=PAD_IDX, p=0.5).to(device)\n",
        "model.apply(init_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0003)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGo0eCFYEXQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "eefe920a-be26-463f-baef-86eab14b0446"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  print('Epoch: %d' %(epoch), \" | time in %d minutes, %d seconds\" %(epoch_mins, epoch_secs))\n",
        "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.6931(train)\t|\tAcc: 50.6%(train)\n",
            "\tLoss: 0.6912(valid)\t|\tAcc: 67.3%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.6082(train)\t|\tAcc: 69.9%(train)\n",
            "\tLoss: 0.5431(valid)\t|\tAcc: 74.7%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.5073(train)\t|\tAcc: 78.9%(train)\n",
            "\tLoss: 0.4820(valid)\t|\tAcc: 78.4%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.4405(train)\t|\tAcc: 83.0%(train)\n",
            "\tLoss: 0.4322(valid)\t|\tAcc: 81.6%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.3871(train)\t|\tAcc: 86.1%(train)\n",
            "\tLoss: 0.4101(valid)\t|\tAcc: 82.9%(valid)\n",
            "Epoch: 6  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.3477(train)\t|\tAcc: 88.1%(train)\n",
            "\tLoss: 0.4135(valid)\t|\tAcc: 82.6%(valid)\n",
            "Epoch: 7  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.3128(train)\t|\tAcc: 89.7%(train)\n",
            "\tLoss: 0.3922(valid)\t|\tAcc: 83.7%(valid)\n",
            "Epoch: 8  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.2904(train)\t|\tAcc: 90.7%(train)\n",
            "\tLoss: 0.4027(valid)\t|\tAcc: 83.6%(valid)\n",
            "Epoch: 9  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.2629(train)\t|\tAcc: 92.0%(train)\n",
            "\tLoss: 0.3943(valid)\t|\tAcc: 84.0%(valid)\n",
            "Epoch: 10  | time in 0 minutes, 11 seconds\n",
            "\tLoss: 0.2399(train)\t|\tAcc: 92.9%(train)\n",
            "\tLoss: 0.3730(valid)\t|\tAcc: 84.9%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8ju77-HEhVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}