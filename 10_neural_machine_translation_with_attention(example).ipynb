{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_neural_machine_translation_with_attention(example).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1vVNfdhqcWqkpZt49h9DAnDrlAy7wBB2m",
      "authorship_tag": "ABX9TyOgq57QY8F35BETSdau72Wd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course-nlp2020/blob/master/10_neural_machine_translation_with_attention(example).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pNcU5MTKZBT"
      },
      "source": [
        "! python -m spacy download fr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrtPBRi4TU91"
      },
      "source": [
        "## 10-01 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9yTsgs-NQVK"
      },
      "source": [
        "### 必要なモジュール、パッケージ等をインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI1RJEjYHLfw"
      },
      "source": [
        "import sys\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIYWe0f0KOQU"
      },
      "source": [
        "### 再現性確保のための設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T44T8MSgKImf"
      },
      "source": [
        "SEED = 123\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.set_deterministic(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkYH4EH9KXXf"
      },
      "source": [
        "spacy.load(\"fr\")\n",
        "spacy.load(\"en\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ju9jMzMWKjE"
      },
      "source": [
        "### torchtext.dataのフィールドを作成\n",
        "* 翻訳元のテキストと、翻訳先のテキストそれぞれについて、フィールドを作成。\n",
        "* tokenizationはいずれもspaCyにする。\n",
        "* init_tokenとeos_tokenを指定する。\n",
        "* 大文字はすべて小文字にしてしまう。\n",
        " * 本格的な翻訳システムを作る場合は、大文字を小文字にするのはNG。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KRhwP-YL2e2"
      },
      "source": [
        "SRC = Field(tokenize=\"spacy\",\n",
        "            init_token=\"<sos>\",\n",
        "            eos_token=\"<eos>\",\n",
        "            lower=True)\n",
        "\n",
        "TRG = Field(tokenize=\"spacy\",\n",
        "            init_token=\"<sos>\",\n",
        "            eos_token=\"<eos>\",\n",
        "            lower=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VldMniaNWj32"
      },
      "source": [
        "### 訓練データ、検証データ、テストデータを用意する\n",
        "* 今回は、Multi30k Data Repositoryというデータセットから、仏英翻訳の部分を使う。 \n",
        " * https://github.com/multi30k/dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeiJRoXa88NN"
      },
      "source": [
        "Multi30k.download('.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJjZrS6TA2uG"
      },
      "source": [
        "* フランス語のデータはgithubから手動でダウンロードし、解凍。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJq2iHnW_EZT"
      },
      "source": [
        "!wget https://github.com/multi30k/dataset/raw/master/data/task1/raw/train.fr.gz\n",
        "!gunzip train.fr.gz\n",
        "!mv train.fr ./multi30k/\n",
        "!wget https://github.com/multi30k/dataset/raw/master/data/task1/raw/val.fr.gz\n",
        "!gunzip val.fr.gz\n",
        "!mv val.fr ./multi30k/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efE1L6R_MAl9"
      },
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(path='./multi30k/', exts=('.fr', '.en'), fields=(SRC, TRG))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDuW8nnVMFpw"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5jkHSquP9yg"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrk08u0lQEcd"
      },
      "source": [
        "print(train_data.examples[0].src)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j32KusxQHHB"
      },
      "source": [
        "print(train_data.examples[0].trg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZehsUcUoea_j"
      },
      "source": [
        "### 語彙を構築する\n",
        "* 出現頻度が1回の単語はすべて未知語としてまとめてしまう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg9SAjK4QJwI"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=1)\n",
        "TRG.build_vocab(train_data, min_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEowfwRIQheL"
      },
      "source": [
        "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCcc69eGWhYI"
      },
      "source": [
        "* 語彙のうちID順で最初の２つは、やはり特殊な単語になっている。\n",
        " * `<unk>`は未知語\n",
        " * `<pad>`はパディング用の単語"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGrB-P4OWYhs"
      },
      "source": [
        "print(SRC.vocab.itos[:10])\n",
        "print(TRG.vocab.itos[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fevK59J7eiXv"
      },
      "source": [
        "### デバイスを設定する\n",
        "* GPUが使えるなら使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTVgcacYQklu"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBhn4hgPemXG"
      },
      "source": [
        "### ミニバッチを取り出すイテレータを作る\n",
        "* ミニバッチのshapeは、[単語列長, ミニバッチの大きさ]となる。\n",
        " * 正確には、単語列長は、ミニバッチに含まれる単語列のうち最長のものの長さ、である。\n",
        " * 最長の単語列以外の単語列は、最長の列と同じ長さになるまで、末尾にパディング用の特殊なトークンで埋められる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSCRoDu3QuH7"
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "\n",
        "train_iterator = BucketIterator(train_data, batch_size=BATCH_SIZE, device=device,\n",
        "                                sort_within_batch=True, shuffle=True, sort_key=lambda x: len(x.src))\n",
        "valid_iterator = BucketIterator(valid_data, batch_size=BATCH_SIZE, device=device)\n",
        "test_iterator = BucketIterator(test_data, batch_size=BATCH_SIZE, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r0zO5EWSUCS"
      },
      "source": [
        "## 10-02　モデル\n",
        "* エンコーダ\n",
        " * 入力として与えられた単語列をまず埋め込み、そしてRNNによって隠れ状態を表すベクトルへと変換する。\n",
        " * 今回は、bidirectionalなRNNを使う。\n",
        "* デコーダ\n",
        " * エンコーダRNNから隠れ状態ベクトルなどの情報を受け取って、翻訳先の言語の単語列を、RNNによって生成する。\n",
        "* エンコーダ、デコーダ両方とも、LSTMではなく、GRUを使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAunw776Q0Pu"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_dim, emb_dim,\n",
        "               enc_hid_dim, dec_hid_dim, p=0.5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.input_dim = input_dim\n",
        "    self.emb_dim = emb_dim\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "    self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
        "    self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "    self.dropout = nn.Dropout(p=p)\n",
        "\n",
        "  def forward(self, src):\n",
        "    # srcの形は[単語列長, バッチサイズ]\n",
        "\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "    # embeddedの形は[単語列長, バッチサイズ, 埋め込み次元数]\n",
        "\n",
        "    outputs, hidden = self.rnn(embedded)\n",
        "    # outputsの形は[単語列長, バッチサイズ, encoderの隠れ状態の次元数*2]\n",
        "    # hiddenの形は[レイヤー数*2, バッチサイズ, encoderの隠れ状態の次元数]\n",
        "    #   hiddenは[forward_1, backward_1, forward_2, backward_2, ...]とスタックされている。\n",
        "\n",
        "    hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
        "    # hiddenの型が[バッチサイズ, デコーダの隠れ状態の次元数]に変わる\n",
        "\n",
        "    return outputs, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlWbaFv4gKLc"
      },
      "source": [
        "### 注意機構(attention)\n",
        "* attentionの部分だけでクラスを定義する。\n",
        "* decoder側の各トークンについて、encoderの出力ベクトル列を線型結合するための重みを求める。\n",
        " * encoder側のトークンのうち、関連度の高いトークンほど、重みが大きくなる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXKwm4LkvRGt"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, enc_hid_dim, dec_hid_dim, attn_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "    self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "    self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "  def forward(self, decoder_hidden, encoder_outputs):\n",
        "    # 翻訳元のシーケンス長を取得\n",
        "    src_len = encoder_outputs.shape[0]\n",
        "\n",
        "    # decoder_hiddenの形は[バッチサイズ, decoderの隠れ状態次元数]\n",
        "    # unsqueezeで軸を真ん中に追加し、その軸の方向にsrc_len回、同じ内容を繰り返す\n",
        "    repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "    # これにより、decoder_hiddenの形は\n",
        "    # [バッチサイズ, 翻訳元のシーケンス長, decoderの隠れ状態次元数]となる\n",
        "\n",
        "    # 上で作ったrepeated_decoder_hiddenと合うように、encoder_outputsの軸を入れ替える\n",
        "    # encoder_outputsの元の形は[翻訳元のシーケンス長, バッチサイズ, encoderの隠れ状態次元数*2]\n",
        "    # 軸を入れ替えると、[バッチサイズ, 翻訳元のシーケンス長, encoderの隠れ状態次元数*2]という形に変わる\n",
        "    # これでrepeated_decoder_hiddenと合う形になる\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "    # attentionのenergyの計算\n",
        "    # ここで使っているのは内積ではない\n",
        "    # ベクトルをconcatenateして、全結合層self.attnに入力し、tanhで-1~1の範囲に収めている\n",
        "    energy = torch.tanh(self.attn(torch.cat((\n",
        "        repeated_decoder_hidden,\n",
        "        encoder_outputs),\n",
        "        dim = 2)))\n",
        "\n",
        "    # energyの形は[バッチサイズ, シーケンス長, attentionの次元数]\n",
        "    # attentionの次元数方向に和をとって[バッチサイズ, 翻訳元のシーケンス長]という形にする\n",
        "    attention = torch.sum(energy, dim=2)\n",
        "    # attentionの各エントリが、翻訳元の各トークンとの\"関連度\"を表している\n",
        "\n",
        "    # attentionの形は[バッチサイズ, シーケンス長]\n",
        "    # シーケンス長方向にsoftmax関数を適用（これにより線型結合に使う係数が得られる）\n",
        "    return F.softmax(attention, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFCzEZFqUYsI"
      },
      "source": [
        "### デコーダ\n",
        "* やはり、LSTMではなく、GRUを使う。\n",
        "* 単語列を生成できる必要があるため、bidirectionalなものは使えない。\n",
        "* デコーダがエンコーダから受け取る情報として、エンコーダRNNの最後の隠れ状態を使うだけではあまりうまくいかない。\n",
        "* そこで今回は、エンコーダRNNの隠れ状態だけでなく、エンコーダRNNの出力ベクトル列（入力単語列に沿って得られるすべて隠れ状態）も、デコーダの入力の一部として使う。\n",
        " * エンコーダRNNの出力ベクトル列を表すテンソルの形は[単語列長, バッチサイズ, 隠れ状態の次元数*2]である。\n",
        " * これらの重み付きの和を、attentionを利用して求め、デコーダへの入力の一部として利用する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFXvrmxXZ4Yy"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_dim, emb_dim,\n",
        "               enc_hid_dim, dec_hid_dim,\n",
        "               attention, p=0.5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.emb_dim = emb_dim\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.attention = attention\n",
        "\n",
        "    self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "    self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "    self.out = nn.Linear(dec_hid_dim + (enc_hid_dim * 2) + emb_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(p=p)\n",
        "\n",
        "  # Attentionのために追加で必要となる関数\n",
        "  # decoder側の個々のトークンについて別々に呼び出される\n",
        "  def _weighted_encoder_rep(self, decoder_hidden, encoder_outputs):\n",
        "    a = self.attention(decoder_hidden, encoder_outputs)\n",
        "    # 戻ってきたaの形は[バッチサイズ, シーケンス長]\n",
        "    # このaの形を、軸を真ん中に追加することで、[バッチサイズ, 1, シーケンス長]に変える\n",
        "    a = a.unsqueeze(1)\n",
        "\n",
        "    # repeated_decoder_hiddenと合うように、encoder_outputsの軸を入れ替える\n",
        "    # encoder_outputsの元の形は[シーケンス長, バッチサイズ, encoderの隠れ状態次元数*2]\n",
        "    # 軸を入れ替えると、[バッチサイズ, シーケンス長, encoderの隠れ状態次元数*2]という形に変わる\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "    # aを重みとした、encoderの出力ベクトル列の線型結合を求める\n",
        "    weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "    # weighted_encoder_repの形は[バッチサイズ, 1, encoderの隠れ状態次元数*2]\n",
        "    weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "    # weighted_encoder_repの形は[1, バッチサイズ, encoderの隠れ状態次元数*2]になる\n",
        "    return weighted_encoder_rep\n",
        "\n",
        "  # forwardメソッドは、decoder側の個々のトークンについて、別々に呼び出される\n",
        "  def forward(self, input, decoder_hidden, encoder_outputs):\n",
        "    # inputの形は[バッチサイズ]\n",
        "    input = input.unsqueeze(0)\n",
        "    # inputの形が[1, バッチサイズ]になる\n",
        "\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    # embeddedの形は[1, バッチサイズ, 埋め込み次元数]\n",
        "\n",
        "    # encoderの出力ベクトル列の線型結合を求める（つまりattentionの計算）\n",
        "    weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                      encoder_outputs)\n",
        "    # 戻ってきたweighted_encoder_repの形は[1, バッチサイズ, encoderの隠れ状態次元数*2]\n",
        "    # encoderの出力ベクトル列の線型結合と、埋め込みベクトルをconcatenateする\n",
        "    rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "    # 次のトークンを予測する\n",
        "    output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "    embedded = embedded.squeeze(0)\n",
        "    # embeddedの形は[バッチサイズ, 埋め込み次元数]になる\n",
        "    output = output.squeeze(0)\n",
        "    # outputの形は[バッチサイズ, decoderの隠れ状態次元数]になる\n",
        "    weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "    # weighted_encoder_repの形は[バッチサイズ, encoderの隠れ状態次元数*2]になる\n",
        "    output = self.out(torch.cat((output, weighted_encoder_rep, embedded), dim = 1))\n",
        "\n",
        "    return output, decoder_hidden.squeeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIUqUqhjYR-m"
      },
      "source": [
        "### エンコーダとデコーダをまとめる\n",
        "* エンコーダとデコーダをまとめて扱うためのクラスを定義する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L48AsrWMbtjv"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, device):\n",
        "    super().__init__()\n",
        "       \n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.device = device\n",
        "\n",
        "  def forward(self, src, trg, teacher_forcing_ratio=0.5, no_length_limit=False):\n",
        "    # trgの形は[単語列長, バッチサイズ]\n",
        "    max_len, batch_size = trg.shape\n",
        "    if no_length_limit:\n",
        "      max_len *= 2\n",
        "    trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "    outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "    encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "    # デコーダへの最初の入力トークンは<sos>トークン\n",
        "    output = trg[0,:]\n",
        "    for t in range(1, max_len):\n",
        "      output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "      outputs[t] = output\n",
        "      teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "      top1 = output.max(1)[1]\n",
        "      output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8qQoryupNCd"
      },
      "source": [
        "### 定数の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASfUgCNZfWCg"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "\n",
        "ENC_EMB_DIM = 128\n",
        "DEC_EMB_DIM = 128\n",
        "ENC_HID_DIM = 128\n",
        "DEC_HID_DIM = 128\n",
        "ATTN_DIM = 16\n",
        "ENC_DROPOUT = 0.2\n",
        "DEC_DROPOUT = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imTDkiCepPty"
      },
      "source": [
        "### モデルのインスタンスを作る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4P9v56jfhGB"
      },
      "source": [
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "\n",
        "model = Seq2Seq(\n",
        "    Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, p=ENC_DROPOUT),\n",
        "    Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, attn, p=DEC_DROPOUT),\n",
        "    device\n",
        "    ).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUsuzxFrAI_H"
      },
      "source": [
        "!pip install torch-summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37-mVw42AMvC"
      },
      "source": [
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2qiVi85AWI4"
      },
      "source": [
        "summary(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYQhZ-TppZbr"
      },
      "source": [
        "### optimizerの準備\n",
        "* Adamを使う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW6aAw98f6Vc"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWy4Nt9hgAHG"
      },
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRwkTpFTpd8q"
      },
      "source": [
        "### 損失関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOoS-LzpgEV6"
      },
      "source": [
        "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
        "print(PAD_IDX)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttPYGa32p8XI"
      },
      "source": [
        "## 10-03 学習や評価を補助するための関数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0wCVPzopgfs"
      },
      "source": [
        "### 訓練のための関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6I5gj72gKaJ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "  model.train()\n",
        "\n",
        "  epoch_loss = 0\n",
        "  for batch in iterator:\n",
        "    src = batch.src\n",
        "    trg = batch.trg\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(src, trg)\n",
        "    output = output[1:].view(-1, output.shape[-1])\n",
        "    trg = trg[1:].view(-1)\n",
        "\n",
        "    loss = criterion(output, trg)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMzz2Vleplta"
      },
      "source": [
        "### 評価のための関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp44U6kAhUtZ"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "  model.eval()\n",
        "\n",
        "  epoch_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      src = batch.src\n",
        "      trg = batch.trg\n",
        "\n",
        "      output = model(src, trg, 0) # teacher forcingは無効にする\n",
        "      output = output[1:].view(-1, output.shape[-1])\n",
        "      trg = trg[1:].view(-1)\n",
        "\n",
        "      loss = criterion(output, trg)\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u9ejxDOpn2O"
      },
      "source": [
        "### 経過時間を表示する関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRwz0mzrhk-X"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52f9ZQonprxu"
      },
      "source": [
        "### チェックポイントの保存・読み込みの関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mbYrgxojcQo"
      },
      "source": [
        "def save_checkpoint(path, model, optimizer, epoch):\n",
        "  torch.save({\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'epoch': epoch,\n",
        "      }, path)\n",
        "  \n",
        "def load_checkpoint(path, model, optimizer):\n",
        "  checkpoint = torch.load(path)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  return checkpoint['epoch']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7zERf_5pz8r"
      },
      "source": [
        "## 10-04 学習の実行\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmRV52TcBdLN"
      },
      "source": [
        "* 途中まで学習済みのモデルがあればロードする。\n",
        " * チェックポイントを保存するパスは各自設定してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pafg7qUiBUc0"
      },
      "source": [
        "# 下記のパスは、あくまでも、例です。\n",
        "LOAD_PATH = '/content/drive/MyDrive/2020Courses/NLP/10_NMT_fr.tar' \n",
        "SAVE_PATH = '/content/drive/MyDrive/2020Courses/NLP/10_NMT_fr.tar'\n",
        "\n",
        "# チェックポイントのロード（エラーは無視）\n",
        "init_epoch = 0\n",
        "try:\n",
        "  init_epoch = load_checkpoint(LOAD_PATH, model, optimizer)\n",
        "except:\n",
        "  print(\"No checkpoints.\")\n",
        "  pass\n",
        "init_epoch += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4FyOBsBBYWl"
      },
      "source": [
        "* trainingのループ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8NaX5G1hunV"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(init_epoch, init_epoch + N_EPOCHS):\n",
        "\n",
        "  start_time = time.time()\n",
        "  train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "  valid_loss, _ = evaluate(model, valid_iterator, criterion)\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    save_checkpoint(SAVE_PATH, model, optimizer, epoch)\n",
        "\n",
        "  print(f'Epoch: {epoch:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWkobCS7zSnr"
      },
      "source": [
        "## 10-05 テストセット上で評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLElnZVgzYEd"
      },
      "source": [
        "### 定量的評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5EhLaG_iBMR"
      },
      "source": [
        "test_loss, output = evaluate(model, test_iterator, criterion)\n",
        "print(f'| Test Loss: {test_loss:.3f}\\t|\\tTest PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubW8Z5WKzaX5"
      },
      "source": [
        "### 定性的評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSDs7OP91T8P"
      },
      "source": [
        "load_checkpoint(LOAD_PATH, model, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyxow5vBYUOh"
      },
      "source": [
        "def iseq2sseq(field, seq):\n",
        "  return [field.vocab.itos[i] for i in seq if i != field.vocab.stoi[field.pad_token] and i != field.vocab.stoi[field.eos_token]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iFxPGyEvYHH"
      },
      "source": [
        "test_batch = list(test_iterator)[0]\n",
        "outputs = model(test_batch.src, test_batch.trg, 0, True)\n",
        "for j in range(test_batch.src.shape[1]):\n",
        "  print('>', ' '.join(iseq2sseq(SRC, test_batch.src[1:, j])))\n",
        "  print('=', ' '.join(iseq2sseq(TRG, test_batch.trg[1:, j])))\n",
        "  print('<', ' '.join(iseq2sseq(TRG, outputs[1:, j, :].squeeze().argmax(1))))\n",
        "  print('-' * 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bIGzYoDzO20"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}